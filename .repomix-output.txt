This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-03-08T17:57:25.193Z

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
docs/
  backend-architecture.mermaid
  checking-user-and-debate-flow.md
  citation-support-how-it-works.md
  greatdebate.code-workspace
  langchain-integration.md
  Potential-issues.md
  RAG-Implementation.md
  README.md
  Status.md
public/
  file.svg
  globe.svg
  next.svg
  vercel.svg
  window.svg
src/
  app/
    api/
      analyze/
        route.ts
      auth/
        [...nextauth]/
          route.ts
      content/
        document/
          route.ts
        link/
          route.ts
        media/
          route.ts
      debate/
        route.ts
      debate-fixed/
        route.ts
      debate-new/
        route.ts
      debate-simple/
        route.ts
      debate-test/
        route.ts
      hello/
        route.ts
      test/
        route.ts
      test-agents/
        route.ts
      test-api/
        route.ts
      test-redis/
        route.ts
      user/
        account/
          delete/
            route.ts
        preferences/
          route.ts
        profile/
          update/
            route.ts
          route.ts
      voice/
        route.ts
    api-test/
      page.tsx
    app/
      debate/
        layout.tsx
        page.tsx
      layout.tsx
      page.tsx
    auth/
      signin/
        page.tsx
    profile/
      page.tsx
    settings-test/
      page.tsx
    globals.css
    layout.tsx
    page.tsx
    providers.tsx
  components/
    content-processing/
      ContentUploader.tsx
    debate/
      CitationFooter.tsx
      DebatePanel.tsx
      DebateSummary.tsx
      ExpertCard.tsx
      ExpertProfile.tsx
      ExpertTypeSelector.tsx
      Message.tsx
      MessageBubble.tsx
      UserInput.tsx
    ui/
      AccountDetails.tsx
      alert-dialog.tsx
      avatar.tsx
      button.tsx
      card.tsx
      dropdown-menu.tsx
      input.tsx
      PreferenceSettings.tsx
      ProfilePicture.tsx
      select.tsx
      skeleton.tsx
      spinner.tsx
      switch.tsx
      tabs.tsx
      textarea.tsx
      toast.tsx
      toaster.tsx
      use-toast.ts
    ThemeProvider.tsx
    ThemeToggle.tsx
    ThinkingIndicator.tsx
    UserNavigation.tsx
  lib/
    agents/
      context-management.ts
      fact-checking.ts
      index.ts
      knowledge-retrieval.ts
      README.md
      test-integration.ts
    ai/
      document-processor.ts
      expert-selector.ts
      openai-client.ts
      response-generator.ts
    content-processing/
      document-parser.ts
      index.ts
      media-processor.ts
      topic-extractor.ts
    contexts/
      settings-context.tsx
    db/
      models/
        debate.ts
        user.ts
      firestore.ts
    mock/
      user.ts
    services/
      DebateCache.ts
    storage/
      background-task-manager.ts
      debate-storage.ts
      types.ts
    tasks/
      background-tasks.ts
    utils/
      citation-processor.ts
    auth.ts
    elevenlabs.ts
    langchain-config.ts
    openai.ts
    providers.tsx
    redis.ts
    store.ts
    test-redis.js
    test-upstash-redis.js
    theme.ts
    utils.ts
  types/
    content-processing.ts
    expert.ts
    message.ts
    storage.ts
.gitignore
eslint.config.mjs
GOOGLE_CLOUD_SETUP.md
next.config.js
next.config.ts
package.json
postcss.config.mjs
README.md
tailwind.config.ts
tsconfig.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="docs/backend-architecture.mermaid">
flowchart TB
    subgraph Client
        UI["React Frontend"]
        VoiceIn["Voice Input Module"]
        VoiceOut["Voice Output Module"]
    end
    
    subgraph Backend
        API["API Layer (Next.js)"]
        
        subgraph ContentProcessing
            DocParser["Document Parser"]
            TopicExtractor["Topic Extractor"]
            MediaProcessor["Media Processor"]
        end
        
        subgraph AIEngine
            LLM["Large Language Model"]
            DebatersDB["Debater Personas DB"]
            PromptEngine["Prompt Engineering Engine"]
            FactChecker["Fact Verification"]
            RAG["Retrieval Augmented Generation"]
        end
        
        subgraph UserDataStore
            Supabase[(Supabase/PostgreSQL)]
            VectorDB[(Vector Database)]
            KnowledgeGraph[(Knowledge Graph)]
        end
    end
    
    subgraph ExternalServices
        ElevenLabs["ElevenLabs API"]
        ReadwiseAPI["Readwise API"]
        TwitterAPI["Twitter/X API"]
        YoutubeAPI["YouTube API"]
    end
    
    UI --> API
    VoiceIn --> API
    API --> VoiceOut
    
    API --> DocParser
    API --> TopicExtractor
    API --> MediaProcessor
    
    DocParser --> TopicExtractor
    MediaProcessor --> TopicExtractor
    
    TopicExtractor --> PromptEngine
    PromptEngine --> LLM
    DebatersDB --> PromptEngine
    RAG --> LLM
    LLM --> FactChecker
    FactChecker --> API
    
    API --> Supabase
    API --> VectorDB
    API --> KnowledgeGraph
    
    VoiceIn --> ElevenLabs
    ElevenLabs --> VoiceOut
    
    API --> ReadwiseAPI
    API --> TwitterAPI
    API --> YoutubeAPI
</file>

<file path="docs/checking-user-and-debate-flow.md">
### Debate Web App - Technical Outline and Data Flow
This will be broken into **several key sections**:
**1** **System Architecture & User Flow**
**2** **AI Debater Logic & API Orchestration**
**3** **Handling Timing, Context, and Relevance**
**4** **Data Storage (Firebase Integration)**
**5** **Technical Stack & Code Breakdown**

⠀Let’s begin with **System Architecture & User Flow**.

# 1. System Architecture & User Flow
### User Journey
**1** **User selects a debate topic** (e.g., "Should AI be regulated?").
**2** **User chooses a side** (support or oppose).
**3** **AI debaters generate an opening argument** (one for, one against).
**4** **User participates**, responding with their argument.
**5** **AI debaters take turns engaging with each other and the user**.
**6** **System maintains context and coherence** through structured debate turns.
**7** **Debate concludes** after a set number of rounds or if the user opts to end it.

⠀Core System Components
| **Component** | **Function** |
|:-:|:-:|
| **Next.js 15** | Frontend UI, Chat Interface |
| **OpenAI API** | Generates AI debater responses |
| **Grok3 & Perplexity** | Fetch additional references, facts, counterpoints |
| **LangChain Agents** | Retrieve relevant information before responses |
| **Firebase Firestore** | Stores chat history, user profiles |
| **Queue System** | Handles API delays by simulating "thinking" time |

### Data Flow Diagram
**Step-by-step Data Flow
1** **User chooses a debate topic** → Sent to Firebase.
**2** **System initializes AI debaters** → LangChain fetches background knowledge.
**3** **First AI debater (support) responds** → Next.js UI updates chat.
**4** **Second AI debater (oppose) responds** → Next.js UI updates chat.
**5** **User inputs response** → Sent to Firebase.
**6** **AI debaters analyze user’s response** → Generate rebuttals using OpenAI & Grok3.
**7** **Flow repeats** until the debate ends.

Here is the **system architecture data flow diagram**. It visually represents how user interactions, AI debaters, background knowledge retrieval, and API calls are structured.

# 2. AI Debater Logic & API Orchestration
In this section, we’ll cover:
**1** **How AI debaters generate arguments**
**2** **How LangChain agents fetch background knowledge**
**3** **How OpenAI, Grok3, and Perplexity interact to ensure factual and relevant responses**
**4** **How we orchestrate API calls and manage response timing**

⠀
### AI Debater Flow
Each AI debater (Supporter & Opposer) follows a structured process:
**1** **Topic Initialization**:
	* User selects a topic.
	* The system initializes AI debaters with predefined personas (Supporter & Opposer).
	* A prompt is sent to OpenAI API for the opening arguments.
**2** **Knowledge Retrieval**:
	* A **LangChain agent** runs in the background to collect topic-relevant data.
	* It queries **Grok3** for recent debates, **Perplexity** for factual accuracy, and **OpenAI** for logical argument structuring.
**3** **Turn-Based Argument Generation**:
	* AI Debater (Supporter) responds first.
	* AI Debater (Opposer) generates a counterargument.
	* The **user inputs a response**, which is stored in Firebase.
**4** **Refinement & Context Management**:
	* AI debaters analyze user input.
	* LangChain **retrieves relevant counterpoints** from external sources.
	* The response is formatted and sent back via OpenAI API.

⠀
### LangChain Agent Flow
LangChain plays a crucial role in retrieving background information efficiently.
**1** **Query Generation**:
	* When a debate starts, the system **defines key questions** for background retrieval.
	* Example: If the topic is “Should AI be regulated?”, the system might generate:
		* *"What are the latest arguments for AI regulation?"*
		* *"What are counterarguments against AI regulation?"*
**2** **External Data Retrieval**:
	* Queries are sent to:
		* **Grok3 API** (to fetch expert arguments & references)
		* **Perplexity API** (to validate factual accuracy)
		* **OpenAI API** (to generate structured responses)
**3** **Response Integration**:
	* LangChain processes the retrieved content and **feeds it into the AI debaters’ next responses**.
	* AI debaters **refine arguments based on this data**.

⠀
### API Orchestration
Since multiple APIs are involved, we need a structured way to **ensure optimal response timing** while keeping the debate natural.
| **API** | **Function** | **Timing Strategy** |
|:-:|:-:|:-:|
| **OpenAI** | AI debater responses | Instant (cached for fast retrieval) |
| **Grok3** | Expert-backed arguments | Background (LangChain fetch) |
| **Perplexity** | Fact-checking | Background (LangChain validation) |
| **Firebase** | Storing chat history | Instant |
| **Queue System** | Handles API delays | Simulates "thinking" time |

### Managing Response Timing & Flow
Since OpenAI API calls return fast, but knowledge retrieval can take longer, we introduce **simulated delays**:
**1** **Instant OpenAI Response**: AI debaters generate an initial reply quickly.
**2** **Background Research Trigger**: LangChain starts retrieving deeper insights.
**3** **"Thinking" Message Displayed**: If a response is taking longer, the UI shows:
	* *"AI Debater is thinking..."*
**4** **Delayed but Enriched Response**: Once Grok3/Perplexity data is available, a refined response is sent.

⠀
### Code Implementation (LangChain Agent & Debate Flow)
Now, let’s write a basic **LangChain integration** to retrieve structured debate points.
### from langchain.llms import OpenAI
### from langchain.tools import Tool
### from langchain.agents import AgentType, initialize_agent
### from langchain.memory import ConversationBufferMemory

### # Define LLM model
### llm = OpenAI(model="gpt-4", temperature=0.7)

### # Define tools (APIs)
### grok_tool = Tool(name="Grok3", func=lambda q: f"Grok3 data for {q}")
### perplexity_tool = Tool(name="Perplexity", func=lambda q: f"Perplexity fact-check for {q}")

### # Initialize LangChain agent
### agent = initialize_agent(
###     tools=[grok_tool, perplexity_tool],
###     llm=llm,
###     agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
###     memory=ConversationBufferMemory()
### )

### # Simulated AI debater response using LangChain
### def generate_ai_response(user_input, side):
###     query = f"Generate a {side} argument for: {user_input}"
###     knowledge = agent.run(query)
###     return f"{side.upper()} RESPONSE:\n{knowledge}"

### # Example usage
### topic = "Should AI be regulated?"
### support_response = generate_ai_response(topic, "support")
### oppose_response = generate_ai_response(topic, "oppose")

### print(support_response)
### print(oppose_response)

### 
# 3. Handling Timing, Context, and Relevance
To maintain a smooth debate experience while managing API delays, ensuring relevance, and keeping context intact, we need to focus on:
**1** **Turn-based Debate Structure**
**2** **Simulating AI “Thinking” for Delayed Responses**
**3** **Maintaining Context Across Turns**
**4** **Handling Off-topic or Irrelevant Responses**

⠀
### 1. Turn-Based Debate Structure
To enforce a structured debate:
* **Each participant takes turns** (User → AI Debater Support → AI Debater Oppose → Repeat).
* We **store the conversation flow** in Firebase to track who speaks next.
* Each AI debater **acknowledges the previous response** before generating their own.

⠀**Step** **Action** |
|:-:|---|
| 1 | User selects a topic. |
| 2 | Supporter AI makes an opening statement. |
| 3 | Opposer AI counters with a rebuttal. |
| 4 | User responds (optional). |
| 5 | Supporter AI analyzes user’s point and counterattacks. |
| 6 | Opposer AI refutes again. |
| 7 | Repeat until the debate ends. |

### 2. Simulating AI “Thinking” for Delayed Responses
Since some responses (fact-checking, deeper analysis) may take longer, we **introduce artificial delays**.
**1** **Instant Responses**:
	* If OpenAI can generate a response quickly, it is displayed immediately.
**2** **Delayed but Enriched Responses**:
	* If background knowledge (from Grok3/Perplexity) is needed, the UI shows:
		* *"AI Debater is thinking..."*
	* This buys time for external API calls while maintaining user engagement.
	* Once data arrives, a more **detailed response** is generated.

⠀**Implementation Strategy:**
* Use a queue system to determine if an immediate response is possible.
* If data is still being retrieved, display a "thinking" message.
* Update the UI when the final response is ready.

⠀const handleAIResponse = async (debater, topic) => {
  setThinkingState(debater, true); // Show "thinking..."

  const quickResponse = await fetchOpenAIResponse(topic);
  updateChat(debater, quickResponse);

  const additionalData = await fetchBackgroundKnowledge(topic);
  if (additionalData) {
    const enrichedResponse = await generateFinalResponse(topic, additionalData);
    updateChat(debater, enrichedResponse);
  }

  setThinkingState(debater, false); // Hide "thinking..."
};

### 3. Maintaining Context Across Turns
A major challenge is keeping **AI debaters focused and relevant**. Without memory, they might **repeat themselves** or **lose track of the debate flow**.
**How We Maintain Context**
* Store **entire conversation history** in **Firebase**.
* Use **LangChain’s memory** to **keep track of previous arguments**.
* Reinforce **debate rules** in AI prompts (e.g., *Don’t change the topic*).

⠀**LangChain Memory Example**
### from langchain.memory import ConversationBufferMemory

### memory = ConversationBufferMemory()

### def generate_response(user_input, side):
###     prompt = f"{memory.load_memory_variables({})}\nNew input: {user_input}\nGenerate {side} argument."
###     response = openai.Completion.create(model="gpt-4", prompt=prompt)
###     memory.save_context({"input": user_input}, {"output": response})
###     return response
**How it Works:**
* AI remembers past arguments.
* Ensures logical progression of the debate.
* Helps AI **respond to user inputs intelligently** instead of starting fresh each time.

⠀
### 4. Handling Off-topic or Irrelevant Responses
Users may **derail the debate** by:
* Asking unrelated questions (*"What’s your favorite color?"*).
* Spamming non-debate content.
* Switching topics midway.

⠀**Solution: Context-Aware Filters**
* Use **moderation filters** to **detect off-topic input**.
* If detected, AI debaters **steer the conversation back**.

⠀def filter_irrelevant_input(user_input):
    if "weather" in user_input or "random" in user_input:
        return "That seems off-topic. Let's focus on the debate."
    return None

# 
## 4. Data Storage (Firebase Integration)
Since we are using **Firebase Firestore** for storing **chat history, user profiles, and debate logs**, we need to ensure:
**1** **Efficient storage structure** for debates and user participation.
**2** **Real-time updates** so the chat UI stays synced.
**3** **Scalability** to handle multiple concurrent debates.

⠀
### Firestore Database Structure
Firestore organizes data in **collections and documents**. Here’s how we structure the database:
/debates (Collection)
   /debateID_123 (Document)
       - topic: "Should AI be regulated?"
       - user_id: "user_abc"
       - created_at: timestamp
       - messages: [Array]
           - { role: "user", text: "I think AI should be regulated.", timestamp }
           - { role: "support", text: "AI regulation is crucial to prevent misuse.", timestamp }
           - { role: "oppose", text: "Regulation may hinder innovation.", timestamp }

/users (Collection)
   /user_abc (Document)
       - name: "John Doe"
       - debates_participated: ["debateID_123", "debateID_456"]
       - created_at: timestamp
* **/debates**: Stores each debate session.
* **messages array**: Maintains the conversation flow.
* **/users**: Stores user profile and debate history.

⠀
### Real-Time Updates for Chat UI
To ensure the **chat UI updates live**, we use Firestore’s **real-time listeners**.
**Setup Firestore Listener in Next.js**
import { db } from '../firebase'; // Firebase config
import { collection, query, orderBy, onSnapshot } from "firebase/firestore";

const listenToDebate = (debateID, setMessages) => {
    const q = query(collection(db, `debates/${debateID}/messages`), orderBy("timestamp"));

    return onSnapshot(q, (snapshot) => {
        let chatMessages = [];
        snapshot.forEach((doc) => {
            chatMessages.push({ id: doc.id, ...doc.data() });
        });
        setMessages(chatMessages); // Update UI
    });
};
**How It Works:**
* Listens for new messages.
* Automatically updates the UI when a new message is added.
* Uses **orderBy("timestamp")** to maintain message sequence.

⠀
### Storing User Messages & AI Responses
When a user or AI sends a message, we **store it in Firestore**.
import { db } from "../firebase";
import { collection, addDoc, serverTimestamp } from "firebase/firestore";

const sendMessage = async (debateID, role, text) => {
    await addDoc(collection(db, `debates/${debateID}/messages`), {
        role,
        text,
        timestamp: serverTimestamp()
    });
};
* Uses **serverTimestamp()** to sync timestamps across different time zones.
* Supports **real-time collaboration** for debates.

⠀
### Handling Scalability & Load
To support multiple users:
**1** **Index Firestore Queries**:
	* Firestore performs best with **indexed queries**.
	* Use **Firestore rules** to optimize security & performance.
**2** **Paginate Older Messages**:const fetchOldMessages = async (debateID, lastVisibleMessage) => {
3     const q = query(collection(db, `debates/${debateID}/messages`),
4                     orderBy("timestamp"),
5                     startAfter(lastVisibleMessage),
6                     limit(10));
7     return getDocs(q);
8 };
9 

⠀
## 
## 5. Technical Stack & Code Breakdown
Now that we have defined the architecture, AI logic, and Firebase integration, let’s put everything together into a **scalable Next.js 15 implementation**.
### Full Tech Stack
| **Component** | **Technology** |
|:-:|:-:|
| **Frontend UI** | Next.js 15, TailwindCSS |
| **Chat Storage** | Firebase Firestore |
| **User Authentication** | Firebase Auth (Google Sign-In, Email) |
| **AI Debaters** | OpenAI API (GPT-4), LangChain |
| **Fact-checking** | Grok3 API, Perplexity API |
| **Background Agents** | LangChain Tools & Memory |
| **State Management** | React Context API, Firestore Real-time Listener |

## 5.1. Next.js 15 Project Setup
### Step 1: Install Dependencies
Run the following in your Next.js project directory:
npx create-next-app@latest debate-app
cd debate-app

# Install Firebase and AI APIs
npm install firebase langchain openai

### Step 2: Configure Firebase in Next.js
Create a firebase.js file:
import { initializeApp } from "firebase/app";
import { getFirestore } from "firebase/firestore";
import { getAuth, GoogleAuthProvider } from "firebase/auth";

// Firebase config
const firebaseConfig = {
  apiKey: "YOUR_API_KEY",
  authDomain: "YOUR_AUTH_DOMAIN",
  projectId: "YOUR_PROJECT_ID",
  storageBucket: "YOUR_STORAGE_BUCKET",
  messagingSenderId: "YOUR_MESSAGING_SENDER_ID",
  appId: "YOUR_APP_ID"
};

// Initialize Firebase
const app = initializeApp(firebaseConfig);
const db = getFirestore(app);
const auth = getAuth(app);
const provider = new GoogleAuthProvider();

export { db, auth, provider };

### Step 3: Build Chat UI (Frontend)
Inside pages/index.js:
import { useEffect, useState } from "react";
import { db, auth } from "../firebase";
import { collection, addDoc, query, orderBy, onSnapshot, serverTimestamp } from "firebase/firestore";

export default function Debate() {
    const [messages, setMessages] = useState([]);
    const [input, setInput] = useState("");
    const [debateID] = useState("debate_123"); // Hardcoded for now

    useEffect(() => {
        const q = query(collection(db, `debates/${debateID}/messages`), orderBy("timestamp"));
        return onSnapshot(q, (snapshot) => {
            let chatMessages = [];
            snapshot.forEach((doc) => chatMessages.push({ id: doc.id, ...doc.data() }));
            setMessages(chatMessages);
        });
    }, [debateID]);

    const sendMessage = async () => {
        if (!input.trim()) return;
        await addDoc(collection(db, `debates/${debateID}/messages`), {
            role: "user",
            text: input,
            timestamp: serverTimestamp()
        });
        setInput("");
    };

    return (
        <div className="min-h-screen flex flex-col items-center justify-center bg-gray-100 p-4">
            <div className="w-full max-w-2xl bg-white shadow-lg rounded-lg p-6">
                <h2 className="text-2xl font-bold mb-4">Debate Chat</h2>
                <div className="h-80 overflow-y-auto border p-4 mb-4">
                    {messages.map((msg) => (
                        <p key={msg.id} className={`p-2 ${msg.role === "user" ? "bg-blue-200" : "bg-gray-200"}`}>
                            <strong>{msg.role}:</strong> {msg.text}
                        </p>
                    ))}
                </div>
                <input
                    type="text"
                    className="w-full border p-2 rounded"
                    value={input}
                    onChange={(e) => setInput(e.target.value)}
                    placeholder="Type your argument..."
                />
                <button onClick={sendMessage} className="w-full mt-2 bg-blue-500 text-white py-2 rounded">
                    Send
                </button>
            </div>
        </div>
    );
}

### Step 4: AI Debaters (Backend API Route)
Inside pages/api/debate.js:
import { OpenAI } from "langchain/llms/openai";
import { db } from "../../firebase";
import { collection, addDoc, serverTimestamp } from "firebase/firestore";

const llm = new OpenAI({ modelName: "gpt-4", temperature: 0.7 });

export default async function handler(req, res) {
    if (req.method !== "POST") return res.status(405).end();

    const { debateID, userMessage, side } = req.body;

    // Generate AI response
    const aiPrompt = `You are debating on the topic '${debateID}'. As a ${side} debater, generate a logical response to: '${userMessage}'`;
    const aiResponse = await llm.call(aiPrompt);

    // Store response in Firestore
    await addDoc(collection(db, `debates/${debateID}/messages`), {
        role: side,
        text: aiResponse,
        timestamp: serverTimestamp()
    });

    res.status(200).json({ message: aiResponse });
}

### Step 5: Connecting AI Responses to Chat UI
Modify pages/index.js to call AI after user input:
const sendMessage = async () => {
    if (!input.trim()) return;
    
    // Send user message to Firestore
    await addDoc(collection(db, `debates/${debateID}/messages`), {
        role: "user",
        text: input,
        timestamp: serverTimestamp()
    });

    // Call AI for the next response
    const response = await fetch("/api/debate", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ debateID, userMessage: input, side: "support" })
    });

    const data = await response.json();
    setInput("");
};

### Step 6: Adding AI Thinking Delay
Modify the API handler to introduce a **"thinking..."** message:
await addDoc(collection(db, `debates/${debateID}/messages`), {
    role: side,
    text: "AI is thinking...",
    timestamp: serverTimestamp()
});

setTimeout(async () => {
    const aiResponse = await llm.call(aiPrompt);
    await addDoc(collection(db, `debates/${debateID}/messages`), {
        role: side,
        text: aiResponse,
        timestamp: serverTimestamp()
    });
}, 5000);

## 

## 6. Advanced AI Refinements: Fact-Checking & LangChain Integration
Now, we will refine the AI debaters with:
**1** **Fact-checking using Grok3 & Perplexity**
**2** **LangChain integration for retrieving structured debate knowledge**
**3** **Bias reduction & debate structuring**
**4** **Ensuring AI-generated responses stay logical and relevant**

⠀
## 6.1. Fact-Checking with Grok3 & Perplexity
AI-generated arguments need **fact verification** to prevent misinformation. We integrate **Grok3 for expert insights** and **Perplexity for external fact-checking**.
### LangChain Tool Setup for API Calls
Modify pages/api/debate.js:
import { OpenAI } from "langchain/llms/openai";
import { Tool, initializeAgent, AgentType } from "langchain/agents";
import { db } from "../../firebase";
import { collection, addDoc, serverTimestamp } from "firebase/firestore";

const llm = new OpenAI({ modelName: "gpt-4", temperature: 0.7 });

// Define fact-checking tools
const tools = [
    new Tool({
        name: "Grok3",
        func: async (query) => {
            const response = await fetch(`https://api.grok3.com/search?q=${encodeURIComponent(query)}`);
            return await response.text();
        },
        description: "Fetches expert-backed arguments."
    }),
    new Tool({
        name: "Perplexity",
        func: async (query) => {
            const response = await fetch(`https://api.perplexity.ai/search?q=${encodeURIComponent(query)}`);
            return await response.text();
        },
        description: "Retrieves factual information from various sources."
    })
];

// Initialize LangChain agent
const agent = initializeAgent({
    tools,
    llm,
    agentType: AgentType.ZERO_SHOT_REACT_DESCRIPTION
});

export default async function handler(req, res) {
    if (req.method !== "POST") return res.status(405).end();

    const { debateID, userMessage, side } = req.body;
    
    // AI generates an initial response
    const aiPrompt = `You are debating '${debateID}'. As a ${side} debater, generate a logical argument: '${userMessage}'`;
    const initialResponse = await llm.call(aiPrompt);

    // Store "thinking..." message
    await addDoc(collection(db, `debates/${debateID}/messages`), {
        role: side,
        text: "AI is verifying information...",
        timestamp: serverTimestamp()
    });

    // Fact-check response with Grok3 & Perplexity
    const verificationQuery = `Verify: ${initialResponse}`;
    const grokCheck = await tools[0].func(verificationQuery);
    const perplexityCheck = await tools[1].func(verificationQuery);

    // Refine response based on fact-checking
    const refinedPrompt = `Adjust the following argument to be more factually correct based on: \nGrok3: ${grokCheck}\nPerplexity: ${perplexityCheck}\n\nOriginal Argument: ${initialResponse}`;
    const finalResponse = await llm.call(refinedPrompt);

    // Store verified response
    await addDoc(collection(db, `debates/${debateID}/messages`), {
        role: side,
        text: finalResponse,
        timestamp: serverTimestamp()
    });

    res.status(200).json({ message: finalResponse });
}

## 6.2. Integrating Background Knowledge Retrieval
Instead of relying solely on real-time AI generation, we fetch **structured knowledge** before the debate starts.
### How it Works
**1** **Before the debate starts**, LangChain fetches background knowledge.
2 This knowledge is stored in **Firebase** for reference.
3 AI debaters use **this stored knowledge** to **stay consistent**.

⠀
### Preloading Knowledge to Firestore
Modify pages/api/startDebate.js:
import { db } from "../../firebase";
import { OpenAI } from "langchain/llms/openai";
import { collection, addDoc, serverTimestamp } from "firebase/firestore";

const llm = new OpenAI({ modelName: "gpt-4", temperature: 0.7 });

export default async function handler(req, res) {
    if (req.method !== "POST") return res.status(405).end();

    const { debateID, topic } = req.body;

    // Fetch background knowledge
    const backgroundPrompt = `Provide a well-structured knowledge base for debating: '${topic}'. Include pros, cons, historical context, and key statistics.`;
    const backgroundKnowledge = await llm.call(backgroundPrompt);

    // Store knowledge in Firebase
    await addDoc(collection(db, `debates/${debateID}`), {
        topic,
        background: backgroundKnowledge,
        created_at: serverTimestamp()
    });

    res.status(200).json({ message: "Background knowledge stored." });
}

### AI Debaters Using Stored Knowledge
Modify pages/api/debate.js:
import { doc, getDoc } from "firebase/firestore";

const fetchStoredKnowledge = async (debateID) => {
    const debateDoc = await getDoc(doc(db, "debates", debateID));
    return debateDoc.exists() ? debateDoc.data().background : "";
};

export default async function handler(req, res) {
    if (req.method !== "POST") return res.status(405).end();

    const { debateID, userMessage, side } = req.body;
    
    // Retrieve stored knowledge
    const storedKnowledge = await fetchStoredKnowledge(debateID);

    // AI argument using stored knowledge
    const aiPrompt = `Using the stored debate knowledge: \n${storedKnowledge}\n\nGenerate a logical ${side} argument: '${userMessage}'`;
    const aiResponse = await llm.call(aiPrompt);

    // Store AI response
    await addDoc(collection(db, `debates/${debateID}/messages`), {
        role: side,
        text: aiResponse,
        timestamp: serverTimestamp()
    });

    res.status(200).json({ message: aiResponse });
}

## 6.3. AI Debater Bias Reduction
To avoid AI debaters **favoring one side**, we enforce:
* **Equal argument structuring**
* **Automatic contradiction detection**
* **Randomized response phrasing**

⠀Modify AI generation with **structured argument formats**:
const structuredDebatePrompt = `
You are debating '${debateID}'.
As a ${side} debater, respond to: '${userMessage}'
Follow this structure:
1. Acknowledge the opposing view.
2. Provide a logical counterargument.
3. Include a supporting example.
4. Conclude with a persuasive statement.
`;
This ensures **balanced** and **structured** responses.

## 6.4. Handling Logical Fallacies
To avoid AI using **weak arguments**:
* We **scan AI output for logical fallacies**.
* If detected, the AI **self-corrects**.

⠀Modify AI response validation:
const detectLogicalFallacies = async (response) => {
    const fallacyCheckPrompt = `Does the following response contain logical fallacies? If so, rewrite it to be more logical.\n\nResponse: ${response}`;
    return await llm.call(fallacyCheckPrompt);
};

// Refine AI response if fallacies are detected
const finalResponse = await detectLogicalFallacies(aiResponse);
This prevents:
* **Strawman arguments**
* **False analogies**
* **Slippery slope fallacies**
</file>

<file path="docs/citation-support-how-it-works.md">
# Citation Support Implementation

## Overview

The citation support feature enhances the debate application by enabling experts to back their claims with verifiable sources. This document explains how citations are implemented, from knowledge retrieval to UI display.

## Architecture

The citation system uses a multi-stage approach:

1. **Knowledge Retrieval**: Background information and sources are gathered for each expert
2. **Citation Instruction**: The LLM is prompted to include citation markers in responses
3. **Citation Processing**: Response text is parsed to extract citation markers
4. **Source Linking**: Citations are linked to specific source references
5. **UI Rendering**: Citations are displayed in a collapsible footer under expert messages

## Key Components

### 1. Data Structures

```typescript
// Citation structure
export interface Citation {
  id: string;          // Citation identifier (e.g., "1", "2")
  source: SourceReference; // Reference to the source
  highlight?: string;  // Optional highlighted text that was cited
}

// Source reference structure
export interface SourceReference {
  title: string;
  url?: string;
  author?: string;
  publishDate?: string;
  excerpt?: string;
  relevance?: number; // 0-1 scale
}

// Extended Message interface
export interface Message {
  // Existing fields...
  citations?: Citation[];
  hasProcessedCitations?: boolean;
}

// Extended Expert interface
export interface Expert {
  // Existing fields...
  sourceReferences?: SourceReference[];
}
```

### 2. Utility Functions

#### Citation Processing

The `processCitationMarkers` function extracts citation markers from text and links them to source references:

```typescript
export function processCitationMarkers(
  text: string,
  sources: SourceReference[]
): {
  processedText: string;
  citations: Citation[];
} {
  // If no sources provided, return original text with empty citations
  if (!sources || sources.length === 0) {
    return {
      processedText: text,
      citations: []
    };
  }

  // Regex to find citation markers like [1], [2], etc.
  const citationRegex = /\[(\d+)\]/g;
  
  // Track all citations (avoid duplicates)
  const citationMap = new Map<string, SourceReference>();
  
  // Find all citation markers in the text
  let match;
  while ((match = citationRegex.exec(text)) !== null) {
    const id = match[1];
    const sourceIndex = parseInt(id, 10) - 1;
    
    // Only add citation if source exists at the given index
    if (sources[sourceIndex]) {
      citationMap.set(id, sources[sourceIndex]);
    }
  }
  
  // Convert the map to citations array
  const citations: Citation[] = [];
  citationMap.forEach((source, id) => {
    citations.push({
      id,
      source,
    });
  });
  
  return {
    processedText: text,
    citations,
  };
}
```

#### Prompt Enhancement

The system prompt is enhanced with citation instructions:

```typescript
export function enhancePromptWithCitationInstructions(systemPrompt: string): string {
  const citationInstructions = `
When stating facts or making claims, include citation markers in square brackets [1], [2], etc.
Each citation should reference a credible source from your knowledge base.
Place the citation marker immediately after the relevant claim.
Ensure each citation is relevant and correctly numbered starting from [1].
Only cite reliable sources that actually exist.`;

  return `${systemPrompt}\n\n${citationInstructions}`;
}
```

### 3. UI Components

The `CitationFooter` component displays citations in a collapsible section:

```tsx
export function CitationFooter({ citations, className }: CitationFooterProps) {
  const [isExpanded, setIsExpanded] = useState(false);

  // If no citations, don't render anything
  if (!citations || citations.length === 0) {
    return null;
  }

  return (
    <div className={cn("mt-2 pt-2 border-t border-gray-200 dark:border-gray-700", className)}>
      <Button
        variant="ghost"
        size="sm"
        className="flex items-center gap-1 mb-1 text-xs font-medium text-muted-foreground hover:text-foreground"
        onClick={() => setIsExpanded(!isExpanded)}
      >
        {isExpanded ? (
          <>
            <ChevronUp className="h-3 w-3" />
            Hide Sources ({citations.length})
          </>
        ) : (
          <>
            <ChevronDown className="h-3 w-3" />
            Show Sources ({citations.length})
          </>
        )}
      </Button>
      
      {isExpanded && (
        <div className="space-y-2 pl-2 text-xs">
          {citations.map((citation) => (
            <div key={citation.id} className="flex flex-col">
              <div className="flex items-baseline">
                <span className="font-semibold mr-1">[{citation.id}]</span>
                <span className="font-medium">{citation.source.title}</span>
              </div>
              
              <div className="text-muted-foreground text-xs ml-4 flex flex-col">
                {/* Source details... */}
              </div>
            </div>
          ))}
        </div>
      )}
    </div>
  );
}
```

## Process Flow

### 1. Expert Knowledge Retrieval

When a debate is initiated, we retrieve background knowledge for each expert:

```typescript
async function retrieveBackgroundKnowledgeForExperts(debateId: string, experts: Expert[], topic: string) {
  // For each expert:
  // 1. Retrieve background knowledge
  const backgroundKnowledge = await retrieveBackgroundKnowledge(expert, topic);
  
  // 2. Extract source references
  const sourceReferences = await extractSourceReferences(backgroundKnowledge, topic);
  
  // 3. Store with the expert
  expert.backgroundKnowledge = backgroundKnowledge;
  expert.sourceReferences = sourceReferences;
  
  // 4. Update the database
  // ...
}
```

### 2. Response Generation with Citations

When generating responses, the system prompt is enhanced with citation instructions:

```typescript
// Create the base system prompt
let systemContent = `You are ${expert.name}, a ${expert.stance} expert...`;

// Enhance with citation instructions
systemContent = enhancePromptWithCitationInstructions(systemContent);

// Generate response
const completion = await openai.chat.completions.create({
  // ...
  messages: formattedMessages,
});
```

### 3. Citation Processing in the Client

When a message is added to the UI, citations are processed:

```typescript
// In DebatePanel.tsx
addMessage({
  id: messageId,
  role: 'assistant',
  content: response,
  speaker: expertName,
  // ...
});

// Process citations
useDebateStore.getState().processCitationsInMessage(messageId);
```

The store provides a method to process citations:

```typescript
// In store.ts
processCitationsInMessage: (messageId) => set((state) => {
  // Find the message and expert
  const msgIndex = state.messages.findIndex(m => m.id === messageId);
  if (msgIndex === -1) return state;
  
  const message = state.messages[msgIndex];
  if (message.hasProcessedCitations || message.role !== 'assistant') return state;
  
  const expert = state.experts.find(e => e.name === message.speaker);
  if (!expert || !expert.sourceReferences) return state;
  
  // Process the citations
  const { processedText, citations } = processCitationMarkers(
    message.content, 
    expert.sourceReferences
  );
  
  // Update the message
  const updatedMessages = [...state.messages];
  updatedMessages[msgIndex] = {
    ...message,
    content: processedText,
    citations,
    hasProcessedCitations: true
  };
  
  return { messages: updatedMessages };
})
```

### 4. Citation Rendering in the UI

The `MessageBubble` component displays citations:

```tsx
// In MessageBubble.tsx
return (
  <div className="...">
    {/* Expert information and message content... */}
    <p className="text-sm whitespace-pre-wrap">{message.content}</p>
    
    {/* Citations */}
    {showCitations && message.citations && message.citations.length > 0 && (
      <CitationFooter citations={message.citations} />
    )}
  </div>
);
```

## User Experience

From the user's perspective:

1. The user starts a debate on a topic
2. Experts provide responses with citation markers [1], [2], etc.
3. Below each expert message, a "Show Sources" button appears
4. Clicking the button reveals the sources, with options to view more details
5. Sources may include titles, authors, publication dates, and links to external resources

## Future Enhancements

Potential improvements to the citation system:

1. **Citation Highlighting**: Highlight the specific text that corresponds to each citation
2. **Citation Quality Indicators**: Add visual indicators for source credibility
3. **Source Verification**: Integrate with external fact-checking APIs
4. **Cross-referencing**: Allow citations to reference sources from other experts
5. **Citation Search**: Enable users to search for specific cited claims or sources
6. **Citation Export**: Let users export citations in academic formats (APA, MLA, etc.)
7. **Citation Filtering**: Allow users to filter debates to show only claims with citations

## Technical Considerations

### Performance

- Citation processing happens client-side to avoid modifying the original LLM response
- Source references are cached to avoid repeated retrieval
- The UI uses a collapsible design to minimize visual clutter

### Reliability

- The system gracefully handles missing sources or invalid citation markers
- Source extraction uses a lower temperature setting for more reliable results
- The cache prevents repeated extraction of the same information

### Accessibility

- Citation markers are clearly visible in square brackets
- The citation footer is keyboard accessible
- Source information includes text alternatives for non-text content
</file>

<file path="docs/greatdebate.code-workspace">
{
	"folders": [
		{
			"path": ".."
		}
	],
	"settings": {}
}
</file>

<file path="docs/langchain-integration.md">
# LangChain Integration for Great Debate

This document outlines the implementation details, usage, and future roadmap for the LangChain integration in the Great Debate application.

## Overview

The LangChain integration enhances the debate experience by providing:

1. **Knowledge retrieval** - Background information for experts based on their stance and expertise
2. **Fact checking** - Verification of claims made during debates
3. **Context management** - Tracking conversation flow, extracting key points, and maintaining speaker turns

## Integration Components

### 1. Configuration (`src/lib/langchain-config.ts`)

Central configuration for LangChain integrations including:
- API key management
- Model configuration (temperature, token limits)
- Agent settings (caching, thresholds, etc.)
- Debug and test options

### 2. Agent Modules

#### Knowledge Retrieval (`src/lib/agents/knowledge-retrieval.ts`)

Provides experts with relevant background information on debate topics:
- Retrieves tailored knowledge based on expert stance (pro/con)
- Considers expert background and areas of expertise
- Implements caching for performance optimization
- Extracts source references for citation

#### Fact Checking (`src/lib/agents/fact-checking.ts`)

Evaluates factual claims made during debates:
- Assesses claims against known facts and evidence
- Provides accuracy ratings (true, false, partially true, uncertain)
- Explains reasoning behind assessments
- Extracts claims from messages for checking

#### Context Management (`src/lib/agents/context-management.ts`)

Manages debate context across multiple turns:
- Tracks turn history and speaker sequence
- Extracts and stores key points from expert messages
- Records user questions for follow-up
- Generates summaries of current debate state
- Determines which expert should speak next
- Simulates "thinking" for more natural conversation flow

### 3. UI Components

#### Thinking Indicator (`src/components/ThinkingIndicator.tsx`)

Provides visual feedback when experts are "thinking":
- Animated indicator with customizable appearance
- Shows which expert is currently generating a response
- Improves perceived intelligence and responsiveness

### 4. Testing and Development

#### Integration Tests (`src/lib/agents/test-integration.ts`)

Comprehensive tests for each agent functionality:
- Knowledge retrieval testing
- Fact checking testing
- Context management testing
- Configurable test options

#### Test API Endpoint (`src/app/api/test-agents/route.ts`)

API route for running and verifying integration tests:
- Accepts test configuration via POST requests
- Returns detailed test results
- Only available in development mode

## How It Works

### Debate Flow with LangChain

1. **Debate Creation:**
   - User selects a topic and creates a new debate
   - System initializes debate context
   - LangChain selects appropriate experts based on topic

2. **Expert Background:**
   - Knowledge retrieval agent gathers relevant information for each expert
   - Information is tailored to expert's stance and expertise
   - Background knowledge is stored in expert context

3. **Conversation Flow:**
   - Context management tracks turn history
   - ThinkingIndicator component shows when expert is generating a response
   - System determines which expert should respond next

4. **Response Generation:**
   - Expert generates a response using their background knowledge
   - Response is analyzed to extract key points
   - Fact checking evaluates claims in the response
   - Context is updated with new information

5. **User Interaction:**
   - User questions are extracted and stored
   - Experts can address specific questions or continue the debate

## Implementation Details

### API Changes

The LangChain integration modifies the following API endpoints:

1. **`/api/debate`**: Enhanced with LangChain agents for improved response generation
2. **`/api/experts`**: Updated to include background knowledge retrieval
3. **NEW - `/api/test-agents`**: For testing LangChain integration

### Data Model Changes

1. **Expert Interface**: Added `backgroundKnowledge` field for storing retrieved information
2. **DebateContext Interface**: Enhanced with tracking for turn history, questions, and key points
3. **Message Interface**: Added support for fact-checking and source references

## Testing the Integration

### Running Integration Tests

1. Start the development server:
   ```
   npm run dev
   ```

2. Test the integration via the API:
   ```
   curl -X POST http://localhost:3000/api/test-agents \
     -H "Content-Type: application/json" \
     -d '{"topic": "climate change", "testType": "all", "verbose": true}'
   ```

3. Check the test results in the console and API response

### Manual Testing

1. Create a new debate on any topic
2. Observe the ThinkingIndicator while responses are generated
3. Note the quality and relevance of expert responses
4. Check for improved coherence in multi-turn conversations

## Future Improvements

1. **Source Citation**: Enhance knowledge retrieval with real-time web search
2. **Real-time Fact Checking**: Visual indicators for claim accuracy during debates
3. **Enhanced Memory**: Long-term memory for recurring debate topics and themes
4. **Multilingual Support**: Expand to support debates in multiple languages
5. **User Feedback Loop**: Incorporate user feedback to improve agent responses

## Troubleshooting

### Common Issues

1. **API Key Errors**: Ensure OPENAI_API_KEY is properly set in environment variables
2. **Rate Limiting**: Implement backoff strategy for OpenAI API calls
3. **Slow Responses**: Adjust token limits and caching settings in config
4. **Inaccurate Responses**: Fine-tune temperature and other model parameters

## Conclusion

The LangChain integration significantly enhances the Great Debate application by providing more intelligent, coherent, and factual debate experiences. The modular architecture allows for easy extension and maintenance of different agent capabilities.

## Resources

- [LangChain Documentation](https://js.langchain.com/docs/)
- [OpenAI API Documentation](https://platform.openai.com/docs/api-reference)
- [Next.js Documentation](https://nextjs.org/docs)
</file>

<file path="docs/Potential-issues.md">
# Potential Issues and Limitations

## API Limitations

### OpenAI (GPT-4)
- **Rate Limits**: 
  - Default tier: 200 requests per minute
  - Can lead to 429 errors during high usage
  - Need proper error handling and retry logic
- **Token Usage**:
  - GPT-4 has 8K/32K context window limits
  - Long debates may hit token limits
  - Costs increase significantly with context length
  - Need strategy for context pruning in long debates
- **Cost Management**:
  - GPT-4 costs $0.03/1K tokens for output
  - Need usage caps and monitoring
  - Consider implementing user quotas

### ElevenLabs
- **Rate Limiting**:
  - Free tier: 10,000 characters per month
  - Need to handle rate limit errors gracefully
- **Voice Generation Time**:
  - Can take 15-30 seconds per response
  - Users may perceive as system being slow
  - Need clear loading states
- **Cost Considerations**:
  - $0.30 per 1,000 characters
  - Long debates can become expensive
  - Need character count monitoring

## Database Concerns

### Scalability
- **Document Size**:
  - Debate transcripts can grow large
  - Need efficient storage strategy
  - Consider pagination or chunking
- **Query Performance**:
  - Complex debate queries may be slow
  - Need proper indexing strategy
  - Consider caching frequently accessed data

### Data Management
- **Storage Limits**:
  - Free tiers often have storage caps
  - Need cleanup strategy for old debates
  - Consider data archival process
- **Backup Strategy**:
  - Regular backups needed
  - Consider point-in-time recovery
  - Handle partial debate recovery

## Frontend Challenges

### State Management
- **Complex State**:
  - Multiple experts, messages, and audio states
  - Need careful state organization
  - Consider using state machines
- **Race Conditions**:
  - Async operations can conflict
  - Need proper loading states
  - Handle concurrent user actions

### Performance
- **Memory Usage**:
  - Audio blobs can consume significant memory
  - Need cleanup strategy
  - Consider streaming for long audio
- **Bundle Size**:
  - Dependencies can bloat bundle
  - Need code splitting
  - Consider lazy loading components

### Browser Limitations
- **Audio Playback**:
  - Mobile browsers have autoplay restrictions
  - Need user interaction for playback
  - Handle audio context limitations
- **LocalStorage**:
  - Limited to 5-10 MB
  - Need strategy for large debates
  - Consider IndexedDB for larger storage

## Security Considerations

### API Keys
- **Key Protection**:
  - Must secure API keys
  - Use environment variables
  - Implement proper key rotation
- **Usage Monitoring**:
  - Track API key usage
  - Implement alerts for unusual activity
  - Have revocation process

### User Data
- **Privacy**:
  - Handle user data responsibly
  - Clear data retention policies
  - Implement proper data encryption
- **Content Moderation**:
  - Need strategy for inappropriate content
  - Consider content filtering
  - Have reporting mechanism

## Network Issues

### Connection Handling
- **Intermittent Connectivity**:
  - Handle network interruptions
  - Implement retry logic
  - Save debate progress locally
- **Large Payloads**:
  - API responses can be large
  - Need compression strategy
  - Consider chunked transfers

### Timeouts
- **Long Operations**:
  - API calls can be slow
  - Need proper timeout handling
  - Consider background processing

## User Experience

### Response Times
- **Perceived Performance**:
  - Voice generation is slow
  - Need clear progress indicators
  - Consider generating voices in parallel
- **Error Communication**:
  - Clear error messages needed
  - User-friendly error recovery
  - Maintain debate state during errors

### Resource Usage
- **Battery Impact**:
  - Audio processing can drain battery
  - Need efficient audio handling
  - Consider power-saving modes
- **Data Usage**:
  - Audio files can be large
  - Need compression strategy
  - Consider offline mode

## Maintenance Challenges

### Version Control
- **API Changes**:
  - OpenAI/ElevenLabs APIs evolve
  - Need version compatibility checks
  - Have fallback mechanisms
- **Database Migrations**:
  - Schema changes need careful handling
  - Need migration strategy
  - Consider backward compatibility

### Monitoring
- **Error Tracking**:
  - Need comprehensive logging
  - Monitor API usage/costs
  - Track user experience metrics
- **Performance Metrics**:
  - Track response times
  - Monitor resource usage
  - Set up alerting system

## Mitigation Strategies

### General Approaches
1. Implement robust error handling
2. Use retry mechanisms with exponential backoff
3. Implement proper logging and monitoring
4. Have clear user communication
5. Implement proper testing strategy
6. Regular security audits
7. Performance optimization routine

### Specific Solutions
1. Implement debouncing for API calls
2. Use caching where appropriate
3. Implement proper cleanup routines
4. Have clear escalation paths
5. Regular dependency updates
6. Automated testing pipeline
7. Regular security scans
</file>

<file path="docs/RAG-Implementation.md">
# Retrieval-Augmented Generation (RAG) Implementation

This document outlines the implementation of Retrieval-Augmented Generation (RAG) in the Debate-Aible application, which enables factual responses based on uploaded documents.

## Implementation Overview

The RAG implementation consists of the following components:

1. **Document Processor** (`src/lib/ai/document-processor.ts`)
   - Handles PDF text extraction
   - Splits text into chunks
   - Generates embeddings
   - Stores vectors in Pinecone
   - Retrieves relevant content for queries

2. **Analyze API Route** (`src/app/api/analyze/route.ts`)
   - Processes uploaded documents
   - Extracts topics
   - Stores document chunks in the vector database
   - Returns a unique debateId linked to the document

3. **Response Generator** (`src/lib/ai/response-generator.ts`)
   - Retrieves relevant content from the vector database
   - Incorporates this content into the system prompt
   - Generates responses that are grounded in the document content

4. **Debate API Route** (`src/app/api/debate/route.ts`)
   - Passes the debateId to the response generator
   - Maintains the connection between debates and their source documents

## Potential Issues and Considerations

### 1. Error Handling and Fallbacks

The implementation includes error handling to ensure that the application continues to function even if:
- Pinecone is not properly configured
- Document processing fails
- Content retrieval fails

In these cases, the system falls back to standard AI responses without document grounding.

### 2. Mock Implementation for Development

A mock implementation is provided for development environments where Pinecone is not available. This uses:
- In-memory storage for document chunks
- Simple keyword matching for retrieval

To use this, set `USE_MOCK_DATA=true` in your environment variables.

### 3. Performance Considerations

- **Initial Processing**: Processing large documents may take time, especially for the initial embedding generation.
- **API Costs**: Each embedding generation and AI completion incurs OpenAI API costs.
- **Vector Database Costs**: Pinecone has usage-based pricing that should be monitored.

### 4. Integration with Existing Components

The RAG implementation is designed to work alongside existing functionality:
- It preserves the debate flow and UI
- It maintains compatibility with Firebase and Redis storage
- It doesn't interfere with voice synthesis or other features

## Future Improvements

1. **Chunking Strategy**: Implement more sophisticated chunking strategies (e.g., semantic chunking) for better retrieval.

2. **Hybrid Search**: Combine vector search with keyword search for improved retrieval accuracy.

3. **Document Management**: Add UI for viewing, managing, and deleting uploaded documents.

4. **Multi-Document Support**: Allow multiple documents to be associated with a single debate.

5. **Caching**: Implement caching of embeddings and retrieved content to reduce API costs.

6. **Feedback Loop**: Add user feedback mechanisms to improve retrieval quality over time.

7. **Alternative Vector Databases**: Add support for other vector databases like Weaviate, Qdrant, or Supabase pgvector.

## Testing the Implementation

To test the RAG implementation:

1. Configure Pinecone credentials in your `.env.local` file
2. Upload a PDF document through the UI
3. Start a debate using a topic extracted from the document
4. Ask questions related to the document content
5. Verify that the responses include information from the document

If you encounter any issues, check the console logs for error messages related to document processing or content retrieval.

### Setup for Document-Based Responses

To enable this feature, you need to:

1. Create a Pinecone account at [pinecone.io](https://www.pinecone.io/)
2. Create a new index with the following settings:
   - Dimensions: 1024 (for OpenAI embeddings)
   - Metric: Cosine
   - Pod Type: Starter (for development)
3. Add your Pinecone API key, environment, and index name to your `.env.local` file:
   ```
   PINECONE_API_KEY=your_pinecone_api_key
   PINECONE_ENVIRONMENT=gcp-starter
   PINECONE_INDEX=debate-documents
   ```
</file>

<file path="docs/README.md">
### The Great Debate Notebook
*(Mashup: AI Debate + Famous Experts + Intellectual Sparring Partner)*
**Concept:**Instead of just writing notes, users engage in **AI-generated debates with historical or modern experts** who would best understand the topic. The app presents **two famous figures arguing different sides**, turning note-taking into a **dynamic intellectual battle**.

### How It Works:
**1** **Enter Your Idea or Topic**
	* Example: *“Is artificial intelligence a threat or a tool for progress?”*
	* The app scans the **core question** and finds two historical or contemporary figures to debate the topic.
**2** **AI Assigns Debaters**
	* Example Matchup:
		* **Alan Turing** (pro-AI, innovation, potential for human betterment)
		* **Elon Musk** (concerned about AI risks, advocates AI regulations)
**3** **Debate Begins**
	* The AI-generated **debate plays out dynamically**, with each thinker presenting arguments based on their real-life views and writings.
	* **You can interject**, asking follow-up questions, challenging them, or even taking a side yourself.
**4** **Live Debate Adjustments**
	* The **tone and complexity** adjust based on your knowledge level—beginner-friendly explanations or deep philosophical dives.
	* If you **change positions**, the debaters react, forcing you to rethink ideas.
**5** **Summarization & Critical Thinking Exercise**
	* The app **summarizes key arguments** for both sides.
	* It then asks: *“Which side convinced you most, and why?”*
	* Users can **synthesize their own conclusions** and keep them as evolving notes.

⠀
### Use Cases & Applications
**1. Supercharged Critical Thinking**
* Forces you to **see both sides** of an issue before forming an opinion.
* Helps break **confirmation bias**, exposing users to viewpoints they wouldn’t normally consider.

⠀**2. Academic & Learning Enhancement**
* Ideal for **students studying philosophy, politics, ethics, and history**.
* Example: *Should we have universal basic income?* → Debate between **Karl Marx and Milton Friedman**.

⠀**3. Writing & Idea Refinement**
* Great for **authors, debaters, and thinkers** refining an argument for an essay or book.
* Example: *Would Shakespeare approve of AI-generated poetry?* → Debate between **Shakespeare and an AI model**.

⠀**4. Creative Problem-Solving**
* Can be applied to **business strategy, technology, or future trends**.
* Example: *What’s the best way to colonize Mars?*
  * **Elon Musk (Pro-Colonization)** vs. **Carl Sagan (Cautionary Approach)**

⠀**5. Entertainment & Fun Debates**
* Casual debates for fun, like:
  * **Plato vs. Nietzsche** → "Is happiness the goal of life?"
  * **Marie Curie vs. Elon Musk** → "What’s the most important scientific discovery ever?"
  * **Einstein vs. Da Vinci** → "What’s more important—art or science?"

⠀
### Potential Features to Expand It Further
✅ **Debate Customization**
* Choose **tone**: Formal, sarcastic, aggressive, playful.
* Adjust **depth**: Simple explanations or technical deep dives.

⠀✅ **Historical vs. Modern Matchups**
* Can match a **historical figure vs. a modern thinker** (e.g., *Socrates vs. Steve Jobs on creativity*).

⠀✅ **Multiplayer Mode**
* Invite friends to **join the debate**, taking different sides.

⠀✅ **Memory Mode**
* AI remembers previous debates, tracking how your **opinion evolves over time**.

⠀✅ **User-Defined uploads**
* User can upload PDFs as support material to debate **Each debator takes a side**.

⠀✅ **Closer to real time material**
* User can ask it to scan more recent material on the web **Access Twitter, X, Perplexity etc**.

⠀
### The Big Picture: Why This Is Revolutionary
* **Turns note-taking into an interactive thought exercise.**
* **Merges learning with entertainment, making philosophy, science, and politics more engaging.**
* **Challenges users to think deeply instead of passively consuming information.**

⠀
### ### The Ultimate Debate-Enhanced Note-Taking & Knowledge Curation App
*(Merging Note-Taking, Bookmarking, and AI Debates in an Interactive, Multi-Format Learning System)*

### 🎯 The Core Idea:
A **next-gen note-taking app** that **ingests** all forms of saved content (text notes, bookmarks, voice recordings, podcast snippets, YouTube videos, tweets, PDFs) and **automatically generates a debate** around the key ideas—offering two opposing expert perspectives in **real-time voice simulation** using AI-generated voices (e.g., ElevenLabs).
The user can:✔️ **Express their own opinion** (text or voice).✔️ **Receive two opposing viewpoints** (generated by AI & voiced by famous experts or intellectuals).✔️ **Engage in a real-time voice-based discussion** with historical or modern thinkers.✔️ **Build structured knowledge from their content consumption.**

# 🖥️ The UI & Workflow: How It Works
### 1️⃣ Capture & Organize Input Sources
Users can input or save:📌 **Text Notes** – Written reflections, summaries, or ideas.📌 **Bookmarks** – Saved articles, X (Twitter) threads, Readwise highlights, Medium posts.📌 **Voice Notes** – Quick thoughts recorded directly in the app.📌 **Snippets from Podcasts & YouTube** – Highlight specific segments using timestamps.
Each captured idea is tagged by **topic, source, and sentiment** (positive/neutral/negative stance).

### 2️⃣ User Defines Their Stance
* Users enter a short **opinion or hypothesis** in text or voice.
* Example: *"I think AI will replace many creative jobs but create new industries."*
* The system **analyzes the key argument** and **detects nuances** in the user’s stance.

⠀
### 3️⃣ AI Generates Two Expert Opposing Views
* AI selects two **counterbalancing figures**—one **aligned** with the user’s stance and one **opposed**.
* Generates **coherent counterarguments** rooted in **real-life quotes, writings, and expert knowledge**.
* Experts are voiced in **real-time audio using ElevenLabs or a similar AI voice platform**.

⠀**🎤 Example AI-Generated Debate**
(*User: “I believe AI will replace many creative jobs but create new industries.”*)
🗣️ **Alan Turing (Pro-AI Revolution):***"AI has already proven its ability to enhance human creativity rather than replace it. Just as the printing press expanded literature, AI will amplify creative potential."*
🗣️ **Jaron Lanier (AI Skeptic & Digital Humanist):***"This is a dangerous assumption. AI-generated content is derived from past human work—it doesn’t create from scratch. The real risk is that it commodifies art and weakens human originality."*
🔊 **Real-time playback allows users to pause, rewind, or explore deeper counterarguments.**

### 4️⃣ Interactive Debate & Refinement
✔️ **User can ask follow-ups**: *“What about job loss in journalism?”*✔️ **AI dynamically adjusts the debate**: *Now, Noam Chomsky joins to discuss AI’s impact on free speech.*✔️ **Users can switch sides** at any point to **see how their argument holds up**.✔️ **Personalized insights** summarize **what changed the user’s perspective** over time.

### 5️⃣ Integrated Knowledge Graph & Summarization
* **Every debate session is saved** as a **living knowledge graph**.
* Users can **see how their ideas evolve**, compare past perspectives, and **track argument strength**.
* Automatic **TL;DR summaries** provide:
  * ✅ Key arguments for & against.
  * ✅ Thought-provoking follow-up questions.
  * ✅ Suggested **further reading (book links, articles, YouTube videos)**.

⠀
# 🎛️ UI & Navigation: Best UX Approach
### 📌 Sidebar Panel for Quick Captures
✅ Add **notes, voice snippets, bookmarks** from any app with a **floating quick-save button** (à la Readwise Reader).✅ **Auto-organized library** of saved ideas, categorized by **theme, sentiment, and relevance**.✅ **Filter by argument strength**—see which ideas generated the best counterpoints.

### 📜 Debate Mode Interface: Immersive & Dynamic
* The **main screen** shows the debate:
  * 🎤 **Your argument (centered)**.
  * 🗣️ **Expert #1 (Left, Pro-side)**.
  * 🗣️ **Expert #2 (Right, Counterargument).**
* Tap **“Deepen Discussion”** to introduce additional experts.
* **Playback controls** allow pausing, jumping to key rebuttals, or requesting simpler explanations.

⠀🎭 **Optional "Theatrical Mode"**: AI generates full **philosophical dialogues** à la Plato’s **Socratic Dialogues**.

# 🔮 Why This is a Game-Changer
✔️ **Transforms passive knowledge consumption into active debate.**✔️ **Eliminates echo chambers** by exposing users to opposing views.✔️ **Perfect for students, journalists, and deep thinkers.**✔️ **Encourages users to refine arguments through real-time, voice-driven dialectics.**

# ### Refining the AI’s Knowledge Engine for Authentic Expert Responses
For this app to be **truly valuable**, the AI needs to generate **highly authentic** expert responses that feel **coherent, nuanced, and historically or factually accurate**—not just generic AI summaries. Here’s how we can refine the **AI’s knowledge engine** to ensure **credibility, accuracy, and engaging debate quality**.

# 🧠 How the AI Constructs Expert Responses
To generate expert-level arguments that sound *real* and *contextually accurate*, we need a **multi-layered knowledge system** with **real-time validation**. Here’s the **framework**:
### 1️⃣ Layered Data Sources for Debate Generation
To make **each expert’s argument feel true to their real-life beliefs**, the AI will reference multiple **verified sources**:
* **📖 Primary Sources**: Books, essays, academic papers by the expert.
* **📰 Context-Specific References**: Interviews, public debates, blog posts.
* **📜 Philosophical & Political Writings**: Foundational arguments from history.
* **🎙️ Speech & Voice Archives**: Transcripts of actual speeches (e.g., TED Talks, historic addresses).
* **📡 Real-Time Web Crawling (Optional)**: Fetches the latest references if a topic is evolving (e.g., AI ethics, climate change).

⠀🔹 **Example:** If the debate is on *"Should universal basic income (UBI) exist?"*, the AI would pull from:
* 📖 **Primary Source**: Andrew Yang’s UBI proposal.
* 📜 **Historical Context**: Keynes on automation & job loss.
* 📰 **Counterarguments**: Milton Friedman’s writings on free markets.

⠀Each argument would be **structured in the debater’s real voice and ideology**, rather than sounding like generic AI synthesis.

### 2️⃣ Expert Persona Modeling – Keeping Debates Authentic
The AI needs to **simulate** famous thinkers **as if they were actually speaking**. To do this, it will:
✅ **Use their actual sentence structure & vocabulary.**
* Einstein’s responses should be **thoughtful, exploratory, scientific**.
* Nietzsche’s responses should be **bold, provocative, aphoristic**.
* Elon Musk’s arguments should **lean toward technology optimism, market-driven solutions**.

⠀✅ **Incorporate their well-known beliefs & biases.**
* If debating AI, Alan Turing should reference **his work on computing and intelligence**.
* If debating capitalism, Karl Marx should lean into **his critique of labor and class struggle**.

⠀✅ **AI Style Transfer for Voice Consistency.**
* Uses **fine-tuned LLMs** to keep responses **tonally consistent** with real historical writing styles.
* Example: Nietzsche’s **hyperbolic and poetic style** vs. Bertrand Russell’s **calm, structured logic**.

⠀
### 3️⃣ Real-Time Fact Validation (Avoiding Hallucinations)
Since **AI can sometimes generate false information**, we introduce **real-time knowledge verification**:
**1** **Pre-Debate Accuracy Check**
	* Before generating responses, AI checks its **sources against real writings**.
	* Flags **uncited claims** and searches for a **real quote, example, or reference**.
**2** **Fact-Level Transparency for Users**
	* The app highlights **where each claim comes from** (e.g., *Plato’s "Republic", Ch.5*).
	* Users can **tap a claim** and see the **original source**.
**3** **User-Guided Rebuttal Requests**
	* If a response **feels off**, users can ask: *"Would this expert have really said that?"*
	* The AI **self-audits** and offers a **fact-checked revision**.

⠀
### 4️⃣ Dynamic Multi-Expert Expansion
The AI can **expand the debate dynamically** by:
✅ **Introducing New Perspectives Mid-Debate**
* Example: If Elon Musk & Alan Turing are debating AI, the AI might **pull in Jaron Lanier** as a wildcard **AI ethics critic**.

⠀✅ **Historical vs. Modern Matchups**
* Lets users **pit different eras against each other** (e.g., *Socrates vs. Sam Harris on ethics*).

⠀✅ **Cross-Domain Experts**
* On a topic like AI, the AI might **expand beyond computer scientists** to **psychologists, artists, and philosophers**.

⠀
### 5️⃣ Realistic, Dynamic Debate Tone Adjustments
Instead of **one-size-fits-all debates**, the AI adapts:
✔️ **Academic Style** – Formal, structured, citation-backed.✔️ **Casual Debate** – Witty, conversational, Socratic.✔️ **Intense Argument** – More aggressive, rapid back-and-forth.✔️ **Historical Accuracy Mode** – Uses only **verified real-world statements**.
Users can **switch debate styles** at any time.

# 🚀 Why This is Groundbreaking
✔️ **Moves beyond generic AI debates into deeply researched, expert-level discussions.**✔️ **Simulates high-level discourse that would never happen in real life (e.g., Aristotle debating quantum physics).**✔️ **Enhances knowledge-building, critical thinking, and intellectual engagement.**✔️ **Provides high-quality, fact-checked arguments in real-time—better than reading 100 opinion articles.**

# ### 📌 Prototype Outline & UX Flow for the AI-Powered Debate Notebook
*(A seamless, interactive system for note-taking, debating, and structured idea refinement.)*
This prototype focuses on **capturing knowledge from multiple sources, synthesizing arguments, and generating AI-driven debates** in a **visually intuitive** and **voice-powered** interface.

# 🖥️ Main Screens & UX Flow
### 1️⃣ Capture & Organize Knowledge Sources
💡 **Entry Points:**
* 📝 **Text Notes** (Manual entries or summaries)
* 📌 **Bookmarks** (X/Twitter, Readwise, Medium, PDFs, articles)
* 🎙️ **Voice Notes** (Quick idea recordings)
* 🎧 **Podcast & YouTube Snippets** (Timestamped highlights)

⠀🔹 **UI Layout:**
* **Left Sidebar**: Saved Topics (organized by tags, recency, and importance).
* **Main Panel**: **User’s Current Thought / Opinion** (editable field where they write or record their stance).

⠀🔹 **Action Buttons:**✅ **“Extract Debate Topic”** → AI processes the user’s saved notes & selects debatable points.✅ **“Quick Debate”** → Instant AI counterarguments from famous thinkers.✅ **“Deep Dive”** → Structured multi-layered debate simulation.

### 2️⃣ Define Your Position (User Stance Entry)
* The user **enters their viewpoint** as text or voice.
* AI **analyzes sentiment** and **breaks down argument structure**.
* The system **suggests refinements**, asking:
  * *"Do you want to make this more specific?"*
  * *"What key supporting facts do you want included?"*

⠀🔹 **UI Layout:**
* **Top Bar:** Displays "Your Perspective."
* **Main Panel:** Live editable **argument editor** with AI suggestions.
* **Quick Toggle:** *Formal vs. Conversational Mode* (adjusts complexity & tone).

⠀✅ **“Preview Opposing Arguments”** → AI suggests **2 opposing views with expert profiles** before launching the debate.

### 3️⃣ AI-Generated Debate Simulation (Core Feature)
💬 **The Debate Panel:**
* AI generates **two opposing perspectives** in **real-time voice (via ElevenLabs or similar AI voice synthesis)**.
* Arguments are structured as a **spoken dialogue**, playable in **voice or text format**.
* The UI **mimics a live conversation**, visually highlighting each speaker's **tone, emotion, and reasoning style**.

⠀🔹 **UI Layout:**📌 **Left Panel**: **Your stance (editable)**.📌 **Middle Panel**: Live **voice-based debate** between **Expert #1 vs. Expert #2**.📌 **Right Panel**: Interactive **fact-checking & sources** for each argument.
✅ **"Pause & Interject"** → The user can jump into the debate at any time.✅ **"Challenge an Argument"** → Forces the AI debaters to respond to a specific question or counterpoint.✅ **"Expand with More Experts"** → Introduces a **third historical thinker** for a new perspective.

### 4️⃣ Interactive Engagement: Refining the Debate
* 🏆 **Scoring System:** The AI **evaluates argument strength**, rating each side based on logical coherence, historical accuracy, and persuasion.
* ✍️ **User Participation:** Users can choose to:
  * *Reinforce* their original stance with stronger supporting evidence.
  * *Switch sides* and argue the **opposite** for deeper critical thinking.
  * *Summarize & Save* key insights from the debate.

⠀🔹 **UI Layout:**📌 **Left Panel**: **Notes & Key Takeaways**.📌 **Main Panel**: Debate **highlights & best arguments**.📌 **Right Panel**: *Score & Impact Analysis* (How did the debate shift perspectives?).
✅ **“Post-Debate Summary”** → AI summarizes:
* 🎯 **What changed in your thinking?**
* 🔍 **What strong points did each side present?**
* 📚 **Recommended Further Reading** (books, research papers, YouTube videos).

⠀
### 5️⃣ Knowledge Graph & Review System
🔹 **Visual Representation of Thought Evolution:**
* A **timeline of debates** shows how the user’s views evolve.
* AI detects **patterns in thinking** (e.g., *“You tend to favor arguments that emphasize technology optimism.”*).
* Users can **revisit old debates** and see if their stance **has changed over time**.

⠀✅ **"Compare Past vs. Present Self"** → Side-by-side view of past arguments vs. new insights.
🔹 **UI Layout:**📌 **Main View**: A **knowledge graph** showing **related debates & evolving opinions**.📌 **Side Panel**: Access to **past notes, rebuttals, and saved arguments**.

# 🎨 UI/UX Features for Seamless Flow
### ✅ Floating Quick Capture Button (Anywhere, Anytime)
* Available **system-wide** for capturing ideas, tweets, articles, or voice memos.
* Sends captured content **directly into the Debate Notebook** for future discussions.

⠀✅ Multi-Device Sync
* Fully **integrated with Readwise, Twitter/X, YouTube, Pocket, Apple Notes, Obsidian**.
* Enables **cross-platform idea curation**, ensuring **seamless recall of past knowledge**.

⠀✅ Voice-Driven Interaction
* Users can **listen to debates hands-free** while commuting.
* “Hey AI, summarize today’s best debates” → AI generates a **5-minute recap**.

⠀
# 🚀 The Big Picture: What Makes This Revolutionary?
✔️ **A dynamic, evolving thought system** → Your opinions don’t just sit in notes; they evolve through interactive debate.✔️ **Brings knowledge to life** → Passive reading turns into **real-time argumentation & dialectics**.✔️ **Kills echo chambers** → Encourages users to engage with opposing views in a constructive, structured way.✔️ **Enhances deep learning & self-reflection** → Tracks **how thinking patterns evolve over time**.

### ### 📌 Development Breakdown: Building the AI-Powered Debate Notebook in Stages
*(Structured roadmap for integrating Next.js 15, Cursor AI IDE, and GitHub.)*
This will be built in **stages**, ensuring **modularity, scalability, and integration efficiency**. Each stage will produce a **usable, independent component** that can later be merged into a full system.

# 🛠️ Phase 1: Core System Setup & Note Capture (MVP)
**Goal:** Establish the **basic note-taking and knowledge capture** system before integrating AI debates.
✅ **1. Next.js 15 Project Setup**
* Create a **Next.js 15 app** (npx create-next-app@latest).
* Set up **TypeScript, ESLint, Prettier**.
* Configure **Tailwind CSS** or Chakra UI for styling.
* Initialize **GitHub repo** for version control.

⠀✅ **2. Build the Note-Taking & Capture System**
* **Text Input**: Simple markdown-based editor (react-markdown or lexical).
* **Voice Notes**: Integrate browser-based **speech-to-text API** for dictation.
* **Bookmark Manager**:
  * Save articles, X/Twitter posts (API integration later).
  * Store YouTube links, podcast timestamps.

⠀✅ **3. Database & API Setup**
* Use **Supabase (Postgres)** for note storage.
* Set up a **GraphQL or REST API** (/api/notes).
* Implement **CRUD operations** (Add/Edit/Delete Notes).

⠀🔹 **Deliverable:** A functional **note-taking & bookmarking system** with GitHub version tracking.

# 🛠️ Phase 2: AI Debate Engine (Text-Based MVP)
**Goal:** Implement **AI-driven arguments** with a **basic debate flow** (text-only).
✅ **1. AI Debate Model Selection**
* Integrate **OpenAI GPT-4 Turbo** (or local Llama/Claude API).
* Fine-tune prompts for **structured debates**.
* Define **argument framework** (Claim, Rebuttal, Counter-Rebuttal).

⠀✅ **2. Expert Persona Modeling (Simulated Debaters)**
* **Hardcode** initial expert personalities:
  * Example: *Plato, Karl Marx, Elon Musk, Alan Turing, Sam Harris*.
* Use **few-shot prompting** to match writing styles.

⠀✅ **3. Interactive Debate UI**
* **Debate View**:
  * **User Stance (Left Panel)**.
  * **Expert #1 (Middle, Pro-Side)**.
  * **Expert #2 (Right, Counterargument)**.
* Users can **challenge arguments** dynamically.

⠀✅ **4. AI Refinement & Response Tracking**
* Implement **"Challenge an Argument"** → AI generates a **response to a rebuttal**.
* Add **"Expand Debate"** → AI introduces a third expert.

⠀🔹 **Deliverable:** A **functional text-based debate system** that generates expert-level counterarguments.

# 🛠️ Phase 3: Voice AI Integration (ElevenLabs & Real-Time Debates)
**Goal:** Make AI-generated debates **audible & interactive**.
✅ **1. ElevenLabs API for Voice Synthesis**
* Convert **AI-generated text into expert voices**.
* Generate **dynamic debate audios**.
* Implement **"Play Debate" Button**.

⠀✅ **2. Real-Time Voice Interjection**
* Users can **speak a counterargument**, and AI generates **live responses**.
* Use **Whisper AI (speech-to-text)** for user voice input.

⠀✅ **3. Debate History & Playback**
* Save debates to **Supabase** for future review.
* Implement a **"Replay Debate"** function.

⠀🔹 **Deliverable:** A **real-time, voice-driven debate engine** where users can **hear experts argue**.

# 🛠️ Phase 4: Advanced Features & Knowledge Graph
**Goal:** Build **a knowledge evolution system** that **maps ideas over time**.
✅ **1. Debate Evolution Tracking**
* Track **how user opinions change** across debates.
* Implement a **timeline visualization**.

⠀✅ **2. Readwise & X (Twitter) API Integration**
* Fetch **highlights from Readwise** → Convert them into **debatable points**.
* Enable **X/Twitter thread import** for AI-generated discussions.

⠀✅ **3. AI-Generated Summaries & Reports**
* Auto-generate **debate summaries**.
* Provide **further reading suggestions** (books, papers).

⠀🔹 **Deliverable:** A **fully integrated debate-enhanced knowledge system**.

### Potential issues by phase
### 📌 Potential Issues & Solutions for Each Development Phase
*(Anticipating roadblocks & optimizing our build process for smooth development.)*
Each phase presents unique **technical challenges**, so let’s **document potential issues and solutions** proactively. These notes can be added to GitHub issues or documentation as we progress.

# 🛠️ Phase 1: Core System Setup & Note Capture (MVP)
💡 **Main Risks: Database Design, Bookmark Handling, Text & Voice Input Complexity**
### 🔴 Potential Issues & Solutions
✅ **1. Database Performance & Scaling**
* **Issue:** Storing a mix of text, voice, and external links could lead to **scaling bottlenecks**.
* **Solution:**
  * **Use Postgres with Supabase**, with indexing for search optimization.
  * **Store large media files (audio snippets) in cloud storage (Supabase Storage, S3, or Cloudflare R2).**

⠀✅ **2. Handling Different Note Types (Markdown, Audio, Links, YouTube Snippets)**
* **Issue:** Standardizing **diverse input formats** for easy retrieval and editing.
* **Solution:**
  * Convert **YouTube & Podcast snippets into timestamped links**.
  * Use **Lexical (or React Markdown) for rich-text notes**.
  * Implement **a simple voice-to-text integration** from the start.

⠀✅ **3. API Rate Limits (Readwise, Twitter/X, YouTube)**
* **Issue:** External services (Readwise, X API, YouTube API) have rate limits that may **restrict data fetching**.
* **Solution:**
  * **Batch API requests** & cache responses locally.
  * **Optimize sync frequency** (fetch updates periodically instead of every request).

⠀
# 🛠️ Phase 2: AI Debate Engine (Text-Based MVP)
💡 **Main Risks: Ensuring Debate Relevance, Avoiding AI Hallucinations, Maintaining Logical Flow**
### 🔴 Potential Issues & Solutions
✅ **1. AI Generating Unconvincing or Hallucinated Arguments**
* **Issue:** GPT-based models sometimes **make up facts or misrepresent** a thinker’s real stance.
* **Solution:**
  * Restrict AI responses **only to verified sources** (books, speeches, papers).
  * Build a **"Fact Check" button** where users can **flag suspicious claims**.

⠀✅ **2. Making AI Debaters Sound Realistic & Distinct**
* **Issue:** Responses may sound too **generic or GPT-like**, failing to reflect **expert personalities**.
* **Solution:**
  * Fine-tune **prompt engineering for different experts**.
  * Train models on **their actual writings** for style-matching.

⠀✅ **3. Structuring Arguments Clearly**
* **Issue:** AI debates may lack a **logical progression** (jumping from topic to topic).
* **Solution:**
  * Force AI to follow **structured debate formats**:1️⃣ **Opening Claim** → 2️⃣ **Counterargument** → 3️⃣ **Rebuttal** → 4️⃣ **Conclusion**.
  * Use **Graph-Based Argument Mapping** for coherence.

⠀✅ **4. User Interaction With AI Responses**
* **Issue:** Users may feel **passive** in the debate, rather than **engaged**.
* **Solution:**
  * **"Challenge This Argument" Button** → AI must refine its position dynamically.
  * **"Expand With Another Expert" Button** → Introduce a **third counterargument**.

⠀
# 🛠️ Phase 3: Voice AI Integration (ElevenLabs & Real-Time Debates)
💡 **Main Risks: Latency in Speech Processing, AI Sounding Unnatural, Handling User Voice Inputs**
### 🔴 Potential Issues & Solutions
✅ **1. Voice Latency (Speech Synthesis Delays in Real-Time Debates)**
* **Issue:** If ElevenLabs takes too long to generate speech, **debates will feel sluggish**.
* **Solution:**
  * Pre-load expert voice responses **asynchronously in the background**.
  * Implement **a "Quick Debate Summary" option** in text, so users don’t wait.

⠀✅ **2. AI Voices Sounding Too Robotic or Wrong Tone**
* **Issue:** Some AI voices **lack natural inflection** or sound **generic**.
* **Solution:**
  * Fine-tune voice **emphasis and pacing**.
  * Introduce **speech variance** (pauses, excitement levels).

⠀✅ **3. User Voice Input Accuracy (Speech-to-Text Issues)**
* **Issue:** If voice commands **misinterpret user input**, debates become frustrating.
* **Solution:**
  * **Use OpenAI Whisper** for high-accuracy speech-to-text.
  * Allow **manual text corrections after voice input**.

⠀✅ **4. User Interrupting the Debate & Handling Dynamic Responses**
* **Issue:** AI debates are **scripted** but users may want to **jump in** at any moment.
* **Solution:**
  * Implement **an "Interrupt & Respond" button** where users cut into the debate.
  * Use **partial sentence recognition** → AI responds in real time instead of restarting.

⠀
# 🛠️ Phase 4: Advanced Features & Knowledge Graph
💡 **Main Risks: Handling Large Debate History, UI Complexity, Ensuring Searchability**
### 🔴 Potential Issues & Solutions
✅ **1. Handling Long-Term Debate History & Knowledge Evolution**
* **Issue:** Storing and searching **thousands of past debates** efficiently.
* **Solution:**
  * Implement **vector-based search (Pinecone/Weaviate) for semantic retrieval**.
  * Use **graph databases (Neo4j) to visualize argument trees**.

⠀✅ **2. Making Knowledge Graphs Intuitive & Not Overwhelming**
* **Issue:** If the knowledge graph **feels too abstract**, users may not engage.
* **Solution:**
  * Keep UI **simple**: Show **one debate branch at a time**.
  * Auto-generate **TL;DR summaries** → Instead of raw graphs, users get **“Key Insights”**.

⠀✅ **3. Integrating Readwise, X, and YouTube Seamlessly**
* **Issue:** API rate limits may prevent **real-time content syncing**.
* **Solution:**
  * Implement **daily background sync** instead of every request.
  * Let users manually **“Pull Latest Highlights”** to refresh instantly.

⠀✅ **4. Avoiding “Echo Chamber Effect” in AI Debates**
* **Issue:** If AI always selects the same counterarguments, **users may never hear fresh perspectives**.
* **Solution:**
  * Rotate **"wildcard experts"** for unpredictability (e.g., introduce an artist in a tech debate).
  * Let users choose **"Uncommon Perspectives" mode** to receive **unexpected** counterpoints.

⠀
### ### 📌 Potential Issues & Solutions for Each Development Phase
*(Anticipating roadblocks & optimizing our build process for smooth development.)*
Each phase presents unique **technical challenges**, so let’s **document potential issues and solutions** proactively. These notes can be added to GitHub issues or documentation as we progress.

# 🛠️ Phase 1: Core System Setup & Note Capture (MVP)
💡 **Main Risks: Database Design, Bookmark Handling, Note Organization**
### ⚠️ Issue 1: Database Schema Complexity (Notes, Bookmarks, Audio)
* **Problem**: Storing multiple content types (text, voice, bookmarks, YouTube timestamps) in a way that remains **scalable and efficient**.
* **Solution**:✅ Use **Supabase (Postgres)** with a **normalized schema**:
  * notes: Stores text notes.
  * bookmarks: Stores external links (X/Twitter, Readwise, etc.).
  * audio_notes: Stores voice recordings.✅ **Foreign key relations** link all content under a single **topic ID** to keep structure modular.✅ Use **JSONB columns** for storing metadata (e.g., YouTube timestamps, voice note transcriptions).

⠀⚠️ Issue 2: Handling YouTube & Podcast Snippets
* **Problem**: Extracting **specific timestamps** from YouTube or podcasts requires **additional API calls**, increasing API usage limits.
* **Solution**:✅ Use the **YouTube API** & **Pocket Casts API** to fetch transcripts if available.✅ Store timestamps **locally** rather than making API calls repeatedly.✅ Allow **manual timestamp entry** if no transcript exists.

⠀⚠️ Issue 3: Browser Limitations for Voice Notes
* **Problem**: **Native voice recording APIs** have **limited compatibility** (iOS Safari issues, permission restrictions).
* **Solution**:✅ Implement **Whisper AI** for voice-to-text processing.✅ Provide a **fallback UI** for users to upload pre-recorded audio if live recording fails.

⠀📌 **Resolution Notes:**
* Design a **modular database schema** with **scalable architecture**.
* Ensure **API requests are optimized** to avoid unnecessary rate limits.
* Test **browser compatibility early** to prevent recording issues later.

⠀
# 🛠️ Phase 2: AI Debate Engine (Text-Based MVP)
💡 **Main Risks: AI Quality, Hallucination Prevention, Realism of Expert Debates**
### ⚠️ Issue 1: AI Debate Responses May Be Too Generic
* **Problem**: AI (GPT-4) tends to generate **generic** responses rather than **deep, authentic expert opinions**.
* **Solution**:✅ Implement **persona-based prompting** using **few-shot learning** to match expert tone.✅ Create a **prompt-engineering system** that injects **historical references, real quotes, and argument structures** into responses.✅ Use **OpenAI Functions API** to generate **more structured counterarguments** rather than free-flowing text.

⠀⚠️ Issue 2: Ensuring Debate Coherence Over Multiple Exchanges
* **Problem**: GPT-based models tend to **lose track of previous points** after multiple rebuttals.
* **Solution**:✅ Store **past responses in a structured format** (e.g., tree-based argument structure).✅ Implement **context window optimization** → AI only recalls **key previous arguments** instead of the full chat history.

⠀⚠️ Issue 3: Avoiding AI Hallucination & Fact-Checking Issues
* **Problem**: AI might **fabricate** quotes or arguments that were never actually said by the expert.
* **Solution**:✅ Use **retrieval-augmented generation (RAG)** by pulling **real** historical documents as context for AI-generated responses.✅ Add a **fact-check layer** where the AI **self-validates** its claims by sourcing references before generating an argument.

⠀📌 **Resolution Notes:**
* Fine-tune **persona prompting** early for **realistic debates**.
* Implement **structured memory tracking** to keep long debates coherent.
* Fact-check responses by **grounding AI output in real, verifiable sources**.

⠀
# 🛠️ Phase 3: Voice AI Integration (ElevenLabs & Real-Time Debates)
💡 **Main Risks: Latency, AI Voice Lifelikeness, Speech-to-Text Processing**
### ⚠️ Issue 1: Latency in Generating AI-Generated Speech
* **Problem**: ElevenLabs and similar AI speech platforms introduce **1-3 seconds of processing delay** when converting AI text to speech.
* **Solution**:✅ Use **pre-buffering**: Generate **the first 2-3 responses ahead of time**.✅ Allow **simultaneous text & voice output** → users see the response **instantly** while voice audio is still processing.

⠀⚠️ Issue 2: Capturing Real-Time User Interruptions
* **Problem**: Users may want to **interrupt** an AI debater mid-sentence, but the AI **does not pause dynamically**.
* **Solution**:✅ Implement **interrupt detection**: If the user speaks, the AI **stops mid-response** and adjusts dynamically.✅ Use **partial transcription matching** to detect interruptions **in real-time**.

⠀⚠️ Issue 3: Making AI Voices Sound Less Robotic
* **Problem**: AI-generated voices often lack **emotional depth & rhetorical style**.
* **Solution**:✅ Fine-tune **intonation and pauses** using **SSML (Speech Synthesis Markup Language)**.✅ Allow users to **adjust debate pacing** (fast, normal, slow).

⠀📌 **Resolution Notes:**
* Implement **speech buffering** to avoid excessive latency.
* Build **interrupt recognition** to allow real-time dynamic conversations.
* Use **intonation optimization** to make debates sound natural.

⠀
# 🛠️ Phase 4: Advanced Features & Knowledge Graph
💡 **Main Risks: UX Complexity, API Rate Limits, Knowledge Evolution Tracking**
### ⚠️ Issue 1: Making the Knowledge Graph Intuitive
* **Problem**: Users may struggle to **navigate debate history & evolving thought patterns** visually.
* **Solution**:✅ Use a **graph-based UI (D3.js or React Flow)** to map ideas clearly.✅ Allow **"time-travel mode"** where users can **compare past vs. present thinking**.

⠀⚠️ Issue 2: API Rate Limits (Readwise, X/Twitter, YouTube)
* **Problem**: High-volume API calls for fetching tweets, articles, and transcripts may hit **rate limits**.
* **Solution**:✅ Implement **local caching** for retrieved content.✅ Use **batch processing** instead of **per-item** calls.

⠀⚠️ Issue 3: Detecting Thought Evolution Over Time
* **Problem**: How do we **track changes** in a user’s stance **quantitatively**?
* **Solution**:✅ AI assigns a **"confidence score"** to user beliefs based on debate performance.✅ Users can see **how their opinions shift** over multiple debates (e.g., from “strongly agree” to “neutral”).

⠀📌 **Resolution Notes:**
* Design a **graph UI that visually represents argument evolution**.
* Implement **API caching & batching** to avoid rate limits.
* Track **user stance over time** with an AI-based belief shift index.

⠀
# ### 📌 Optimized MVP Build for Early Users & Expansion 🚀
*(A lean yet powerful MVP that delivers core value fast while leaving room for scalable growth.)*
### 🎯 Goal:
* **Launch a functional MVP** that lets users engage in **AI-generated debates** on **their saved content** (notes, bookmarks, voice clips).
* **Minimize complexity** while ensuring the experience is **engaging & repeat-worthy**.
* **Use feedback loops** to refine features **before building advanced AI & knowledge graphs**.

⠀
# 💡 Phase 1: MVP Core - AI Debate Engine + Note Capture (3-4 Weeks)
✅ **1. Set Up Next.js 15 + Database (Supabase/Postgres)**
* **Features:**
  * Store **user notes, bookmarks, and voice snippets**.
  * API endpoints for **saving and retrieving data**.
* **Why?** → We need a **scalable** and **real-time** backend for storing user-generated debates.

⠀✅ **2. AI Debate Engine (Text-Based)**
* **Features:**
  * User **enters a thought or opinion**.
  * AI generates **two opposing perspectives** from famous thinkers.
  * Users can **challenge & refine arguments**.
* **Why?** → This is the **core engagement loop**—users interact with AI-driven debates.

⠀✅ **3. Basic UI & User Flow (Minimalist, Clean)**
* **Core Pages:**
  * 📌 **Home** – Start a debate.
  * 📝 **Note Capture** – Save thoughts, articles, or audio.
  * 💬 **Debate Screen** – AI debate with user participation.
* **Why?** → We need a simple, **intuitive UX** so users **quickly understand the product**.

⠀🔹 **MVP Deliverable:** A **working AI debate feature** where users **input opinions, trigger AI arguments, and interact via text**.

# 💡 Phase 2: Voice Debates & Speech Integration (Expand Engagement, 3-6 Weeks)
✅ **4. ElevenLabs Voice Synthesis Integration**
* **Convert AI responses into speech** for a **real-time debate feel**.
* Implement **“Play Debate” button**.
* **Why?** → Users **connect more deeply with audio** than plain text.

⠀✅ **5. Speech-to-Text (User Voice Input via Whisper AI)**
* **Let users respond via voice**, AI generates real-time counterarguments.
* **Why?** → Increases engagement **without requiring typing**.

⠀✅ **6. Debate Replay & Summary Generation**
* AI **summarizes each debate** in bullet points.
* Saves debate history for review.
* **Why?** → Gives **users tangible takeaways** from each debate.

⠀🔹 **Deliverable:** A fully **voice-powered AI debate experience** where users can **listen & participate via speech**.

# 💡 Phase 3: Early Community & Content Expansion (Expand User Base, 6-8 Weeks)
✅ **7. Readwise & X (Twitter) API Integration**
* Import **user highlights & tweets** → Generate AI debates automatically.
* **Why?** → Makes the app **instantly useful** for people who **already consume high-quality content**.

⠀✅ **8. “Wild Card” AI Experts (Serendipity Feature)**
* Occasionally **inject unexpected debaters** (e.g., Einstein jumps into a discussion on social media).
* **Why?** → Keeps debates **engaging & unpredictable**.

⠀✅ **9. Community Feedback & Iteration**
* Run **user feedback loops** → Improve **AI responses, voice quality, UX**.
* Measure **retention metrics** → Find out **which debate types are most engaging**.

⠀🔹 **Deliverable:** MVP evolves into a **sticky product with social sharing & deeper user engagement**.

### 🚀 The Optimized MVP Strategy
| **Phase** | **Feature Focus** | **Why?** | **Timeline** |
|:-:|:-:|:-:|:-:|
| **1** | 📝 **AI Debate Engine (Text-Only) + Note Capture** | **Core engagement** | 3-4 Weeks |
| **2** | 🎙️ **Voice Debates & Speech Input (ElevenLabs + Whisper AI)** | **Increases immersion** | 3-6 Weeks |
| **3** | 🔗 **Readwise & Twitter API + AI Surprises** | **Expands content sources & community** | 6-8 Weeks |

# 🚀 Immediate Next Steps
1️⃣ **Kickstart Phase 1: Text-Based AI Debates + Note Capture**
* **Set up Next.js 15 project** & **Supabase backend**.
* **Implement AI text debates**.
* **Deploy early MVP for testing**.

⠀2️⃣ **Plan Phase 2: Voice Debates (Start ElevenLabs Integration)**
* **Test AI-generated speech responses** in **simple voice debates**.

⠀3️⃣ **Define Phase 3 Expansion (API, Social Growth)**
* **Early access users from Readwise & X community**.

⠀
# 💡 Summary: Why This Works?
✅ **MVP ships fast, capturing early users** without overcomplicating AI.✅ **Keeps the focus on core engagement** (debate & user participation).✅ **Leaves room for expansion** into **voice, API integrations & knowledge evolution**.
</file>

<file path="docs/Status.md">
# Project Status

## Completed Features

### Core Debate Functionality
- ✅ Topic input and expert selection
- ✅ Expert response generation using GPT-4o
- ✅ User perspective input
- ✅ Dynamic expert responses to user input
- ✅ Cost tracking for API usage
- ✅ Mock implementation for testing without API key
- ✅ LangChain integration for enhanced debate logic
- ✅ Background knowledge retrieval for experts
- ✅ Context management for multi-turn debates
- ✅ Simulated "thinking" for more natural response timing

### Voice Features
- ✅ Voice synthesis for expert responses using ElevenLabs
- ✅ Voice toggle option
- ✅ Individual play/stop controls for each response
- ✅ Audio caching to prevent unnecessary regeneration
- ✅ Loading state indication during voice generation
- ✅ Speech-to-text for user input via microphone

### UI/UX Improvements
- ✅ Dark/Light theme support
- ✅ Responsive design for all screen sizes
- ✅ Expert profile cards with stance indicators
- ✅ Message bubbles with expert information
- ✅ Loading states and animations
- ✅ Debate summary feature with key points extraction
- ✅ Token usage and cost display
- ✅ Interactive microphone button with visual feedback
- ✅ Rebranded to "Debate-Aible"
- ✅ "Thinking" indicator for experts during response generation

## Pending Features

### Core Functionality
- [ ] Save/Load debate sessions
- [ ] Export debate transcripts
- [ ] Multiple debate formats (1v1, panel, etc.)
- [ ] Custom expert selection
- [ ] Citation support for expert claims
- [ ] Enhanced fact-checking with external API integration

### Voice Enhancements
- [✅] Voice input for user perspective
- [ ] Voice emotion/tone control
- [ ] Multiple voice options per expert
- [ ] Background music/ambiance option
- [ ] Voice speed control

### UI/UX Enhancements
- [ ] Progress tracking for debate stages
- [ ] Interactive timeline view
- [ ] Expert credibility scores
- [ ] Real-time fact-checking
- [ ] Social sharing features
- [ ] Debate statistics and analytics

### Advanced Features
- [ ] Multi-user debate support
- [ ] Real-time collaborative debates
- [ ] Integration with research databases
- [ ] Custom expert persona creation
- [ ] Debate scoring system
- [ ] Learning mode with explanations
- [ ] Knowledge graph visualization

### Technical Improvements
- [✅] Optimize API usage with model selection (gpt-4o)
- [ ] Implement rate limiting
- [✅] Add comprehensive error handling for API keys
- [ ] Improve voice synthesis quality
- [ ] Add unit and integration tests
- [✅] Implement caching strategy for mock responses
- [ ] Add analytics tracking

## Known Issues
- Voice synthesis occasionally takes longer than expected
- Need to improve key points extraction accuracy
- Mobile responsiveness can be enhanced
- Dark mode contrast needs adjustment in some areas
- Project-based OpenAI API keys may not work correctly

## Recent Changes
- Fixed critical user authentication issue with debate creation
- Implemented LangChain integration for enhanced AI functionality
- Added background knowledge retrieval for experts
- Created context management system for coherent multi-turn conversations
- Added "thinking" indicator component for more natural conversation flow
- Added test endpoints for LangChain agent verification
- Updated Firebase data model for better consistency
- Fixed field naming inconsistencies (lastUpdatedAt → updatedAt)
- Added comprehensive documentation for LangChain integration
- Improved error handling for debate creation and API calls
- Updated LangChain import paths for compatibility with the latest version:
  - Changed imports from `langchain/schema` to `@langchain/core/messages`
  - Changed imports from `langchain/llms/openai` and `langchain/chat_models/openai` to `@langchain/openai`

## Current Architecture

### Frontend
- Next.js 15 with TailwindCSS for UI
- Zustand for state management
- Components for debate panel, expert cards, message bubbles
- ThinkingIndicator component for visualization of AI processing

### Backend
- Next.js API routes for serverless functions
- OpenAI integration with GPT-4o for core responses
- LangChain for agent-based operations:
  - Knowledge retrieval agents
  - Fact-checking functionality
  - Context management
  - Using modular package structure (@langchain/core, @langchain/openai)
- Firebase/Firestore for data persistence

### Data Flow
1. User selects a topic
2. System generates experts with opposing viewpoints
3. Background knowledge is retrieved for experts
4. Context management system initializes
5. Initial expert statements are generated
6. User adds perspective through UI
7. Turn-based debate continues with context awareness

## Next Steps

### Serverless Migration Plan

#### Phase 1: User Authentication & Profiles

1. **Authentication System**
   - Implement Auth0 or NextAuth.js for serverless authentication
   - Create login/signup flows with social login options
   - Design user profile page with customization options
   - Set up JWT token handling for serverless functions

2. **User Profile Data Schema**
   ```typescript
   interface UserProfile {
     id: string;
     email: string;
     name: string;
     profilePicture?: string;
     preferences: {
       defaultExpertType: 'historical' | 'domain';
       useVoiceSynthesis: boolean;
       theme: 'light' | 'dark' | 'system';
     }
   }
   ```

#### Phase 2: Database & Persistence Layer

1. **Choose Serverless Database**
   - **Primary DB**: Firestore/DynamoDB for document-based storage
   - **Considerations**: Scaling, cold starts, query patterns

2. **Data Schema Design**
   ```typescript
   // Debate history schema
   interface SavedDebate {
     id: string;
     userId: string;
     topic: string;
     experts: Expert[];
     messages: Message[];
     expertType: 'historical' | 'domain';
     createdAt: Date;
     updatedAt: Date; // Updated field name for consistency
     status: string;
     isFavorite: boolean;
     tags?: string[];
     summary?: string;
     context?: DebateContext; // Added for LangChain context
   }
   ```

3. **Data Access Layer**
   - Create abstraction for database operations
   - Implement CRUD operations for debates
   - Set up indexes for efficient queries

#### Phase 3: Serverless Functions

1. **Auth-Protected API Routes**
   - Convert current `/api/debate` to authenticated endpoint
   - Add user context to all API calls

2. **New Endpoints**
   ```
   /api/debates             # List user's debates
   /api/debates/[id]        # Get/update specific debate
   /api/favorites           # Manage favorite debates
   /api/user/preferences    # Update user preferences
   ```

3. **Optimize for Cold Starts**
   - Split large functions into smaller ones
   - Implement connection pooling for database
   - Use provisioned concurrency for critical paths

#### Phase 4: Frontend Enhancements

1. **User Dashboard**
   - Recent debates list
   - Favorites section
   - Topic recommendations

2. **Persistence Controls**
   - "Save Debate" button
   - Auto-save functionality
   - Export/share options

3. **History & Favorites UI**
   ```jsx
   <DebateHistory 
     debates={userDebates}
     onSelect={loadDebate}
     onDelete={deleteDebate}
     onToggleFavorite={toggleFavorite}
   />
   ```

### Implementation Staging

#### Stage 1: Foundation (Weeks 1-2)
- Set up authentication
- Create database schemas
- Implement basic user profiles

#### Stage 2: Core Functionality (Weeks 3-4)
- Debate persistence
- History & favorites
- User preferences

#### Stage 3: Enhanced Features (Weeks 5-6)
- Dashboard & analytics
- Sharing functionality
- Optimizations & performance

### Technical Architecture

```
┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐
│                 │     │                 │     │                 │
│  Next.js App    │────▶│  API Gateway    │────▶│  Auth Service   │
│  (Static Site)  │     │                 │     │  (Auth0/NextAuth)│
│                 │     │                 │     │                 │
└─────────────────┘     └─────────────────┘     └─────────────────┘
        │                        │                      │
        │                        ▼                      │
        │               ┌─────────────────┐             │
        │               │                 │             │
        └──────────────▶│  Serverless     │◀────────────┘
                        │  Functions      │
                        │                 │
                        └─────────────────┘
                                │
                                ▼
         ┌───────────┐  ┌─────────────────┐  ┌───────────┐
         │           │  │                 │  │           │
         │  OpenAI   │◀─┤  Database       │─▶│ ElevenLabs│
         │  API      │  │  (Firestore/    │  │ API       │
         │           │  │   DynamoDB)     │  │           │
         └───────────┘  └─────────────────┘  └───────────┘
                                │
                                ▼
                        ┌───────────────┐
                        │  LangChain    │
                        │  Knowledge    │
                        │  Agents       │
                        └───────────────┘
```

### Key Considerations

1. **Stateless Design**
   - Move from client-state to server-persisted state
   - Ensure all functions can run independently

2. **Cost Optimization**
   - Implement tiered usage limits
   - Consider caching for expensive operations
   - Monitor API call volume to OpenAI/ElevenLabs

3. **Security**
   - Secure user data with proper encryption
   - Implement rate limiting
   - Add API key rotation
</file>

<file path="public/file.svg">
<svg fill="none" viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg"><path d="M14.5 13.5V5.41a1 1 0 0 0-.3-.7L9.8.29A1 1 0 0 0 9.08 0H1.5v13.5A2.5 2.5 0 0 0 4 16h8a2.5 2.5 0 0 0 2.5-2.5m-1.5 0v-7H8v-5H3v12a1 1 0 0 0 1 1h8a1 1 0 0 0 1-1M9.5 5V2.12L12.38 5zM5.13 5h-.62v1.25h2.12V5zm-.62 3h7.12v1.25H4.5zm.62 3h-.62v1.25h7.12V11z" clip-rule="evenodd" fill="#666" fill-rule="evenodd"/></svg>
</file>

<file path="public/globe.svg">
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><g clip-path="url(#a)"><path fill-rule="evenodd" clip-rule="evenodd" d="M10.27 14.1a6.5 6.5 0 0 0 3.67-3.45q-1.24.21-2.7.34-.31 1.83-.97 3.1M8 16A8 8 0 1 0 8 0a8 8 0 0 0 0 16m.48-1.52a7 7 0 0 1-.96 0H7.5a4 4 0 0 1-.84-1.32q-.38-.89-.63-2.08a40 40 0 0 0 3.92 0q-.25 1.2-.63 2.08a4 4 0 0 1-.84 1.31zm2.94-4.76q1.66-.15 2.95-.43a7 7 0 0 0 0-2.58q-1.3-.27-2.95-.43a18 18 0 0 1 0 3.44m-1.27-3.54a17 17 0 0 1 0 3.64 39 39 0 0 1-4.3 0 17 17 0 0 1 0-3.64 39 39 0 0 1 4.3 0m1.1-1.17q1.45.13 2.69.34a6.5 6.5 0 0 0-3.67-3.44q.65 1.26.98 3.1M8.48 1.5l.01.02q.41.37.84 1.31.38.89.63 2.08a40 40 0 0 0-3.92 0q.25-1.2.63-2.08a4 4 0 0 1 .85-1.32 7 7 0 0 1 .96 0m-2.75.4a6.5 6.5 0 0 0-3.67 3.44 29 29 0 0 1 2.7-.34q.31-1.83.97-3.1M4.58 6.28q-1.66.16-2.95.43a7 7 0 0 0 0 2.58q1.3.27 2.95.43a18 18 0 0 1 0-3.44m.17 4.71q-1.45-.12-2.69-.34a6.5 6.5 0 0 0 3.67 3.44q-.65-1.27-.98-3.1" fill="#666"/></g><defs><clipPath id="a"><path fill="#fff" d="M0 0h16v16H0z"/></clipPath></defs></svg>
</file>

<file path="public/next.svg">
<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 394 80"><path fill="#000" d="M262 0h68.5v12.7h-27.2v66.6h-13.6V12.7H262V0ZM149 0v12.7H94v20.4h44.3v12.6H94v21h55v12.6H80.5V0h68.7zm34.3 0h-17.8l63.8 79.4h17.9l-32-39.7 32-39.6h-17.9l-23 28.6-23-28.6zm18.3 56.7-9-11-27.1 33.7h17.8l18.3-22.7z"/><path fill="#000" d="M81 79.3 17 0H0v79.3h13.6V17l50.2 62.3H81Zm252.6-.4c-1 0-1.8-.4-2.5-1s-1.1-1.6-1.1-2.6.3-1.8 1-2.5 1.6-1 2.6-1 1.8.3 2.5 1a3.4 3.4 0 0 1 .6 4.3 3.7 3.7 0 0 1-3 1.8zm23.2-33.5h6v23.3c0 2.1-.4 4-1.3 5.5a9.1 9.1 0 0 1-3.8 3.5c-1.6.8-3.5 1.3-5.7 1.3-2 0-3.7-.4-5.3-1s-2.8-1.8-3.7-3.2c-.9-1.3-1.4-3-1.4-5h6c.1.8.3 1.6.7 2.2s1 1.2 1.6 1.5c.7.4 1.5.5 2.4.5 1 0 1.8-.2 2.4-.6a4 4 0 0 0 1.6-1.8c.3-.8.5-1.8.5-3V45.5zm30.9 9.1a4.4 4.4 0 0 0-2-3.3 7.5 7.5 0 0 0-4.3-1.1c-1.3 0-2.4.2-3.3.5-.9.4-1.6 1-2 1.6a3.5 3.5 0 0 0-.3 4c.3.5.7.9 1.3 1.2l1.8 1 2 .5 3.2.8c1.3.3 2.5.7 3.7 1.2a13 13 0 0 1 3.2 1.8 8.1 8.1 0 0 1 3 6.5c0 2-.5 3.7-1.5 5.1a10 10 0 0 1-4.4 3.5c-1.8.8-4.1 1.2-6.8 1.2-2.6 0-4.9-.4-6.8-1.2-2-.8-3.4-2-4.5-3.5a10 10 0 0 1-1.7-5.6h6a5 5 0 0 0 3.5 4.6c1 .4 2.2.6 3.4.6 1.3 0 2.5-.2 3.5-.6 1-.4 1.8-1 2.4-1.7a4 4 0 0 0 .8-2.4c0-.9-.2-1.6-.7-2.2a11 11 0 0 0-2.1-1.4l-3.2-1-3.8-1c-2.8-.7-5-1.7-6.6-3.2a7.2 7.2 0 0 1-2.4-5.7 8 8 0 0 1 1.7-5 10 10 0 0 1 4.3-3.5c2-.8 4-1.2 6.4-1.2 2.3 0 4.4.4 6.2 1.2 1.8.8 3.2 2 4.3 3.4 1 1.4 1.5 3 1.5 5h-5.8z"/></svg>
</file>

<file path="public/vercel.svg">
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1155 1000"><path d="m577.3 0 577.4 1000H0z" fill="#fff"/></svg>
</file>

<file path="public/window.svg">
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 2.5h13v10a1 1 0 0 1-1 1h-11a1 1 0 0 1-1-1zM0 1h16v11.5a2.5 2.5 0 0 1-2.5 2.5h-11A2.5 2.5 0 0 1 0 12.5zm3.75 4.5a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5M7 4.75a.75.75 0 1 1-1.5 0 .75.75 0 0 1 1.5 0m1.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5" fill="#666"/></svg>
</file>

<file path="src/app/api/analyze/route.ts">
import { NextRequest, NextResponse } from 'next/server';
import openai, { getModel } from '@/lib/ai/openai-client';
import { documentProcessor } from '@/lib/ai/document-processor';
import { v4 as uuidv4 } from 'uuid';
export async function POST(request: NextRequest) {
    try {
        const formData = await request.formData();
        const file = formData.get('file') as File;
        if (!file) {
            return NextResponse.json({ error: 'No file provided' }, { status: 400 });
        }
        // Check file size (max 20MB)
        if (file.size > 20 * 1024 * 1024) {
            return NextResponse.json({ error: 'File too large (max 20MB)' }, { status: 400 });
        }
        // Check file type
        const allowedTypes = ['application/pdf', 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'text/plain'];
        if (!allowedTypes.includes(file.type)) {
            return NextResponse.json({ error: 'Invalid file type (PDF, DOCX, or TXT required)' }, { status: 400 });
        }
        // Generate a unique debate ID
        const debateId = uuidv4();
        // Extract text from file
        const fileContent = await extractTextFromFile(file);
        // Analyze text to extract topics
        const topics = await extractTopics(fileContent);
        // Process document for vector storage if it's a PDF
        let documentProcessed = false;
        let chunkCount = 0;
        if (file.type === 'application/pdf') {
            try {
                // Convert file to buffer
                const buffer = Buffer.from(await file.arrayBuffer());
                // Process document and store in vector database
                const result = await documentProcessor.processDocument(
                    buffer,
                    file.name,
                    debateId
                );
                documentProcessed = result.success;
                chunkCount = result.chunkCount || 0;
                if (!result.success) {
                    console.warn('Document processing failed:', result.error);
                }
            } catch (error) {
                console.error('Error processing document for vector storage:', error);
                // Continue even if document processing fails
            }
        }
        return NextResponse.json({
            topics,
            debateId,
            documentProcessed,
            chunkCount
        });
    } catch (error) {
        console.error('Error in analyze API:', error);
        return NextResponse.json(
            { error: error instanceof Error ? error.message : 'Unknown error' },
            { status: 500 }
        );
    }
}
async function extractTextFromFile(file: File): Promise<string> {
    // For simplicity, we'll just read text files directly
    // In a real implementation, you would use libraries to extract text from PDFs and DOCXs
    if (file.type === 'text/plain') {
        return await file.text();
    }
    // Mock implementation for PDF and DOCX
    // In a real app, you would use libraries like pdf-parse or mammoth
    return `Sample extracted text from ${file.name}. This is a placeholder for the actual content that would be extracted from the document.`;
}
async function extractTopics(text: string): Promise<Array<{
    title: string;
    confidence: number;
    arguments: string[];
}>> {
    try {
        const response = await openai.chat.completions.create({
            model: getModel(),
            messages: [
                {
                    role: 'system',
                    content: `You are an expert at analyzing documents and extracting debate topics. 
          Extract 3 potential debate topics from the provided text. 
          For each topic, provide a clear title, a confidence score (0-100), and 3 key arguments related to the topic.
          Return your response as a JSON array of topics.`
                },
                {
                    role: 'user',
                    content: `Extract debate topics from the following text:\n\n${text.substring(0, 10000)}`
                }
            ],
            temperature: 0.7,
            response_format: { type: 'json_object' }
        });
        const content = response.choices[0]?.message?.content;
        if (!content) {
            throw new Error('No response from OpenAI');
        }
        const parsedResponse = JSON.parse(content);
        // Ensure the response has the expected format
        if (!parsedResponse.topics || !Array.isArray(parsedResponse.topics)) {
            return [
                {
                    title: 'AI and the Future of Work',
                    confidence: 85,
                    arguments: [
                        'AI will transform how we work in the next decade',
                        'Human creativity remains essential despite AI advances',
                        'Ethical guidelines are needed for responsible AI development'
                    ]
                }
            ];
        }
        return parsedResponse.topics;
    } catch (error) {
        console.error('Error extracting topics:', error);
        // Return fallback topics in case of error
        return [
            {
                title: 'AI and the Future of Work',
                confidence: 85,
                arguments: [
                    'AI will transform how we work in the next decade',
                    'Human creativity remains essential despite AI advances',
                    'Ethical guidelines are needed for responsible AI development'
                ]
            }
        ];
    }
}
</file>

<file path="src/app/api/auth/[...nextauth]/route.ts">
import NextAuth from "next-auth";
import { authOptions } from "@/lib/auth";
const handler = NextAuth(authOptions);
export { handler as GET, handler as POST };
</file>

<file path="src/app/api/content/document/route.ts">
import { NextRequest, NextResponse } from 'next/server';
import { writeFile, mkdir } from 'fs/promises';
import { join } from 'path';
import { v4 as uuidv4 } from 'uuid';
// Ensure uploads directory exists
async function ensureUploadsDir() {
    try {
        const uploadsDir = join(process.cwd(), 'uploads');
        await mkdir(uploadsDir, { recursive: true });
        return uploadsDir;
    } catch (error) {
        console.error('Error creating uploads directory:', error);
        throw error;
    }
}
export async function POST(request: NextRequest) {
    try {
        const formData = await request.formData();
        const file = formData.get('file') as File;
        if (!file) {
            return NextResponse.json(
                { message: 'No file provided' },
                { status: 400 }
            );
        }
        // Validate file type
        const fileType = file.name.split('.').pop()?.toLowerCase();
        if (!['pdf', 'docx', 'txt'].includes(fileType || '')) {
            return NextResponse.json(
                { message: 'Unsupported file type. Please upload PDF, DOCX, or TXT files.' },
                { status: 400 }
            );
        }
        // Save file to disk
        const uploadsDir = await ensureUploadsDir();
        const bytes = await file.arrayBuffer();
        const buffer = Buffer.from(bytes);
        const uniqueFilename = `${uuidv4()}-${file.name}`;
        const filePath = join(uploadsDir, uniqueFilename);
        await writeFile(filePath, buffer);
        // Mock document processing and topic extraction
        // In a real implementation, this would use the DocumentParser and TopicExtractor
        const mockTopics = [
            {
                title: `Key insights from ${file.name}`,
                confidence: 0.92,
                arguments: [
                    {
                        claim: "AI will transform how we work in the next decade",
                        evidence: "Multiple studies show 40% of jobs will be augmented by AI by 2030"
                    },
                    {
                        claim: "Human creativity remains essential despite AI advances",
                        evidence: "Creative problem-solving is still difficult for AI systems to replicate"
                    },
                    {
                        claim: "Ethical guidelines are needed for responsible AI development",
                        evidence: "Without proper oversight, AI systems may perpetuate existing biases"
                    }
                ]
            },
            {
                title: `The future of technology based on ${file.name}`,
                confidence: 0.85,
                arguments: [
                    {
                        claim: "Quantum computing will revolutionize cryptography",
                        evidence: "Current encryption methods may become obsolete within 5-10 years"
                    },
                    {
                        claim: "Blockchain technology has applications beyond cryptocurrency",
                        evidence: "Supply chain management and voting systems are adopting blockchain"
                    }
                ]
            },
            {
                title: `Ethical considerations from ${file.name}`,
                confidence: 0.78,
                arguments: [
                    {
                        claim: "Privacy concerns are growing with data collection",
                        evidence: "Users are increasingly aware of how their data is being used"
                    },
                    {
                        claim: "Technology regulation needs to balance innovation and protection",
                        evidence: "Overly restrictive policies may stifle beneficial developments"
                    }
                ]
            }
        ];
        return NextResponse.json({
            message: 'Document processed successfully',
            filename: uniqueFilename,
            fileType,
            fileSize: file.size,
            topics: mockTopics
        });
    } catch (error) {
        console.error('Error processing document:', error);
        return NextResponse.json(
            { message: 'Error processing document', error: (error as Error).message },
            { status: 500 }
        );
    }
}
</file>

<file path="src/app/api/content/link/route.ts">
import { NextRequest, NextResponse } from 'next/server';
import fetch from 'cross-fetch';
import * as cheerio from 'cheerio';
import OpenAI from 'openai';
// Create an OpenAI client
const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
});
// Intelligent topic extractor using OpenAI
class AITopicExtractor {
    async extractTopics(document: any) {
        try {
            const content = document.content || '';
            // If content is too large, we need to truncate it
            const truncatedContent = content.length > 8000
                ? content.substring(0, 8000) + "..."
                : content;
            // Use OpenAI to extract topics and arguments
            const response = await openai.chat.completions.create({
                model: process.env.OPENAI_MODEL || "gpt-4o", // Use the configured model or default to gpt-4o
                messages: [
                    {
                        role: "system",
                        content: `You are an expert at analyzing content and extracting key topics for debate.
                        For a given piece of content:
                        1. Identify 3-5 main topics that would make excellent debate subjects
                        2. For each topic, extract key arguments representing DIFFERENT SIDES of the issue
                        3. Include both supporting AND opposing viewpoints for each topic
                        4. Base all arguments directly on content from the source material
                        5. Focus on controversial or nuanced issues where reasonable people might disagree
                        6. Look for topics that involve ethical considerations, policy decisions, or competing values
                        Format each topic with a clear title and multiple arguments that present different perspectives.`
                    },
                    {
                        role: "user",
                        content: `Analyze the following content and extract debate topics with key arguments. 
                        Format your response as JSON with this exact structure:
                        {
                          "topics": [
                            {
                              "title": "Clear debate topic title",
                              "relevance": 0.9, // number between 0-1
                              "summary": "Brief summary of the topic",
                              "keywords": ["keyword1", "keyword2", "keyword3"],
                              "arguments": [
                                {
                                  "claim": "Argument supporting one perspective",
                                  "evidence": "Direct evidence from the content that supports this claim",
                                  "relevance": 0.85 // number between 0-1
                                },
                                {
                                  "claim": "Argument from an opposing perspective",
                                  "evidence": "Direct evidence from the content that supports this counter-claim",
                                  "relevance": 0.82 // number between 0-1
                                }
                              ]
                            }
                            // additional topics...
                          ]
                        }
                        CONTENT TO ANALYZE:
                        ${truncatedContent}`
                    }
                ],
                response_format: { type: "json_object" },
                temperature: 0.5,
            });
            const result = JSON.parse(response.choices[0].message.content || "{}");
            // Map the result to the expected format
            const topics = (result.topics || []).map((topic: any) => ({
                title: topic.title,
                confidence: topic.relevance || 0.85,
                keywords: topic.keywords || [],
                summary: topic.summary || topic.title,
                sourceSection: {
                    content: truncatedContent.substring(0, 200), // Just a placeholder
                    position: 0
                }
            }));
            const mainArguments = (result.topics || []).flatMap((topic: any, topicIndex: number) =>
                (topic.arguments || []).map((arg: any) => ({
                    claim: arg.claim,
                    confidence: arg.relevance || 0.8,
                    evidence: Array.isArray(arg.evidence) ? arg.evidence : [arg.evidence],
                    sourceSection: {
                        content: truncatedContent.substring(0, 200), // Just a placeholder
                        position: topicIndex
                    }
                }))
            );
            return {
                success: true,
                topics,
                mainArguments
            };
        } catch (error) {
            console.error("Error extracting topics with AI:", error);
            return {
                success: false,
                topics: [],
                mainArguments: [],
                error: `Failed to extract topics: ${(error as Error).message}`
            };
        }
    }
}
export async function POST(request: NextRequest) {
    try {
        const formData = await request.formData();
        const url = formData.get('url') as string;
        if (!url) {
            return NextResponse.json(
                { message: 'No URL provided' },
                { status: 400 }
            );
        }
        // Fetch the web page content
        const response = await fetch(url);
        if (!response.ok) {
            return NextResponse.json(
                { message: `Failed to fetch content from URL: ${response.statusText}` },
                { status: 400 }
            );
        }
        const html = await response.text();
        // Parse the HTML content
        const $ = cheerio.load(html);
        // Extract text content from the page (removing scripts, styles, etc.)
        $('script, style, noscript, iframe, object, embed').remove();
        const textContent = $('body').text().replace(/\s+/g, ' ').trim();
        // Extract metadata
        const metadata = {
            url,
            title: $('title').text() || 'Unknown Title',
            author: $('meta[name="author"]').attr('content') || 'Unknown Author',
            publishedDate: $('meta[name="date"]').attr('content') || 'Unknown Date',
            source: new URL(url).hostname,
            wordCount: textContent.split(/\s+/).length
        };
        // Check if OpenAI API key is available
        if (!process.env.OPENAI_API_KEY) {
            console.warn("OpenAI API key not found, falling back to mock data");
            // Return mock data with a warning
            return NextResponse.json({
                message: 'Web link processed with mock data (OpenAI API key not configured)',
                metadata,
                topics: [
                    {
                        title: 'No OpenAI API key configured',
                        confidence: 1.0,
                        arguments: [
                            {
                                claim: "To use actual topic extraction, you need to configure OPENAI_API_KEY in your .env file",
                                evidence: "This is a placeholder response because OpenAI API key is not configured."
                            },
                            {
                                claim: "The app is currently using mock data instead of real content analysis",
                                evidence: "Check your environment variables and make sure OPENAI_API_KEY is set properly."
                            }
                        ]
                    }
                ]
            });
        }
        // Use the AITopicExtractor to analyze the content
        const topicExtractor = new AITopicExtractor();
        const extractionResult = await topicExtractor.extractTopics({
            content: textContent
        });
        if (!extractionResult.success) {
            console.error('Topic extraction failed:', extractionResult.error);
            return NextResponse.json(
                { message: 'Failed to extract topics from content', error: extractionResult.error },
                { status: 500 }
            );
        }
        // Format the topics for the frontend
        const formattedTopics = extractionResult.topics.map(topic => {
            // Convert the arguments to the format expected by the frontend
            const args = extractionResult.mainArguments
                .filter(arg => arg.sourceSection.position === extractionResult.topics.indexOf(topic))
                .map(arg => ({
                    claim: arg.claim,
                    evidence: Array.isArray(arg.evidence) ? arg.evidence.join(' ') : arg.evidence
                }));
            return {
                title: topic.title,
                confidence: topic.confidence,
                arguments: args.length > 0 ? args : [
                    {
                        claim: "No specific arguments found for this topic",
                        evidence: "Consider exploring this topic further for more detailed analysis"
                    }
                ]
            };
        });
        return NextResponse.json({
            message: 'Web link processed successfully',
            metadata,
            topics: formattedTopics
        });
    } catch (error) {
        console.error('Error processing web link:', error);
        return NextResponse.json(
            { message: 'Error processing web link', error: (error as Error).message },
            { status: 500 }
        );
    }
}
</file>

<file path="src/app/api/content/media/route.ts">
import { NextRequest, NextResponse } from 'next/server';
export async function POST(request: NextRequest) {
    try {
        const formData = await request.formData();
        const url = formData.get('url') as string;
        const type = formData.get('type') as string;
        if (!url) {
            return NextResponse.json(
                { message: 'No URL provided' },
                { status: 400 }
            );
        }
        if (!['youtube', 'podcast'].includes(type)) {
            return NextResponse.json(
                { message: 'Invalid media type. Supported types: youtube, podcast' },
                { status: 400 }
            );
        }
        // Mock media processing
        // In a real implementation, this would use the MediaProcessor and TopicExtractor
        const mockTopics = [
            {
                title: type === 'youtube'
                    ? 'Key points from this YouTube video'
                    : 'Main topics from this podcast',
                confidence: 0.89,
                arguments: [
                    {
                        claim: "Digital transformation is accelerating across industries",
                        evidence: "Companies are investing heavily in cloud infrastructure and AI"
                    },
                    {
                        claim: "Remote work has permanently changed workplace dynamics",
                        evidence: "Hybrid models are becoming the standard for knowledge workers"
                    },
                    {
                        claim: "Data privacy concerns are growing among consumers",
                        evidence: "Recent surveys show increased awareness of personal data usage"
                    }
                ]
            },
            {
                title: 'Emerging trends discussed in the content',
                confidence: 0.82,
                arguments: [
                    {
                        claim: "Sustainable technology is gaining momentum",
                        evidence: "Green computing initiatives are being adopted by major tech companies"
                    },
                    {
                        claim: "Decentralized systems are challenging traditional models",
                        evidence: "Web3 technologies are creating new ownership paradigms"
                    }
                ]
            },
            {
                title: 'Controversial perspectives from the media',
                confidence: 0.75,
                arguments: [
                    {
                        claim: "AI regulation may stifle innovation",
                        evidence: "Some experts argue that excessive regulation could slow progress"
                    },
                    {
                        claim: "Digital divide is widening despite technological advances",
                        evidence: "Access to technology remains unequal across socioeconomic groups"
                    }
                ]
            }
        ];
        // Add media-specific metadata
        const metadata = {
            url,
            type,
            title: type === 'youtube'
                ? 'How Technology is Reshaping Our Future'
                : 'The Digital Transformation Podcast - Episode 42',
            duration: type === 'youtube' ? '18:24' : '42:15',
            author: type === 'youtube' ? 'TechInsights' : 'Digital Futures Network',
            publishedDate: '2023-09-15'
        };
        return NextResponse.json({
            message: 'Media processed successfully',
            metadata,
            topics: mockTopics
        });
    } catch (error) {
        console.error('Error processing media:', error);
        return NextResponse.json(
            { message: 'Error processing media', error: (error as Error).message },
            { status: 500 }
        );
    }
}
</file>

<file path="src/app/api/debate/route.ts">
import { NextRequest, NextResponse } from 'next/server';
import { Message } from '@/types/message';
import { Expert } from '@/types/expert';
import { v4 as uuidv4 } from 'uuid';
import { DebateStorage } from '@/lib/storage/debate-storage';
import { selectExperts } from '@/lib/ai/expert-selector';
import { generateResponse } from '@/lib/ai/response-generator';
// Handle all debate-related API requests
export async function POST(request: NextRequest) {
  try {
    console.log('Debate API called with method:', request.method);
    const body = await request.json();
    console.log('Debate API request body:', body);
    const { action } = body;
    console.log('Debate API action:', action);
    switch (action) {
      case 'select-experts':
        return handleSelectExperts(body);
      case 'initialize-debate':
        return handleInitializeDebate(body);
      case 'generate-response':
        return handleGenerateResponse(body);
      case 'test':
        // Simple test case
        return NextResponse.json({
          message: 'Debate API test successful',
          receivedData: body,
          timestamp: new Date().toISOString()
        });
      default:
        console.error(`Unknown action: ${action}`);
        return NextResponse.json(
          { error: `Unknown action: ${action}` },
          { status: 400 }
        );
    }
  } catch (error) {
    console.error('Error in debate API:', error);
    return NextResponse.json(
      { error: error instanceof Error ? error.message : 'Unknown error' },
      { status: 500 }
    );
  }
}
// Handle selecting experts for a debate
async function handleSelectExperts(req: any) {
  console.log('handleSelectExperts called with:', req);
  const { topic, expertType = 'historical', count = 2 } = req;
  if (!topic) {
    console.error('Topic is required');
    return NextResponse.json({ error: 'Topic is required' }, { status: 400 });
  }
  try {
    console.log(`API: Selecting ${count} ${expertType} experts for topic: ${topic}`);
    // Try to use the real selectExperts function, but fall back to mock data if it fails
    let experts;
    try {
      experts = await selectExperts(topic, expertType, count);
      console.log('API: Experts selected:', experts);
    } catch (selectError) {
      console.error('Error using selectExperts, falling back to mock data:', selectError);
      // Mock response for testing
      experts = [
        {
          id: `expert_${Date.now()}_1`,
          name: 'Albert Einstein',
          type: expertType,
          expertise: 'Physics',
          era: '20th Century',
          description: 'Theoretical physicist who developed the theory of relativity'
        },
        {
          id: `expert_${Date.now()}_2`,
          name: 'Marie Curie',
          type: expertType,
          expertise: 'Chemistry and Physics',
          era: '19th-20th Century',
          description: 'Physicist and chemist who conducted pioneering research on radioactivity'
        }
      ];
    }
    // Verify experts are of the correct type
    const filteredExperts = experts.filter((expert: Expert) => expert.type === expertType);
    console.log(`API: Selected ${filteredExperts.length} ${expertType} experts`);
    if (filteredExperts.length === 0) {
      throw new Error(`No ${expertType} experts were found for this topic`);
    }
    return NextResponse.json({ experts: filteredExperts });
  } catch (error: any) {
    console.error('Error selecting experts:', error);
    return NextResponse.json(
      { error: error.message || 'Failed to select experts' },
      { status: 500 }
    );
  }
}
// Handle initializing a debate
async function handleInitializeDebate(body: any) {
  const { topic, expertType, userId } = body;
  if (!topic || !expertType || !userId) {
    return NextResponse.json(
      { error: 'Missing required fields: topic, expertType, userId' },
      { status: 400 }
    );
  }
  try {
    // Generate a unique debate ID
    const debateId = `debate_${Date.now()}_${Math.random().toString(36).substring(2, 9)}`;
    // Try to use the real selectExperts function, but fall back to mock data if it fails
    let experts;
    try {
      experts = await selectExperts(topic, expertType, 2);
    } catch (selectError) {
      console.error('Error using selectExperts, falling back to mock data:', selectError);
      // Mock experts for testing
      experts = [
        {
          id: `expert_${Date.now()}_1`,
          name: 'Albert Einstein',
          type: expertType,
          expertise: 'Physics',
          era: '20th Century',
          description: 'Theoretical physicist who developed the theory of relativity'
        },
        {
          id: `expert_${Date.now()}_2`,
          name: 'Marie Curie',
          type: expertType,
          expertise: 'Chemistry and Physics',
          era: '19th-20th Century',
          description: 'Physicist and chemist who conducted pioneering research on radioactivity'
        }
      ];
    }
    // Try to initialize the debate in storage, but don't fail if it doesn't work
    try {
      const debateStorage = await DebateStorage.getInstance();
      await debateStorage.initializeDebate(debateId, topic, experts, userId);
    } catch (storageError) {
      console.error('Error initializing debate in storage:', storageError);
      // Continue anyway since we can return the debate ID and experts
    }
    return NextResponse.json({ debateId, topic, experts });
  } catch (error: any) {
    console.error('Error initializing debate:', error);
    return NextResponse.json(
      { error: error.message || 'Failed to initialize debate' },
      { status: 500 }
    );
  }
}
// Handle generating a response
async function handleGenerateResponse(body: any) {
  const { expert, topic, messages, useCitations = true, debateId } = body;
  if (!expert || !topic || !messages) {
    return NextResponse.json(
      { error: 'Missing required fields: expert, topic, messages' },
      { status: 400 }
    );
  }
  try {
    // Try to use the real generateResponse function, but fall back to mock data if it fails
    let response, usage;
    try {
      const result = await generateResponse(expert, topic, messages, useCitations);
      response = result.response;
      usage = result.usage;
    } catch (generateError) {
      console.error('Error using generateResponse, falling back to mock data:', generateError);
      // Mock response for testing
      response = `This is a mock response from ${expert.name} about ${topic}. This is just a test response to verify the API is working correctly.`;
      usage = { prompt_tokens: 100, completion_tokens: 150, total_tokens: 250 };
    }
    // If debateId is provided, try to store the message
    if (debateId) {
      try {
        const newMessage = {
          id: `msg_${Date.now()}_${expert.id}`,
          role: 'assistant' as const,
          content: response,
          speaker: expert.name,
          timestamp: new Date().toISOString(),
          usage
        };
        const debateStorage = await DebateStorage.getInstance();
        await debateStorage.addMessage(debateId, newMessage);
      } catch (storageError) {
        console.error('Error storing message:', storageError);
        // Continue anyway since we can return the response
      }
    }
    return NextResponse.json({ response, usage });
  } catch (error: any) {
    console.error('Error generating response:', error);
    return NextResponse.json(
      { error: error.message || 'Failed to generate response' },
      { status: 500 }
    );
  }
}
// Simple test endpoint for the debate API
export async function GET(request: NextRequest) {
  console.log('Debate API GET called');
  // Extract query parameters
  const searchParams = request.nextUrl.searchParams;
  const action = searchParams.get('action');
  const debateId = searchParams.get('debateId');
  console.log('Debate API GET params:', { action, debateId });
  // Handle different actions
  if (action === 'test') {
    return NextResponse.json({
      status: 'success',
      message: 'Debate API test endpoint is working',
      timestamp: new Date().toISOString()
    });
  }
  // If debateId is provided, try to fetch debate data
  if (debateId) {
    try {
      const debateStorage = await DebateStorage.getInstance();
      const debate = await debateStorage.getDebate(debateId);
      if (!debate) {
        return NextResponse.json(
          { error: `Debate with ID ${debateId} not found` },
          { status: 404 }
        );
      }
      return NextResponse.json({ debate });
    } catch (error) {
      console.error('Error fetching debate:', error);
      return NextResponse.json(
        { error: error instanceof Error ? error.message : 'Unknown error' },
        { status: 500 }
      );
    }
  }
  // Default response
  return NextResponse.json({
    status: 'success',
    message: 'Debate API is working',
    availableActions: ['test', 'get-debate'],
    note: 'Use with query parameters: ?action=test or ?debateId=your-debate-id',
    timestamp: new Date().toISOString()
  });
}
</file>

<file path="src/app/api/debate-fixed/route.ts">
import { NextRequest, NextResponse } from 'next/server';
import { Message } from '@/types/message';
import { Expert } from '@/types/expert';
import { v4 as uuidv4 } from 'uuid';
import { DebateStorage } from '@/lib/storage/debate-storage';
import { selectExperts } from '@/lib/ai/expert-selector';
import { generateResponse } from '@/lib/ai/response-generator';
// Handle all debate-related API requests
export async function POST(request: NextRequest) {
    try {
        console.log('Debate API called with method:', request.method);
        const body = await request.json();
        console.log('Debate API request body:', body);
        const { action } = body;
        console.log('Debate API action:', action);
        switch (action) {
            case 'select-experts':
                return handleSelectExperts(body);
            case 'initialize-debate':
                return handleInitializeDebate(body);
            case 'generate-response':
                return handleGenerateResponse(body);
            case 'test':
                // Simple test case
                return NextResponse.json({
                    message: 'Debate API test successful',
                    receivedData: body,
                    timestamp: new Date().toISOString()
                });
            default:
                console.error(`Unknown action: ${action}`);
                return NextResponse.json(
                    { error: `Unknown action: ${action}` },
                    { status: 400 }
                );
        }
    } catch (error) {
        console.error('Error in debate API:', error);
        return NextResponse.json(
            { error: error instanceof Error ? error.message : 'Unknown error' },
            { status: 500 }
        );
    }
}
// Handle selecting experts for a debate
async function handleSelectExperts(req: any) {
    console.log('handleSelectExperts called with:', req);
    const { topic, expertType = 'historical', count = 2 } = req;
    if (!topic) {
        console.error('Topic is required');
        return NextResponse.json({ error: 'Topic is required' }, { status: 400 });
    }
    try {
        console.log(`API: Selecting ${count} ${expertType} experts for topic: ${topic}`);
        // Try to use the real selectExperts function, but fall back to mock data if it fails
        let experts;
        try {
            experts = await selectExperts(topic, expertType, count);
            console.log('API: Experts selected:', experts);
        } catch (selectError) {
            console.error('Error using selectExperts, falling back to mock data:', selectError);
            // Mock response for testing
            experts = [
                {
                    id: `expert_${Date.now()}_1`,
                    name: 'Albert Einstein',
                    type: expertType,
                    expertise: 'Physics',
                    era: '20th Century',
                    description: 'Theoretical physicist who developed the theory of relativity'
                },
                {
                    id: `expert_${Date.now()}_2`,
                    name: 'Marie Curie',
                    type: expertType,
                    expertise: 'Chemistry and Physics',
                    era: '19th-20th Century',
                    description: 'Physicist and chemist who conducted pioneering research on radioactivity'
                }
            ];
        }
        // Verify experts are of the correct type
        const filteredExperts = experts.filter((expert: Expert) => expert.type === expertType);
        console.log(`API: Selected ${filteredExperts.length} ${expertType} experts`);
        if (filteredExperts.length === 0) {
            throw new Error(`No ${expertType} experts were found for this topic`);
        }
        return NextResponse.json({ experts: filteredExperts });
    } catch (error: any) {
        console.error('Error selecting experts:', error);
        return NextResponse.json(
            { error: error.message || 'Failed to select experts' },
            { status: 500 }
        );
    }
}
// Handle initializing a debate
async function handleInitializeDebate(body: any) {
    const { topic, expertType, userId } = body;
    if (!topic || !expertType || !userId) {
        return NextResponse.json(
            { error: 'Missing required fields: topic, expertType, userId' },
            { status: 400 }
        );
    }
    try {
        // Generate a unique debate ID
        const debateId = `debate_${Date.now()}_${Math.random().toString(36).substring(2, 9)}`;
        // Try to use the real selectExperts function, but fall back to mock data if it fails
        let experts;
        try {
            experts = await selectExperts(topic, expertType, 2);
        } catch (selectError) {
            console.error('Error using selectExperts, falling back to mock data:', selectError);
            // Mock experts for testing
            experts = [
                {
                    id: `expert_${Date.now()}_1`,
                    name: 'Albert Einstein',
                    type: expertType,
                    expertise: 'Physics',
                    era: '20th Century',
                    description: 'Theoretical physicist who developed the theory of relativity'
                },
                {
                    id: `expert_${Date.now()}_2`,
                    name: 'Marie Curie',
                    type: expertType,
                    expertise: 'Chemistry and Physics',
                    era: '19th-20th Century',
                    description: 'Physicist and chemist who conducted pioneering research on radioactivity'
                }
            ];
        }
        // Try to initialize the debate in storage, but don't fail if it doesn't work
        try {
            const debateStorage = await DebateStorage.getInstance();
            await debateStorage.initializeDebate(debateId, topic, experts, userId);
        } catch (storageError) {
            console.error('Error initializing debate in storage:', storageError);
            // Continue anyway since we can return the debate ID and experts
        }
        return NextResponse.json({ debateId, topic, experts });
    } catch (error: any) {
        console.error('Error initializing debate:', error);
        return NextResponse.json(
            { error: error.message || 'Failed to initialize debate' },
            { status: 500 }
        );
    }
}
// Handle generating a response
async function handleGenerateResponse(body: any) {
    const { expert, topic, messages, useCitations = true, debateId } = body;
    if (!expert || !topic || !messages) {
        return NextResponse.json(
            { error: 'Missing required fields: expert, topic, messages' },
            { status: 400 }
        );
    }
    try {
        // Try to use the real generateResponse function, but fall back to mock data if it fails
        let response, usage;
        try {
            const result = await generateResponse(expert, topic, messages, useCitations);
            response = result.response;
            usage = result.usage;
        } catch (generateError) {
            console.error('Error using generateResponse, falling back to mock data:', generateError);
            // Mock response for testing
            response = `This is a mock response from ${expert.name} about ${topic}. This is just a test response to verify the API is working correctly.`;
            usage = { prompt_tokens: 100, completion_tokens: 150, total_tokens: 250 };
        }
        // If debateId is provided, try to store the message
        if (debateId) {
            try {
                const newMessage = {
                    id: `msg_${Date.now()}_${expert.id}`,
                    role: 'assistant' as const,
                    content: response,
                    speaker: expert.name,
                    timestamp: new Date().toISOString(),
                    usage
                };
                const debateStorage = await DebateStorage.getInstance();
                await debateStorage.addMessage(debateId, newMessage);
            } catch (storageError) {
                console.error('Error storing message:', storageError);
                // Continue anyway since we can return the response
            }
        }
        return NextResponse.json({ response, usage });
    } catch (error: any) {
        console.error('Error generating response:', error);
        return NextResponse.json(
            { error: error.message || 'Failed to generate response' },
            { status: 500 }
        );
    }
}
// Simple test endpoint for the debate API
export async function GET(request: NextRequest) {
    console.log('Debate API GET called');
    // Extract query parameters
    const searchParams = request.nextUrl.searchParams;
    const action = searchParams.get('action');
    const debateId = searchParams.get('debateId');
    console.log('Debate API GET params:', { action, debateId });
    // Handle different actions
    if (action === 'test') {
        return NextResponse.json({
            status: 'success',
            message: 'Debate API test endpoint is working',
            timestamp: new Date().toISOString()
        });
    }
    // If debateId is provided, try to fetch debate data
    if (debateId) {
        try {
            const debateStorage = await DebateStorage.getInstance();
            const debate = await debateStorage.getDebate(debateId);
            if (!debate) {
                return NextResponse.json(
                    { error: `Debate with ID ${debateId} not found` },
                    { status: 404 }
                );
            }
            return NextResponse.json({ debate });
        } catch (error) {
            console.error('Error fetching debate:', error);
            return NextResponse.json(
                { error: error instanceof Error ? error.message : 'Unknown error' },
                { status: 500 }
            );
        }
    }
    // Default response
    return NextResponse.json({
        status: 'success',
        message: 'Debate API is working',
        availableActions: ['test', 'get-debate'],
        note: 'Use with query parameters: ?action=test or ?debateId=your-debate-id',
        timestamp: new Date().toISOString()
    });
}
</file>

<file path="src/app/api/debate-new/route.ts">
import { NextRequest, NextResponse } from 'next/server';
import { Message } from '@/types/message';
import { Expert } from '@/types/expert';
import { v4 as uuidv4 } from 'uuid';
import { DebateStorage } from '@/lib/storage/debate-storage';
import { selectExperts } from '@/lib/ai/expert-selector';
import { generateResponse } from '@/lib/ai/response-generator';
// Handle all debate-related API requests
export async function POST(request: NextRequest) {
    try {
        console.log('Debate API called with method:', request.method);
        const body = await request.json();
        console.log('Debate API request body:', body);
        const { action } = body;
        console.log('Debate API action:', action);
        switch (action) {
            case 'select-experts':
                return handleSelectExperts(body);
            case 'initialize-debate':
                return handleInitializeDebate(body);
            case 'generate-response':
                return handleGenerateResponse(body);
            case 'test':
                // Simple test case
                return NextResponse.json({
                    message: 'Debate API test successful',
                    receivedData: body
                });
            default:
                console.error(`Unknown action: ${action}`);
                return NextResponse.json(
                    { error: `Unknown action: ${action}` },
                    { status: 400 }
                );
        }
    } catch (error) {
        console.error('Error in debate API:', error);
        return NextResponse.json(
            { error: error instanceof Error ? error.message : 'Unknown error' },
            { status: 500 }
        );
    }
}
// Handle selecting experts for a debate
async function handleSelectExperts(req: any) {
    console.log('handleSelectExperts called with:', req);
    const { topic, expertType = 'historical', count = 2 } = req;
    if (!topic) {
        console.error('Topic is required');
        return NextResponse.json({ error: 'Topic is required' }, { status: 400 });
    }
    try {
        console.log(`API: Selecting ${count} ${expertType} experts for topic: ${topic}`);
        // Mock response for testing
        const experts = [
            {
                id: `expert_${Date.now()}_1`,
                name: 'Albert Einstein',
                type: expertType,
                expertise: 'Physics',
                era: '20th Century',
                description: 'Theoretical physicist who developed the theory of relativity'
            },
            {
                id: `expert_${Date.now()}_2`,
                name: 'Marie Curie',
                type: expertType,
                expertise: 'Chemistry and Physics',
                era: '19th-20th Century',
                description: 'Physicist and chemist who conducted pioneering research on radioactivity'
            }
        ];
        console.log('API: Experts selected:', experts);
        return NextResponse.json({ experts });
    } catch (error: any) {
        console.error('Error selecting experts:', error);
        return NextResponse.json(
            { error: error.message || 'Failed to select experts' },
            { status: 500 }
        );
    }
}
// Handle initializing a debate
async function handleInitializeDebate(body: any) {
    const { topic, expertType, userId } = body;
    if (!topic || !expertType || !userId) {
        return NextResponse.json(
            { error: 'Missing required fields: topic, expertType, userId' },
            { status: 400 }
        );
    }
    try {
        // Generate a unique debate ID
        const debateId = `debate_${Date.now()}_${Math.random().toString(36).substring(2, 9)}`;
        // Mock experts for testing
        const experts = [
            {
                id: `expert_${Date.now()}_1`,
                name: 'Albert Einstein',
                type: expertType,
                expertise: 'Physics',
                era: '20th Century',
                description: 'Theoretical physicist who developed the theory of relativity'
            },
            {
                id: `expert_${Date.now()}_2`,
                name: 'Marie Curie',
                type: expertType,
                expertise: 'Chemistry and Physics',
                era: '19th-20th Century',
                description: 'Physicist and chemist who conducted pioneering research on radioactivity'
            }
        ];
        return NextResponse.json({ debateId, topic, experts });
    } catch (error: any) {
        console.error('Error initializing debate:', error);
        return NextResponse.json(
            { error: error.message || 'Failed to initialize debate' },
            { status: 500 }
        );
    }
}
// Handle generating a response
async function handleGenerateResponse(body: any) {
    const { expert, topic, messages, useCitations = true, debateId } = body;
    if (!expert || !topic || !messages) {
        return NextResponse.json(
            { error: 'Missing required fields: expert, topic, messages' },
            { status: 400 }
        );
    }
    try {
        // Mock response for testing
        const response = `This is a mock response from ${expert.name} about ${topic}. This is just a test response to verify the API is working correctly.`;
        const usage = { prompt_tokens: 100, completion_tokens: 150, total_tokens: 250 };
        return NextResponse.json({ response, usage });
    } catch (error: any) {
        console.error('Error generating response:', error);
        return NextResponse.json(
            { error: error.message || 'Failed to generate response' },
            { status: 500 }
        );
    }
}
// Simple test endpoint for the debate API
export async function GET(request: NextRequest) {
    console.log('Debate API GET called');
    // Extract query parameters
    const searchParams = request.nextUrl.searchParams;
    const action = searchParams.get('action');
    const debateId = searchParams.get('debateId');
    console.log('Debate API GET params:', { action, debateId });
    // Handle different actions
    if (action === 'test') {
        return NextResponse.json({
            status: 'success',
            message: 'Debate API test endpoint is working',
            timestamp: new Date().toISOString()
        });
    }
    // Default response
    return NextResponse.json({
        status: 'success',
        message: 'Debate API is working',
        availableActions: ['test', 'get-debate'],
        note: 'Use with query parameters: ?action=test or ?debateId=your-debate-id',
        timestamp: new Date().toISOString()
    });
}
</file>

<file path="src/app/api/debate-simple/route.ts">
import { NextRequest, NextResponse } from 'next/server';
// Mock data for testing
const mockExperts = [
    {
        id: 'expert_1',
        name: 'Albert Einstein',
        type: 'historical',
        expertise: 'Physics',
        era: '20th Century',
        description: 'Theoretical physicist who developed the theory of relativity'
    },
    {
        id: 'expert_2',
        name: 'Marie Curie',
        type: 'historical',
        expertise: 'Chemistry and Physics',
        era: '19th-20th Century',
        description: 'Physicist and chemist who conducted pioneering research on radioactivity'
    },
    {
        id: 'expert_3',
        name: 'Stephen Hawking',
        type: 'historical',
        expertise: 'Theoretical Physics',
        era: '20th-21st Century',
        description: 'Theoretical physicist known for his work on black holes and relativity'
    },
    {
        id: 'expert_4',
        name: 'Climate Scientist',
        type: 'domain',
        expertise: 'Climate Science',
        era: 'Contemporary',
        description: 'Expert in climate science and environmental impacts'
    },
    {
        id: 'expert_5',
        name: 'AI Ethicist',
        type: 'domain',
        expertise: 'AI Ethics',
        era: 'Contemporary',
        description: 'Specialist in ethical considerations of artificial intelligence'
    }
];
// Handle all debate-related API requests
export async function POST(request: NextRequest) {
    try {
        console.log('Debate API called with method:', request.method);
        const body = await request.json();
        console.log('Debate API request body:', body);
        const { action } = body;
        console.log('Debate API action:', action);
        switch (action) {
            case 'select-experts':
                return handleSelectExperts(body);
            case 'initialize-debate':
                return handleInitializeDebate(body);
            case 'generate-response':
                return handleGenerateResponse(body);
            case 'test':
                // Simple test case
                return NextResponse.json({
                    message: 'Debate API test successful',
                    receivedData: body,
                    timestamp: new Date().toISOString()
                });
            default:
                console.error(`Unknown action: ${action}`);
                return NextResponse.json(
                    { error: `Unknown action: ${action}` },
                    { status: 400 }
                );
        }
    } catch (error) {
        console.error('Error in debate API:', error);
        return NextResponse.json(
            { error: error instanceof Error ? error.message : 'Unknown error' },
            { status: 500 }
        );
    }
}
// Handle selecting experts for a debate
async function handleSelectExperts(req: any) {
    console.log('handleSelectExperts called with:', req);
    const { topic, expertType = 'historical', count = 2 } = req;
    if (!topic) {
        console.error('Topic is required');
        return NextResponse.json({ error: 'Topic is required' }, { status: 400 });
    }
    try {
        console.log(`API: Selecting ${count} ${expertType} experts for topic: ${topic}`);
        // Filter experts by type
        const filteredExperts = mockExperts.filter(expert => expert.type === expertType);
        // Randomly select the requested number of experts
        const selectedExperts = filteredExperts
            .sort(() => 0.5 - Math.random())
            .slice(0, count);
        console.log(`API: Selected ${selectedExperts.length} ${expertType} experts`);
        if (selectedExperts.length === 0) {
            throw new Error(`No ${expertType} experts were found for this topic`);
        }
        return NextResponse.json({ experts: selectedExperts });
    } catch (error: any) {
        console.error('Error selecting experts:', error);
        return NextResponse.json(
            { error: error.message || 'Failed to select experts' },
            { status: 500 }
        );
    }
}
// Handle initializing a debate
async function handleInitializeDebate(body: any) {
    const { topic, expertType, userId } = body;
    if (!topic || !expertType || !userId) {
        return NextResponse.json(
            { error: 'Missing required fields: topic, expertType, userId' },
            { status: 400 }
        );
    }
    try {
        // Generate a unique debate ID
        const debateId = `debate_${Date.now()}_${Math.random().toString(36).substring(2, 9)}`;
        // Filter experts by type
        const filteredExperts = mockExperts.filter(expert => expert.type === expertType);
        // Randomly select 2 experts
        const experts = filteredExperts
            .sort(() => 0.5 - Math.random())
            .slice(0, 2);
        return NextResponse.json({ debateId, topic, experts });
    } catch (error: any) {
        console.error('Error initializing debate:', error);
        return NextResponse.json(
            { error: error.message || 'Failed to initialize debate' },
            { status: 500 }
        );
    }
}
// Handle generating a response
async function handleGenerateResponse(body: any) {
    const { expert, topic, messages } = body;
    if (!expert || !topic || !messages) {
        return NextResponse.json(
            { error: 'Missing required fields: expert, topic, messages' },
            { status: 400 }
        );
    }
    try {
        // Mock response for testing
        const response = `This is a mock response from ${expert.name} about ${topic}. This is just a test response to verify the API is working correctly.`;
        const usage = { prompt_tokens: 100, completion_tokens: 150, total_tokens: 250 };
        return NextResponse.json({ response, usage });
    } catch (error: any) {
        console.error('Error generating response:', error);
        return NextResponse.json(
            { error: error.message || 'Failed to generate response' },
            { status: 500 }
        );
    }
}
// Simple test endpoint for the debate API
export async function GET(request: NextRequest) {
    console.log('Debate API GET called');
    // Extract query parameters
    const searchParams = request.nextUrl.searchParams;
    const action = searchParams.get('action');
    const debateId = searchParams.get('debateId');
    console.log('Debate API GET params:', { action, debateId });
    // Handle different actions
    if (action === 'test') {
        return NextResponse.json({
            status: 'success',
            message: 'Debate API test endpoint is working',
            timestamp: new Date().toISOString()
        });
    }
    // If debateId is provided, return mock debate data
    if (debateId) {
        const mockDebate = {
            id: debateId,
            topic: 'Mock Topic',
            experts: mockExperts.slice(0, 2),
            messages: [
                {
                    id: 'msg_1',
                    role: 'assistant',
                    content: 'This is a mock message from the debate.',
                    speaker: mockExperts[0].name,
                    timestamp: new Date().toISOString()
                }
            ]
        };
        return NextResponse.json({ debate: mockDebate });
    }
    // Default response
    return NextResponse.json({
        status: 'success',
        message: 'Debate API is working',
        availableActions: ['test', 'get-debate'],
        note: 'Use with query parameters: ?action=test or ?debateId=your-debate-id',
        timestamp: new Date().toISOString()
    });
}
</file>

<file path="src/app/api/debate-test/route.ts">
import { NextRequest, NextResponse } from 'next/server';
export async function GET(request: NextRequest) {
    return NextResponse.json({
        message: 'Debate Test API is working',
        timestamp: new Date().toISOString()
    });
}
export async function POST(request: NextRequest) {
    try {
        const body = await request.json();
        const { action } = body;
        console.log('Debate Test API called with action:', action);
        switch (action) {
            case 'test':
                return NextResponse.json({
                    message: 'Debate Test API test action successful',
                    receivedData: body,
                    timestamp: new Date().toISOString()
                });
            case 'select-experts':
                return NextResponse.json({
                    message: 'Mock select experts response',
                    experts: [
                        { id: 'expert1', name: 'Expert 1', type: body.expertType || 'historical' },
                        { id: 'expert2', name: 'Expert 2', type: body.expertType || 'historical' }
                    ],
                    timestamp: new Date().toISOString()
                });
            default:
                return NextResponse.json({
                    error: `Unknown action: ${action}`,
                    timestamp: new Date().toISOString()
                }, { status: 400 });
        }
    } catch (error) {
        console.error('Error in debate test API:', error);
        return NextResponse.json({
            error: error instanceof Error ? error.message : 'Unknown error',
            timestamp: new Date().toISOString()
        }, { status: 500 });
    }
}
</file>

<file path="src/app/api/hello/route.ts">
import { NextRequest, NextResponse } from 'next/server';
export async function GET(request: NextRequest) {
    return NextResponse.json({
        message: 'Hello API is working',
        timestamp: new Date().toISOString()
    });
}
export async function POST(request: NextRequest) {
    try {
        const body = await request.json();
        return NextResponse.json({
            message: 'Hello API POST is working',
            receivedData: body,
            timestamp: new Date().toISOString()
        });
    } catch (error) {
        console.error('Error in hello API:', error);
        return NextResponse.json({
            error: error instanceof Error ? error.message : 'Unknown error',
            timestamp: new Date().toISOString()
        }, { status: 500 });
    }
}
</file>

<file path="src/app/api/test/route.ts">
import { NextRequest, NextResponse } from 'next/server';
export async function GET(request: NextRequest) {
    return NextResponse.json({
        message: 'Test API is working',
        timestamp: new Date().toISOString()
    });
}
export async function POST(request: NextRequest) {
    try {
        const body = await request.json();
        return NextResponse.json({
            message: 'Test API POST is working',
            receivedData: body,
            timestamp: new Date().toISOString()
        });
    } catch (error) {
        console.error('Error in test API:', error);
        return NextResponse.json({
            error: error instanceof Error ? error.message : 'Unknown error',
            timestamp: new Date().toISOString()
        }, { status: 500 });
    }
}
</file>

<file path="src/app/api/test-agents/route.ts">
import { NextRequest, NextResponse } from 'next/server';
import { runIntegrationTests, TestOptions, TestType } from '@/lib/agents/test-integration';
/**
 * API route handler for testing LangChain agent integrations
 * 
 * This endpoint allows running integration tests for the LangChain agents.
 * It accepts POST requests with options for which tests to run and returns
 * the test results.
 * 
 * @param req The incoming request
 * @returns Test results
 */
export async function POST(req: NextRequest) {
    try {
        // Check if we're in development mode
        if (process.env.NODE_ENV !== 'development' && process.env.ALLOW_TEST_ENDPOINTS !== 'true') {
            return NextResponse.json(
                { error: 'Test endpoints are only available in development mode' },
                { status: 403 }
            );
        }
        // Parse the request body
        const body = await req.json();
        // Validate request
        if (!body) {
            return NextResponse.json(
                { error: 'Request body is required' },
                { status: 400 }
            );
        }
        // Extract test options
        const options: TestOptions = {
            topic: body.topic || 'climate change',
            testType: (body.testType as TestType) || 'all',
            verbose: body.verbose || false
        };
        console.log(`API: Running integration tests for ${options.testType} with topic "${options.topic}"`);
        // Run the integration tests
        const results = await runIntegrationTests(options);
        // Calculate overall success
        const allTests = Object.values(results);
        const successCount = allTests.filter(result => result.success).length;
        const totalTests = allTests.length;
        return NextResponse.json({
            message: `Completed ${successCount}/${totalTests} tests successfully`,
            results,
            success: successCount === totalTests
        });
    } catch (error) {
        console.error('Error in test-agents API route:', error);
        return NextResponse.json(
            {
                error: 'An error occurred while running integration tests',
                message: error instanceof Error ? error.message : String(error)
            },
            { status: 500 }
        );
    }
}
/**
 * API route handler for GET requests
 * 
 * Provides simple instructions on how to use the test endpoint
 * 
 * @returns Instructions for using the API
 */
export async function GET() {
    return NextResponse.json({
        message: 'LangChain Integration Test API',
        usage: {
            method: 'POST',
            body: {
                topic: 'optional debate topic (default: "climate change")',
                testType: 'optional test type (knowledge-retrieval, fact-checking, context-management, all)',
                verbose: 'optional boolean to enable detailed logging (default: false)'
            },
            example: {
                topic: 'renewable energy',
                testType: 'all',
                verbose: true
            }
        }
    });
}
</file>

<file path="src/app/api/test-api/route.ts">
import { NextRequest, NextResponse } from 'next/server';
/**
 * Simple test API endpoint to verify API routes are working
 */
export async function GET(request: NextRequest) {
    console.log('Test API GET called');
    return NextResponse.json({
        status: 'success',
        message: 'Test API is working',
        method: 'GET',
        timestamp: new Date().toISOString()
    });
}
export async function POST(request: NextRequest) {
    console.log('Test API POST called');
    let body = {};
    try {
        body = await request.json();
        console.log('Test API received body:', body);
    } catch (error) {
        console.error('Error parsing request body:', error);
    }
    return NextResponse.json({
        status: 'success',
        message: 'Test API POST is working',
        method: 'POST',
        receivedData: body,
        timestamp: new Date().toISOString()
    });
}
</file>

<file path="src/app/api/test-redis/route.ts">
import { NextRequest, NextResponse } from 'next/server'
import { DebateStorage } from '@/lib/storage/debate-storage'
export async function GET(request: NextRequest) {
    console.log('Test Redis API called')
    try {
        // Get the DebateStorage instance
        const debateStorage = await DebateStorage.getInstance()
        // Test Redis connection with a simple key/value
        const testKey = `test_${Date.now()}`
        const testValue = `Test value at ${new Date().toISOString()}`
        // Test Redis connection
        const testResult = await debateStorage.testRedisConnection(testKey, testValue)
        return NextResponse.json({
            status: 'success',
            message: 'Redis test completed',
            result: testResult,
            timestamp: new Date().toISOString()
        })
    } catch (error) {
        console.error('Error testing Redis:', error)
        return NextResponse.json({
            status: 'error',
            message: 'Failed to test Redis',
            error: error instanceof Error ? error.message : 'Unknown error',
            timestamp: new Date().toISOString()
        }, { status: 500 })
    }
}
</file>

<file path="src/app/api/user/account/delete/route.ts">
import { NextRequest, NextResponse } from 'next/server';
import { deleteUser, getUserById } from '@/lib/db/models/user';
import { getServerSession } from 'next-auth';
import { authOptions } from '@/lib/auth';
/**
 * DELETE /api/user/account/delete
 * Delete a user's account and all associated data
 */
export async function DELETE(request: NextRequest) {
    try {
        // Check if user is authenticated
        const session = await getServerSession(authOptions);
        if (!session || !session.user || !session.user.id) {
            return NextResponse.json(
                { error: 'Unauthorized: Please sign in to access this resource' },
                { status: 401 }
            );
        }
        const userId = session.user.id;
        // Check if user exists
        const userProfile = await getUserById(userId);
        if (!userProfile) {
            return NextResponse.json(
                { error: 'User profile not found' },
                { status: 404 }
            );
        }
        // Delete user account
        await deleteUser(userId);
        return NextResponse.json({
            success: true,
            message: 'Your account has been successfully deleted.'
        });
    } catch (error) {
        console.error('Error deleting user account:', error);
        return NextResponse.json(
            {
                error: 'Internal server error',
                details: error instanceof Error ? error.message : 'Unknown error'
            },
            { status: 500 }
        );
    }
}
</file>

<file path="src/app/api/user/preferences/route.ts">
import { NextRequest, NextResponse } from 'next/server';
import { getUserById, updateUserProfile, createUser } from '@/lib/db/models/user';
import { getServerSession } from 'next-auth';
import { authOptions } from '@/lib/auth';
/**
 * GET /api/user/preferences
 * Fetch a user's preferences
 */
export async function GET() {
    try {
        // Check if user is authenticated
        const session = await getServerSession(authOptions);
        if (!session || !session.user || !session.user.id) {
            console.error('Unauthorized access attempt to user preferences API');
            return NextResponse.json(
                { error: 'Unauthorized: Please sign in to access this resource' },
                { status: 401 }
            );
        }
        // Get user preferences from database
        const userId = session.user.id;
        console.log(`Fetching preferences for user ID: ${userId}`);
        try {
            let userProfile = await getUserById(userId);
            // Create a new user profile if one doesn't exist
            if (!userProfile) {
                console.log(`No existing profile found for ID: ${userId}, creating new profile`);
                // Use session data to create a basic profile
                const userData = {
                    id: userId,
                    email: session.user.email || `${userId}@example.com`,
                    name: session.user.name || 'New User',
                    createdAt: new Date().toISOString(),
                    updatedAt: new Date().toISOString(),
                    lastLoginAt: new Date().toISOString(),
                    profilePicture: session.user.image || null,
                    preferredLanguage: 'en',
                    preferredTopics: [],
                    expertTypes: ['domain', 'historical'],
                    settings: {
                        notifications: true,
                        theme: 'system'
                    }
                };
                try {
                    userProfile = await createUser(userData);
                    console.log(`Successfully created new profile for user ID: ${userId}`);
                } catch (createError) {
                    const errorMessage = createError instanceof Error ? createError.message : 'Unknown error';
                    console.error('Error creating new user profile:', errorMessage);
                    return NextResponse.json(
                        { error: `Failed to create user profile: ${errorMessage}` },
                        { status: 500 }
                    );
                }
            }
            // Extract just the preferences-related fields
            const { preferredLanguage, preferredTopics, expertTypes, settings } = userProfile;
            return NextResponse.json({ preferredLanguage, preferredTopics, expertTypes, settings });
        } catch (dbError) {
            const errorMessage = dbError instanceof Error ? dbError.message : 'Unknown database error';
            console.error('Database error fetching user preferences:', errorMessage);
            return NextResponse.json(
                { error: `Database error: ${errorMessage}` },
                { status: 500 }
            );
        }
    } catch (error) {
        const errorMessage = error instanceof Error ? error.message : 'Unknown error';
        console.error('Error fetching user preferences:', errorMessage);
        return NextResponse.json(
            { error: `Error fetching user preferences: ${errorMessage}` },
            { status: 500 }
        );
    }
}
/**
 * PUT /api/user/preferences
 * Update a user's preferences
 */
export async function PUT(request: NextRequest) {
    try {
        // Check if user is authenticated
        const session = await getServerSession(authOptions);
        if (!session || !session.user || !session.user.id) {
            console.error('Unauthorized attempt to update user preferences');
            return NextResponse.json(
                { error: 'Unauthorized: Please sign in to update preferences' },
                { status: 401 }
            );
        }
        // Parse request body
        const userId = session.user.id;
        const preferenceData = await request.json();
        console.log(`Updating preferences for user ID: ${userId}`);
        try {
            // Update user profile with new preference data
            const updatedProfile = await updateUserProfile(userId, preferenceData);
            console.log(`Successfully updated preferences for user ID: ${userId}`);
            return NextResponse.json({
                success: true,
                preferences: {
                    preferredLanguage: updatedProfile.preferredLanguage,
                    preferredTopics: updatedProfile.preferredTopics,
                    expertTypes: updatedProfile.expertTypes,
                    settings: updatedProfile.settings
                }
            });
        } catch (dbError) {
            const errorMessage = dbError instanceof Error ? dbError.message : 'Unknown database error';
            console.error('Database error updating user preferences:', errorMessage);
            return NextResponse.json(
                { error: `Database error: ${errorMessage}` },
                { status: 500 }
            );
        }
    } catch (error) {
        const errorMessage = error instanceof Error ? error.message : 'Unknown error';
        console.error('Error updating user preferences:', errorMessage);
        return NextResponse.json(
            { error: `Error updating user preferences: ${errorMessage}` },
            { status: 500 }
        );
    }
}
</file>

<file path="src/app/api/user/profile/update/route.ts">
import { NextRequest, NextResponse } from 'next/server';
import { getUserById, updateUserProfile, createUser } from '@/lib/db/models/user';
import { getServerSession } from 'next-auth';
import { authOptions } from '@/lib/auth';
/**
 * PUT /api/user/profile/update
 * Update a user's profile
 */
export async function PUT(request: NextRequest) {
    try {
        // Check if user is authenticated
        const session = await getServerSession(authOptions);
        if (!session || !session.user || !session.user.id) {
            console.error('Unauthorized attempt to update user profile');
            return NextResponse.json(
                { error: 'Unauthorized: Please sign in to update your profile' },
                { status: 401 }
            );
        }
        // Parse the request body
        const userId = session.user.id;
        const profileData = await request.json();
        console.log(`Updating profile for user ID: ${userId}`);
        try {
            // First check if user exists
            let existingUser = await getUserById(userId);
            if (!existingUser) {
                console.log(`User profile not found for ID: ${userId}, creating new profile`);
                // Use session data to create a basic profile with the updates applied
                const userData = {
                    id: userId,
                    email: session.user.email || `${userId}@example.com`,
                    name: session.user.name || 'New User',
                    createdAt: new Date().toISOString(),
                    updatedAt: new Date().toISOString(),
                    lastLoginAt: new Date().toISOString(),
                    profilePicture: session.user.image || null,
                    ...profileData // Include the update data in the initial profile
                };
                try {
                    existingUser = await createUser(userData);
                    console.log(`Successfully created new profile for user ID: ${userId}`);
                    return NextResponse.json({
                        success: true,
                        profile: existingUser,
                        created: true
                    });
                } catch (createError) {
                    const errorMessage = createError instanceof Error ? createError.message : 'Unknown error';
                    console.error('Error creating new user profile:', errorMessage);
                    return NextResponse.json(
                        { error: `Failed to create user profile: ${errorMessage}` },
                        { status: 500 }
                    );
                }
            }
            // Update the user's profile in the database
            const updatedProfile = await updateUserProfile(userId, profileData);
            console.log(`Successfully updated profile for user ID: ${userId}`);
            return NextResponse.json({
                success: true,
                profile: updatedProfile
            });
        } catch (dbError) {
            const errorMessage = dbError instanceof Error ? dbError.message : 'Unknown database error';
            console.error('Database error updating user profile:', errorMessage);
            // Don't create mock data, propagate the error
            return NextResponse.json(
                { error: errorMessage },
                { status: 500 }
            );
        }
    } catch (error) {
        const errorMessage = error instanceof Error ? error.message : 'Unknown error';
        console.error('Error updating user profile:', errorMessage);
        return NextResponse.json(
            { error: errorMessage },
            { status: 500 }
        );
    }
}
</file>

<file path="src/app/api/user/profile/route.ts">
import { NextRequest, NextResponse } from 'next/server';
import { getUserById, createUser, createDefaultUserProfile } from '@/lib/db/models/user';
import { getServerSession } from 'next-auth';
import { authOptions } from '@/lib/auth';
/**
 * GET /api/user/profile
 * Fetch a user's profile
 */
export async function GET() {
    try {
        // Check if user is authenticated
        const session = await getServerSession(authOptions);
        if (!session || !session.user || !session.user.id) {
            console.error('Unauthorized access attempt to user profile API');
            return NextResponse.json(
                { error: 'Unauthorized: Please sign in to access this resource' },
                { status: 401 }
            );
        }
        // Get user profile from database
        const userId = session.user.id;
        console.log(`Fetching profile for user ID: ${userId}`);
        try {
            let userProfile = await getUserById(userId);
            // Create a new user profile if one doesn't exist
            if (!userProfile) {
                console.log(`No existing profile found for ID: ${userId}, creating new profile`);
                // Use session data to create a basic profile
                const userData = {
                    id: userId,
                    email: session.user.email || `${userId}@example.com`,
                    name: session.user.name || 'New User',
                    createdAt: new Date().toISOString(),
                    updatedAt: new Date().toISOString(),
                    lastLoginAt: new Date().toISOString(),
                    profilePicture: session.user.image || null,
                    preferredLanguage: 'en',
                    preferredTopics: [],
                    expertTypes: ['domain', 'historical'],
                    settings: {
                        notifications: true,
                        theme: 'system'
                    }
                };
                try {
                    userProfile = await createUser(userData);
                    console.log(`Successfully created new profile for user ID: ${userId}`);
                } catch (createError) {
                    const errorMessage = createError instanceof Error ? createError.message : 'Unknown error';
                    console.error('Error creating new user profile:', errorMessage);
                    return NextResponse.json(
                        { error: `Failed to create user profile: ${errorMessage}` },
                        { status: 500 }
                    );
                }
            }
            return NextResponse.json(userProfile);
        } catch (dbError) {
            const errorMessage = dbError instanceof Error ? dbError.message : 'Unknown database error';
            console.error('Database error fetching user profile:', errorMessage);
            // Don't fall back to mock data, propagate the error
            return NextResponse.json(
                { error: errorMessage },
                { status: 500 }
            );
        }
    } catch (error) {
        const errorMessage = error instanceof Error ? error.message : 'Unknown error';
        console.error('Error fetching user profile:', errorMessage);
        return NextResponse.json(
            { error: errorMessage },
            { status: 500 }
        );
    }
}
</file>

<file path="src/app/api/voice/route.ts">
import { NextRequest, NextResponse } from 'next/server';
import { textToSpeech, getVoices, synthesizeSpeech } from '@/lib/elevenlabs';
// Helper function to safely stringify objects
function safeStringify(obj: any): string {
    try {
        return JSON.stringify(obj, null, 2);
    } catch (error) {
        return `[Error stringifying object: ${error}]`;
    }
}
export async function POST(request: NextRequest) {
    // Add request ID for tracking
    const requestId = Math.random().toString(36).substring(7);
    console.log(`[${requestId}] Starting voice API request`);
    try {
        // Log environment check
        console.log(`[${requestId}] Environment check:`, {
            nodeEnv: process.env.NODE_ENV,
            hasElevenLabsKey: !!process.env.ELEVENLABS_API_KEY,
            envKeys: Object.keys(process.env)
        });
        const body = await request.json();
        const { action, text, voiceId, settings } = body;
        console.log(`[${requestId}] Request details:`, {
            action,
            textLength: text?.length,
            textPreview: text ? `${text.substring(0, 50)}...` : undefined,
            voiceId,
            hasSettings: !!settings,
            settingsKeys: settings ? Object.keys(settings) : undefined
        });
        if (action === 'synthesize') {
            if (!text || !voiceId) {
                const missingParams = [];
                if (!text) missingParams.push('text');
                if (!voiceId) missingParams.push('voiceId');
                const error = `Missing required parameters: ${missingParams.join(', ')}`;
                console.error(`[${requestId}] Validation error:`, error);
                return NextResponse.json({ error, requestId }, { status: 400 });
            }
            try {
                console.log(`[${requestId}] Initiating speech synthesis:`, {
                    voiceId,
                    textLength: text.length,
                    textPreview: `${text.substring(0, 50)}...`
                });
                const startTime = Date.now();
                const { audioBuffer, usage } = await textToSpeech(text, voiceId, settings);
                const duration = Date.now() - startTime;
                if (!audioBuffer || audioBuffer.byteLength === 0) {
                    console.error(`[${requestId}] Empty audio buffer received`);
                    return NextResponse.json({
                        error: 'Received empty audio buffer',
                        requestId
                    }, { status: 500 });
                }
                console.log(`[${requestId}] Speech synthesis successful:`, {
                    duration: `${duration}ms`,
                    bufferSize: audioBuffer.byteLength,
                    contentType: 'audio/mpeg',
                    usage
                });
                const response = new NextResponse(audioBuffer, {
                    headers: {
                        'Content-Type': 'audio/mpeg',
                        'Content-Length': audioBuffer.byteLength.toString(),
                        'X-Request-ID': requestId,
                        'X-Character-Count': usage.characterCount.toString(),
                        'X-Cost-USD': usage.cost.toFixed(4)
                    }
                });
                return response;
            } catch (error) {
                console.error(`[${requestId}] Speech synthesis error:`, {
                    error: error instanceof Error ? {
                        name: error.name,
                        message: error.message,
                        stack: error.stack
                    } : error,
                    voiceId,
                    textLength: text.length
                });
                // Check for specific error types
                if (error instanceof Error) {
                    if (error.message.includes('API key')) {
                        return NextResponse.json({
                            error: 'ElevenLabs API key configuration error',
                            details: error.message,
                            requestId
                        }, { status: 401 });
                    }
                    if (error.message.includes('rate limit') || error.message.includes('quota')) {
                        return NextResponse.json({
                            error: 'ElevenLabs API rate limit or quota exceeded',
                            details: error.message,
                            requestId
                        }, { status: 429 });
                    }
                }
                return NextResponse.json({
                    error: 'Speech synthesis failed',
                    details: error instanceof Error ? error.message : 'Unknown error',
                    requestId
                }, { status: 500 });
            }
        }
        if (action === 'get-voices') {
            try {
                console.log(`[${requestId}] Fetching voices`);
                const voices = await getVoices();
                console.log(`[${requestId}] Successfully fetched voices:`, {
                    count: voices.length,
                    voiceIds: voices.map(v => v.voice_id)
                });
                return NextResponse.json({ voices, requestId });
            } catch (error) {
                console.error(`[${requestId}] Voice fetch error:`, {
                    error: error instanceof Error ? {
                        name: error.name,
                        message: error.message,
                        stack: error.stack
                    } : error
                });
                return NextResponse.json({
                    error: 'Failed to fetch voices',
                    details: error instanceof Error ? error.message : 'Unknown error',
                    requestId
                }, { status: 500 });
            }
        }
        console.error(`[${requestId}] Invalid action:`, action);
        return NextResponse.json({
            error: 'Invalid action',
            requestId
        }, { status: 400 });
    } catch (error) {
        console.error(`[${requestId}] Unhandled API error:`, {
            error: error instanceof Error ? {
                name: error.name,
                message: error.message,
                stack: error.stack
            } : error
        });
        return NextResponse.json({
            error: 'Internal server error',
            details: error instanceof Error ? error.message : 'Unknown error',
            requestId
        }, { status: 500 });
    }
}
</file>

<file path="src/app/api-test/page.tsx">
"use client";
import React, { useState } from 'react';
import { Button } from '@/components/ui/button';
import { Input } from '@/components/ui/input';
import { Textarea } from '@/components/ui/textarea';
export default function ApiTestPage() {
    const [topic, setTopic] = useState('Climate change');
    const [expertType, setExpertType] = useState<'historical' | 'domain'>('historical');
    const [count, setCount] = useState(2);
    const [response, setResponse] = useState<any>(null);
    const [loading, setLoading] = useState(false);
    const [error, setError] = useState<string | null>(null);
    const testSelectExperts = async () => {
        setLoading(true);
        setError(null);
        setResponse(null);
        try {
            console.log(`Testing select-experts with: ${topic}, ${expertType}, ${count}`);
            const res = await fetch('/api/debate', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                    action: 'select-experts',
                    topic,
                    expertType,
                    count
                }),
            });
            const data = await res.json();
            if (!res.ok) {
                throw new Error(data.error || `API error: ${res.status}`);
            }
            setResponse(data);
        } catch (err: any) {
            console.error('Error testing API:', err);
            setError(err.message || 'An unknown error occurred');
        } finally {
            setLoading(false);
        }
    };
    const testApi = async () => {
        setLoading(true);
        setError(null);
        setResponse(null);
        try {
            const res = await fetch('/api/test-api');
            const data = await res.json();
            setResponse(data);
        } catch (err: any) {
            setError(err.message || 'An unknown error occurred');
        } finally {
            setLoading(false);
        }
    };
    const testRedis = async () => {
        setLoading(true);
        setError(null);
        setResponse(null);
        try {
            const res = await fetch('/api/test-redis');
            const data = await res.json();
            if (!res.ok) {
                throw new Error(data.error || `API error: ${res.status}`);
            }
            setResponse(data);
        } catch (err: any) {
            console.error('Error testing Redis:', err);
            setError(err.message || 'An unknown error occurred');
        } finally {
            setLoading(false);
        }
    };
    const testDebateApi = async () => {
        setLoading(true);
        setError(null);
        setResponse(null);
        try {
            const res = await fetch('/api/debate?action=test');
            const data = await res.json();
            if (!res.ok) {
                throw new Error(data.error || `API error: ${res.status}`);
            }
            setResponse(data);
        } catch (err: any) {
            console.error('Error testing debate API:', err);
            setError(err.message || 'An unknown error occurred');
        } finally {
            setLoading(false);
        }
    };
    return (
        <div className="container mx-auto p-4 max-w-3xl">
            <h1 className="text-2xl font-bold mb-6">API Test Page</h1>
            <div className="mb-8 p-4 border rounded-lg">
                <h2 className="text-xl font-semibold mb-4">Test Basic API</h2>
                <div className="flex gap-2">
                    <Button onClick={testApi} disabled={loading}>
                        {loading ? 'Testing...' : 'Test /api/test-api'}
                    </Button>
                    <Button onClick={testDebateApi} disabled={loading}>
                        {loading ? 'Testing...' : 'Test /api/debate'}
                    </Button>
                    <Button onClick={testRedis} disabled={loading}>
                        {loading ? 'Testing...' : 'Test Redis'}
                    </Button>
                </div>
            </div>
            <div className="mb-8 p-4 border rounded-lg">
                <h2 className="text-xl font-semibold mb-4">Test Select Experts</h2>
                <div className="space-y-4 mb-4">
                    <div>
                        <label className="block mb-2">Topic</label>
                        <Input
                            value={topic}
                            onChange={(e) => setTopic(e.target.value)}
                            placeholder="Enter debate topic"
                        />
                    </div>
                    <div>
                        <label className="block mb-2">Expert Type</label>
                        <div className="flex gap-4">
                            <label className="flex items-center">
                                <input
                                    type="radio"
                                    checked={expertType === 'historical'}
                                    onChange={() => setExpertType('historical')}
                                    className="mr-2"
                                />
                                Historical
                            </label>
                            <label className="flex items-center">
                                <input
                                    type="radio"
                                    checked={expertType === 'domain'}
                                    onChange={() => setExpertType('domain')}
                                    className="mr-2"
                                />
                                Domain
                            </label>
                        </div>
                    </div>
                    <div>
                        <label className="block mb-2">Count</label>
                        <Input
                            type="number"
                            value={count}
                            onChange={(e) => setCount(Number(e.target.value))}
                            min={1}
                            max={4}
                        />
                    </div>
                </div>
                <Button onClick={testSelectExperts} disabled={loading}>
                    {loading ? 'Testing...' : 'Test Select Experts'}
                </Button>
            </div>
            {error && (
                <div className="mb-8 p-4 bg-red-100 border border-red-300 rounded-lg text-red-800">
                    <h3 className="font-semibold mb-2">Error</h3>
                    <p>{error}</p>
                </div>
            )}
            {response && (
                <div className="mb-8">
                    <h3 className="font-semibold mb-2">Response</h3>
                    <Textarea
                        value={JSON.stringify(response, null, 2)}
                        readOnly
                        className="w-full h-96 font-mono text-sm"
                    />
                </div>
            )}
        </div>
    );
}
</file>

<file path="src/app/app/debate/layout.tsx">
export default function DebateLayout({
    children,
}: {
    children: React.ReactNode;
}) {
    return (
        <div className="flex min-h-screen flex-col">
            {children}
        </div>
    );
}
</file>

<file path="src/app/app/debate/page.tsx">
"use client";
import { DebatePanel } from '@/components/debate/DebatePanel';
import { ContentUploader } from '@/components/content-processing/ContentUploader';
import { ExpertTypeSelector } from '@/components/debate/ExpertTypeSelector';
import { UserNavigation } from '@/components/UserNavigation';
import Link from 'next/link';
export default function DebatePage() {
    return (
        <div className="flex min-h-screen flex-col">
            <header className="bg-white dark:bg-gray-800 border-b p-4 flex justify-between items-center">
                <Link href="/" className="text-xl font-bold">Debate-Aible</Link>
                <div className="flex items-center gap-4">
                    <nav className="hidden md:flex space-x-6">
                        <Link href="/" className="text-xs font-medium hover:text-primary transition-colors">Home</Link>
                    </nav>
                    <UserNavigation />
                </div>
            </header>
            <div className="max-w-4xl mx-auto w-full p-4">
                <div className="mb-6">
                    <h2 className="text-lg font-semibold mb-2">Welcome to Debate-Aible</h2>
                    <p className="text-sm text-muted-foreground">
                        Upload content to extract debate topics or enter a topic directly to start a debate between AI experts ...and yourself.
                    </p>
                </div>
                <ExpertTypeSelector />
                <ContentUploader />
                <DebatePanel />
            </div>
        </div>
    );
}
</file>

<file path="src/app/app/layout.tsx">
export default function AppLayout({
    children,
}: {
    children: React.ReactNode;
}) {
    return (
        <div className="flex min-h-screen flex-col">
            {children}
        </div>
    );
}
</file>

<file path="src/app/app/page.tsx">
"use client";
import { useEffect } from 'react';
import { useRouter } from 'next/navigation';
export default function AppPage() {
    const router = useRouter();
    useEffect(() => {
        // Redirect to the debate page
        router.push('/app/debate');
    }, [router]);
    return (
        <div className="flex min-h-screen flex-col items-center justify-center">
            <div className="animate-pulse text-center">
                <h1 className="text-2xl font-bold mb-3">Loading Debate-Aible...</h1>
                <p className="text-muted-foreground">Preparing your intellectual experience...</p>
            </div>
        </div>
    );
}
</file>

<file path="src/app/auth/signin/page.tsx">
"use client";
import { signIn, signOut } from "next-auth/react";
import { useSearchParams } from "next/navigation";
import { Button } from "@/components/ui/button";
import Link from "next/link";
import { useState } from "react";
export default function SignIn() {
    const searchParams = useSearchParams();
    const callbackUrl = searchParams.get("callbackUrl") || "/";
    const [error, setError] = useState("");
    const handleGoogleSignIn = async () => {
        try {
            console.log("Starting Google sign-in process");
            // First sign out to clear any existing sessions
            await signOut({ redirect: false });
            console.log("Signed out successfully");
            // Then sign in with Google
            const result = await signIn("google", { 
                callbackUrl,
                redirect: false
            });
            console.log("Sign-in result:", result);
            if (result?.error) {
                setError(`Sign-in error: ${result.error}`);
            }
        } catch (err) {
            console.error("Error during sign-in:", err);
            setError(`Unexpected error: ${err.message}`);
        }
    };
    return (
        <div className="flex min-h-screen flex-col items-center justify-center py-12 px-4 sm:px-6 lg:px-8">
            <div className="w-full max-w-md space-y-8">
                <div className="text-center">
                    <h1 className="text-3xl font-bold">Sign in to Debate-Aible</h1>
                    <p className="mt-2 text-sm text-gray-600 dark:text-gray-400">
                        Access your account and saved debates
                    </p>
                </div>
                {error && (
                    <div className="bg-red-50 border border-red-200 text-red-700 px-4 py-3 rounded">
                        {error}
                    </div>
                )}
                <div className="mt-8 space-y-6">
                    <div className="space-y-4">
                        <Button
                            className="w-full flex items-center justify-center gap-2"
                            onClick={() => signIn("github", { callbackUrl })}
                        >
                            <svg className="h-5 w-5" fill="currentColor" viewBox="0 0 24 24">
                                <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z" />
                            </svg>
                            Continue with GitHub
                        </Button>
                        <Button
                            className="w-full flex items-center justify-center gap-2 bg-white text-black hover:bg-gray-100 border border-gray-300 dark:border-gray-700 dark:bg-gray-800 dark:text-white dark:hover:bg-gray-700"
                            onClick={handleGoogleSignIn}
                        >
                            <svg className="h-5 w-5" viewBox="0 0 24 24" fill="none">
                                <path d="M21.8055 10.0415H21V10H12V14H17.6515C16.827 16.3285 14.6115 18 12 18C8.6865 18 6 15.3135 6 12C6 8.6865 8.6865 6 12 6C13.5295 6 14.921 6.577 15.9805 7.5195L18.809 4.691C17.023 3.0265 14.634 2 12 2C6.4775 2 2 6.4775 2 12C2 17.5225 6.4775 22 12 22C17.5225 22 22 17.5225 22 12C22 11.3295 21.931 10.675 21.8055 10.0415Z" fill="#FFC107" />
                                <path d="M3.15308 7.3455L6.43858 9.755C7.32758 7.554 9.48058 6 12.0001 6C13.5296 6 14.9211 6.577 15.9806 7.5195L18.8091 4.691C17.0231 3.0265 14.6341 2 12.0001 2C8.15908 2 4.82808 4.1685 3.15308 7.3455Z" fill="#FF3D00" />
                                <path d="M12.0001 22C14.5831 22 16.9301 21.0115 18.7046 19.404L15.6097 16.785C14.5719 17.5742 13.3039 18.001 12.0001 18C9.39915 18 7.19015 16.3415 6.35765 14.027L3.09915 16.5395C4.75265 19.778 8.11415 22 12.0001 22Z" fill="#4CAF50" />
                                <path d="M21.8055 10.0415H21V10H12V14H17.6515C17.2571 15.1082 16.5467 16.0766 15.608 16.7855L15.6095 16.7845L18.7045 19.4035C18.4855 19.6025 22 17 22 12C22 11.3295 21.931 10.675 21.8055 10.0415Z" fill="#1976D2" />
                            </svg>
                            Continue with Google
                        </Button>
                    </div>
                </div>
                <p className="mt-4 text-center text-sm text-gray-600 dark:text-gray-400">
                    By signing in, you agree to our{" "}
                    <Link href="/terms" className="font-medium text-primary hover:text-primary-600">
                        Terms of Service
                    </Link>{" "}
                    and{" "}
                    <Link href="/privacy" className="font-medium text-primary hover:text-primary-600">
                        Privacy Policy
                    </Link>
                </p>
            </div>
        </div>
    );
}
</file>

<file path="src/app/profile/page.tsx">
"use client";
import { useState, useEffect, FormEvent } from "react";
import { useSession, signOut } from "next-auth/react";
import { useRouter } from "next/navigation";
import { useToast } from "@/components/ui/use-toast";
import { Tabs, TabsContent, TabsList, TabsTrigger } from "@/components/ui/tabs";
import { Card, CardContent, CardDescription, CardHeader, CardTitle, CardFooter } from "@/components/ui/card";
import { Skeleton } from "@/components/ui/skeleton";
import { Loading } from "@/components/ui/spinner";
import { ProfilePicture } from "@/components/ui/ProfilePicture";
import { AccountDetails } from "@/components/ui/AccountDetails";
import { PreferenceSettings } from "@/components/ui/PreferenceSettings";
import { Button } from "@/components/ui/button";
import { AlertCircle, Trash2 } from "lucide-react";
import {
    AlertDialog,
    AlertDialogAction,
    AlertDialogCancel,
    AlertDialogContent,
    AlertDialogDescription,
    AlertDialogFooter,
    AlertDialogHeader,
    AlertDialogTitle,
} from "@/components/ui/alert-dialog";
import { Input } from "@/components/ui/input";
import { useSettings } from "@/lib/contexts/settings-context";
type UserProfile = {
    id: string;
    email: string;
    name: string;
    profilePicture?: string;
    preferences: {
        defaultExpertType: 'historical' | 'domain';
        useVoiceSynthesis: boolean;
        theme: 'light' | 'dark' | 'system';
    };
};
export default function ProfilePage() {
    const { data: session, status, update } = useSession();
    const router = useRouter();
    const { toast } = useToast();
    const { preferences, updatePreferences } = useSettings();
    const [profile, setProfile] = useState<UserProfile | null>(null);
    const [loading, setLoading] = useState(true);
    const [showDeleteAccountDialog, setShowDeleteAccountDialog] = useState(false);
    const [isDeletingAccount, setIsDeletingAccount] = useState(false);
    const [deleteConfirmation, setDeleteConfirmation] = useState("");
    const [deleteError, setDeleteError] = useState("");
    useEffect(() => {
        if (status === "unauthenticated") {
            router.push("/login");
            return;
        }
        if (status === "authenticated") {
            fetchUserProfile();
        }
    }, [status, router]);
    const fetchUserProfile = async () => {
        try {
            setLoading(true);
            const response = await fetch("/api/user/profile");
            if (!response.ok) throw new Error("Failed to fetch profile");
            const data = await response.json();
            setProfile(data);
        } catch (error) {
            console.error("Error fetching profile:", error);
            toast({
                title: "Error",
                description: "Failed to load your profile. Please try again.",
                variant: "destructive",
            });
        } finally {
            setLoading(false);
        }
    };
    const handleProfileUpdate = async ({ name }: { name: string }) => {
        try {
            const response = await fetch("/api/user/profile/update", {
                method: "PUT",
                headers: { "Content-Type": "application/json" },
                body: JSON.stringify({ name }),
            });
            if (!response.ok) throw new Error("Failed to update profile");
            const { name: updatedName } = await response.json();
            // Update session and profile state
            await update({ name: updatedName });
            setProfile(prev => prev ? { ...prev, name: updatedName } : null);
            toast({
                title: "Success",
                description: "Your profile has been updated.",
            });
            return true;
        } catch (error) {
            console.error("Error updating profile:", error);
            toast({
                title: "Error",
                description: "Failed to update your profile. Please try again.",
                variant: "destructive",
            });
            return false;
        }
    };
    const handlePreferencesUpdate = async (newPreferences: UserProfile['preferences']) => {
        try {
            // Use the settings context to update preferences
            const success = await updatePreferences(newPreferences);
            if (!success) {
                throw new Error("Failed to update preferences");
            }
            // Update the profile state with new preferences
            setProfile(prev => prev ? { ...prev, preferences: { ...prev.preferences, ...newPreferences } } : null);
            toast({
                title: "Success",
                description: "Your preferences have been updated.",
            });
            return true;
        } catch (error) {
            console.error("Error updating preferences:", error);
            toast({
                title: "Error",
                description: "Failed to update your preferences. Please try again.",
                variant: "destructive",
            });
            return false;
        }
    };
    const handleProfilePictureUpdate = async (file: File | null) => {
        try {
            if (!file && !profile?.profilePicture) {
                return true; // Nothing to update
            }
            const formData = new FormData();
            if (file) {
                formData.append("profilePicture", file);
            } else if (profile?.profilePicture) {
                // If file is null but we had a profile picture before, we're removing it
                formData.append("removeProfilePicture", "true");
            }
            const response = await fetch("/api/user/profile/update", {
                method: "PUT",
                body: formData,
            });
            if (!response.ok) {
                throw new Error("Failed to update profile picture");
            }
            const { profilePicture } = await response.json();
            // Update profile state
            setProfile(prev => prev ? { ...prev, profilePicture } : null);
            toast({
                title: "Success",
                description: file
                    ? "Your profile picture has been updated."
                    : "Your profile picture has been removed.",
            });
            return true;
        } catch (error) {
            console.error("Error updating profile picture:", error);
            toast({
                title: "Error",
                description: "Failed to update your profile picture. Please try again.",
                variant: "destructive",
            });
            return false;
        }
    };
    const handleDeleteAccount = async (e?: FormEvent) => {
        if (e) e.preventDefault();
        if (!profile) return;
        if (deleteConfirmation.toLowerCase() !== "delete") {
            setDeleteError("Please type 'delete' to confirm");
            return;
        }
        setIsDeletingAccount(true);
        setDeleteError("");
        try {
            const response = await fetch("/api/user/account/delete", {
                method: "DELETE",
            });
            if (!response.ok) throw new Error("Failed to delete account");
            toast({
                title: "Account Deleted",
                description: "Your account has been successfully deleted. You will be signed out.",
            });
            // Sign out and redirect to home page
            setTimeout(() => {
                signOut({ callbackUrl: "/" });
            }, 2000);
        } catch (error) {
            console.error("Error deleting account:", error);
            toast({
                title: "Error",
                description: "Failed to delete your account. Please try again.",
                variant: "destructive",
            });
            setIsDeletingAccount(false);
            setShowDeleteAccountDialog(false);
            setDeleteConfirmation("");
        }
    };
    if (status === "unauthenticated") {
        return (
            <div className="container max-w-4xl py-10">
                <Card>
                    <CardHeader>
                        <CardTitle>Profile</CardTitle>
                        <CardDescription>
                            You need to be signed in to view your profile.
                        </CardDescription>
                    </CardHeader>
                </Card>
            </div>
        );
    }
    return (
        <div className="container max-w-4xl py-10">
            <h1 className="mb-6 text-2xl font-bold">Your Profile</h1>
            {loading ? (
                <div className="flex flex-col items-center justify-center py-10">
                    <Loading text="Loading your profile..." size="lg" />
                </div>
            ) : (
                profile && (
                    <>
                        <div className="flex flex-col md:flex-row gap-6 mb-8">
                            <div className="md:w-1/4 flex flex-col items-center">
                                <ProfilePicture
                                    imageUrl={profile.profilePicture}
                                    userName={profile.name}
                                    size="large"
                                    onImageChange={handleProfilePictureUpdate}
                                />
                            </div>
                            <div className="flex-1">
                                <h2 className="text-xl font-semibold mb-1">{profile.name}</h2>
                                <p className="text-muted-foreground text-sm mb-4">{profile.email}</p>
                            </div>
                        </div>
                        <Tabs defaultValue="account" className="w-full">
                            <TabsList className="mb-4">
                                <TabsTrigger value="account" className="text-sm">Account</TabsTrigger>
                                <TabsTrigger value="preferences" className="text-sm">Preferences</TabsTrigger>
                                <TabsTrigger value="danger" className="text-sm">Danger Zone</TabsTrigger>
                            </TabsList>
                            <TabsContent value="account">
                                <Card>
                                    <CardHeader>
                                        <CardTitle className="text-lg">Account Details</CardTitle>
                                        <CardDescription className="text-xs">
                                            Manage your account information.
                                        </CardDescription>
                                    </CardHeader>
                                    <CardContent>
                                        <AccountDetails
                                            name={profile.name}
                                            email={profile.email}
                                            isEditable={true}
                                            onSave={handleProfileUpdate}
                                        />
                                    </CardContent>
                                </Card>
                            </TabsContent>
                            <TabsContent value="preferences">
                                <Card>
                                    <CardHeader>
                                        <CardTitle className="text-lg">User Preferences</CardTitle>
                                        <CardDescription className="text-xs">
                                            Customize your app experience.
                                        </CardDescription>
                                    </CardHeader>
                                    <CardContent>
                                        <PreferenceSettings
                                            preferences={profile.preferences}
                                            onSave={handlePreferencesUpdate}
                                        />
                                    </CardContent>
                                </Card>
                            </TabsContent>
                            <TabsContent value="danger">
                                <Card className="border-red-200 dark:border-red-800">
                                    <CardHeader className="text-red-600 dark:text-red-400">
                                        <CardTitle className="flex items-center gap-2 text-lg">
                                            <AlertCircle size={18} />
                                            Danger Zone
                                        </CardTitle>
                                        <CardDescription className="text-xs">
                                            Actions that can't be undone.
                                        </CardDescription>
                                    </CardHeader>
                                    <CardContent>
                                        <div className="space-y-4">
                                            <div>
                                                <h3 className="text-base font-medium">Delete Account</h3>
                                                <p className="text-muted-foreground text-xs mb-4">
                                                    Permanently delete your account and all associated data. This action cannot be undone.
                                                </p>
                                                <Button
                                                    variant="destructive"
                                                    className="flex items-center gap-2 text-sm"
                                                    onClick={() => setShowDeleteAccountDialog(true)}
                                                >
                                                    <Trash2 size={14} />
                                                    Delete Account
                                                </Button>
                                            </div>
                                        </div>
                                    </CardContent>
                                </Card>
                            </TabsContent>
                        </Tabs>
                    </>
                )
            )}
            {/* Delete Account Confirmation Dialog */}
            <AlertDialog open={showDeleteAccountDialog} onOpenChange={(open) => {
                setShowDeleteAccountDialog(open);
                if (!open) {
                    setDeleteConfirmation("");
                    setDeleteError("");
                }
            }}>
                <AlertDialogContent>
                    <AlertDialogHeader>
                        <AlertDialogTitle className="text-lg">Delete Account</AlertDialogTitle>
                        <AlertDialogDescription className="space-y-3 text-sm">
                            <p>
                                Are you absolutely sure you want to delete your account? All of your data will be permanently removed.
                                This action cannot be undone.
                            </p>
                            <form onSubmit={handleDeleteAccount} className="pt-2">
                                <label className="text-xs font-medium">
                                    Type <span className="font-bold">delete</span> to confirm:
                                </label>
                                <Input
                                    className="mt-2 text-sm"
                                    value={deleteConfirmation}
                                    onChange={(e) => setDeleteConfirmation(e.target.value)}
                                    placeholder="delete"
                                    disabled={isDeletingAccount}
                                />
                                {deleteError && (
                                    <p className="text-xs text-red-500 mt-1">{deleteError}</p>
                                )}
                            </form>
                        </AlertDialogDescription>
                    </AlertDialogHeader>
                    <AlertDialogFooter>
                        <AlertDialogCancel disabled={isDeletingAccount} className="text-sm">Cancel</AlertDialogCancel>
                        <AlertDialogAction
                            onClick={() => handleDeleteAccount()}
                            disabled={isDeletingAccount || deleteConfirmation.toLowerCase() !== "delete"}
                            className="bg-destructive text-destructive-foreground hover:bg-destructive/90 text-sm"
                        >
                            {isDeletingAccount ? "Deleting..." : "Delete Account"}
                        </AlertDialogAction>
                    </AlertDialogFooter>
                </AlertDialogContent>
            </AlertDialog>
        </div>
    );
}
function ProfileSkeleton() {
    return (
        <div>
            <div className="mb-8 flex flex-col items-center sm:flex-row sm:items-start gap-6">
                <Skeleton className="h-20 w-20 rounded-full" />
                <div className="flex-1">
                    <Skeleton className="h-6 w-40 mb-2" />
                    <Skeleton className="h-4 w-56 mb-4" />
                </div>
            </div>
            <Tabs defaultValue="account" className="w-full">
                <TabsList className="mb-4">
                    <TabsTrigger value="account" className="text-sm">Account</TabsTrigger>
                    <TabsTrigger value="preferences" className="text-sm">Preferences</TabsTrigger>
                </TabsList>
                <TabsContent value="account">
                    <Card>
                        <CardHeader>
                            <CardTitle><Skeleton className="h-5 w-32" /></CardTitle>
                            <CardDescription><Skeleton className="h-3 w-48" /></CardDescription>
                        </CardHeader>
                        <CardContent>
                            <div className="space-y-6">
                                <div className="space-y-2">
                                    <Skeleton className="h-4 w-20" />
                                    <Skeleton className="h-8 w-full" />
                                </div>
                                <div className="space-y-2">
                                    <Skeleton className="h-4 w-20" />
                                    <Skeleton className="h-8 w-full" />
                                </div>
                            </div>
                        </CardContent>
                    </Card>
                </TabsContent>
            </Tabs>
        </div>
    );
}
</file>

<file path="src/app/settings-test/page.tsx">
"use client";
import { useSettings } from "@/lib/contexts/settings-context";
import { Button } from "@/components/ui/button";
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from "@/components/ui/card";
import { useToast } from "@/components/ui/use-toast";
import { useTheme } from "next-themes";
import { useEffect, useState } from "react";
export default function SettingsTestPage() {
  const { preferences, updatePreferences, isLoaded } = useSettings();
  const { theme, setTheme } = useTheme();
  const { toast } = useToast();
  const [themeApplied, setThemeApplied] = useState(false);
  // Check if theme matches preferences when loaded
  useEffect(() => {
    if (isLoaded && theme) {
      setThemeApplied(theme === preferences.theme);
    }
  }, [isLoaded, preferences.theme, theme]);
  const toggleTheme = async () => {
    const newTheme = preferences.theme === 'light' ? 'dark' : 'light';
    const success = await updatePreferences({ theme: newTheme });
    if (success) {
      toast({
        title: "Theme Updated",
        description: `Theme switched to ${newTheme} mode`,
      });
    } else {
      toast({
        title: "Error",
        description: "Failed to update theme",
        variant: "destructive",
      });
    }
  };
  const toggleVoiceSynthesis = async () => {
    const newValue = !preferences.useVoiceSynthesis;
    const success = await updatePreferences({ useVoiceSynthesis: newValue });
    if (success) {
      toast({
        title: "Voice Synthesis Updated",
        description: `Voice synthesis ${newValue ? 'enabled' : 'disabled'}`,
      });
    } else {
      toast({
        title: "Error",
        description: "Failed to update voice synthesis setting",
        variant: "destructive",
      });
    }
  };
  const changeExpertType = async () => {
    const newType = preferences.defaultExpertType === 'historical' ? 'domain' : 'historical';
    const success = await updatePreferences({ defaultExpertType: newType });
    if (success) {
      toast({
        title: "Expert Type Updated",
        description: `Default expert type set to ${newType}`,
      });
    } else {
      toast({
        title: "Error",
        description: "Failed to update expert type",
        variant: "destructive",
      });
    }
  };
  if (!isLoaded) {
    return <div className="container py-8">Loading settings...</div>;
  }
  return (
    <div className="container py-8">
      <h1 className="text-3xl font-bold mb-8">Settings Test Page</h1>
      <div className="grid gap-6 md:grid-cols-2">
        <Card>
          <CardHeader>
            <CardTitle>Current Settings</CardTitle>
            <CardDescription>Your current user preferences</CardDescription>
          </CardHeader>
          <CardContent>
            <div className="space-y-4">
              <div>
                <span className="font-medium">Theme:</span> {preferences.theme}
                {themeApplied ? (
                  <span className="ml-2 text-green-600 dark:text-green-400">✓ Applied</span>
                ) : (
                  <span className="ml-2 text-red-600 dark:text-red-400">✗ Not Applied</span>
                )}
              </div>
              <div>
                <span className="font-medium">Voice Synthesis:</span> {preferences.useVoiceSynthesis ? 'Enabled' : 'Disabled'}
              </div>
              <div>
                <span className="font-medium">Default Expert Type:</span> {preferences.defaultExpertType}
              </div>
            </div>
          </CardContent>
        </Card>
        <Card>
          <CardHeader>
            <CardTitle>Test Actions</CardTitle>
            <CardDescription>Try changing your settings</CardDescription>
          </CardHeader>
          <CardContent>
            <div className="space-y-4">
              <Button onClick={toggleTheme} className="w-full">
                Toggle Theme
              </Button>
              <Button onClick={toggleVoiceSynthesis} className="w-full">
                Toggle Voice Synthesis
              </Button>
              <Button onClick={changeExpertType} className="w-full">
                Switch Expert Type
              </Button>
            </div>
          </CardContent>
        </Card>
      </div>
      <div className="mt-8">
        <Card>
          <CardHeader>
            <CardTitle>Technical Details</CardTitle>
            <CardDescription>Raw data for debugging</CardDescription>
          </CardHeader>
          <CardContent>
            <pre className="bg-gray-100 dark:bg-gray-800 p-4 rounded-md overflow-auto">
              {JSON.stringify({ 
                preferences, 
                currentTheme: theme, 
                themeApplied 
              }, null, 2)}
            </pre>
          </CardContent>
        </Card>
      </div>
    </div>
  );
}
</file>

<file path="src/app/globals.css">
@tailwind base;
@tailwind components;
@tailwind utilities;
@layer base {
  :root {
    --background: 0 0% 100%;
    --foreground: 240 10% 3.9%;
    --card: 0 0% 100%;
    --card-foreground: 240 10% 3.9%;
    --popover: 0 0% 100%;
    --popover-foreground: 240 10% 3.9%;
    --primary: 240 5.9% 10%;
    --primary-foreground: 0 0% 98%;
    --secondary: 240 4.8% 95.9%;
    --secondary-foreground: 240 5.9% 10%;
    --muted: 240 4.8% 95.9%;
    --muted-foreground: 240 3.8% 46.1%;
    --accent: 240 4.8% 95.9%;
    --accent-foreground: 240 5.9% 10%;
    --success: 142 76% 36%;
    --success-foreground: 0 0% 98%;
    --destructive: 0 84.2% 60.2%;
    --destructive-foreground: 0 0% 98%;
    --border: 240 5.9% 90%;
    --input: 240 5.9% 90%;
    --ring: 240 5.9% 10%;
    --radius: 0.5rem;
  }
  .dark {
    --background: 240 10% 3.9%;
    --foreground: 0 0% 98%;
    --card: 240 10% 3.9%;
    --card-foreground: 0 0% 98%;
    --popover: 240 10% 3.9%;
    --popover-foreground: 0 0% 98%;
    --primary: 0 0% 98%;
    --primary-foreground: 240 5.9% 10%;
    --secondary: 240 3.7% 15.9%;
    --secondary-foreground: 0 0% 98%;
    --muted: 240 3.7% 15.9%;
    --muted-foreground: 240 5% 64.9%;
    --accent: 240 3.7% 15.9%;
    --accent-foreground: 0 0% 98%;
    --success: 142 76% 36%;
    --success-foreground: 0 0% 98%;
    --destructive: 0 84.2% 60.2%;
    --destructive-foreground: 0 0% 98%;
    --border: 240 3.7% 15.9%;
    --input: 240 3.7% 15.9%;
    --ring: 240 4.9% 83.9%;
  }
}
@layer base {
  * {
    @apply border-[hsl(var(--border))];
  }
  body {
    @apply bg-background text-foreground font-light text-[0.85rem];
  }
  p,
  span,
  div,
  label,
  input,
  textarea {
    @apply font-light text-[0.85rem];
  }
  h1 {
    @apply font-normal text-[1.7rem];
  }
  h2 {
    @apply font-normal text-[1.36rem];
  }
  h3 {
    @apply font-normal text-[1.19rem];
  }
  h4 {
    @apply font-normal text-[1.02rem];
  }
  h5,
  h6 {
    @apply font-normal text-[0.85rem];
  }
  button,
  .button,
  [type="button"],
  [type="submit"] {
    @apply font-bold text-[0.85rem];
  }
}
@layer components {
  .animate-spin {
    animation: spin 1s linear infinite;
  }
  .text-xs {
    font-size: 0.68rem !important;
  }
  .text-sm {
    font-size: 0.77rem !important;
  }
  .text-base {
    font-size: 0.85rem !important;
  }
  .text-lg {
    font-size: 1.02rem !important;
  }
  .text-xl {
    font-size: 1.19rem !important;
  }
  .text-2xl {
    font-size: 1.36rem !important;
  }
}
@keyframes spin {
  from {
    transform: rotate(0deg);
  }
  to {
    transform: rotate(360deg);
  }
}
@keyframes fade-in-down {
  from {
    opacity: 0;
    transform: translateY(-0.5rem);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}
.animate-fade-in-down {
  animation: fade-in-down 0.2s ease-out;
}
</file>

<file path="src/app/layout.tsx">
import type { Metadata } from "next";
import { Inter } from "next/font/google";
import "./globals.css";
import { Providers } from "@/lib/providers";
const inter = Inter({
  subsets: ["latin"],
  weight: ['300', '400', '500', '600', '700'],
  variable: '--font-inter',
});
export const metadata: Metadata = {
  title: "Debate-Aible",
  description: "AI-powered debate platform with expert perspectives",
};
export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  return (
    <html lang="en" suppressHydrationWarning>
      <body className={`${inter.className} ${inter.variable} bg-gray-100 dark:bg-gray-900`}>
        <Providers>
          {children}
        </Providers>
      </body>
    </html>
  );
}
</file>

<file path="src/app/page.tsx">
import Link from 'next/link';
import { Button } from '@/components/ui/button';
import { Mic, MessageSquare, Brain, BookOpen, Users, Lightbulb, RefreshCw, FileText } from 'lucide-react';
import { UserNavigation } from '@/components/UserNavigation';
export default function Home() {
  return (
    <main className="flex min-h-screen flex-col overflow-auto">
      {/* Navigation */}
      <header className="bg-white dark:bg-gray-800 border-b p-4 flex justify-between items-center">
        <h1 className="text-xl font-bold">Debate-Aible</h1>
        <div className="flex items-center gap-4">
          <nav className="hidden md:flex space-x-6">
            <Link href="#features" className="text-xs font-medium hover:text-primary transition-colors">Features</Link>
            <Link href="#how-it-works" className="text-xs font-medium hover:text-primary transition-colors">How it Works</Link>
            <Link href="#use-cases" className="text-xs font-medium hover:text-primary transition-colors">Use Cases</Link>
            <Link href="#start-debating" className="text-xs font-medium hover:text-primary transition-colors">Get Started</Link>
          </nav>
          <UserNavigation />
        </div>
      </header>
      {/* Hero Section */}
      <section className="py-16 px-4 md:px-8 lg:py-24 flex flex-col items-center text-center bg-white dark:bg-gray-800">
        <h2 className="text-3xl md:text-4xl lg:text-5xl font-bold mb-6 max-w-3xl">
          Engage in AI-powered debates with historical experts
        </h2>
        <p className="text-lg text-muted-foreground mb-8 max-w-2xl">
          Transform your ideas into dynamic intellectual battles. Debate with AI-generated experts who bring historical context and specialized knowledge to any topic.
        </p>
        <div className="flex flex-col sm:flex-row gap-4">
          <Button size="lg" className="px-8">
            <Link href="/app/debate">Start Debating</Link>
          </Button>
          <Button size="lg" variant="secondary" className="px-8">
            <Link href="#watch-demo">Watch Demo</Link>
          </Button>
        </div>
        <div className="mt-12 relative w-full max-w-4xl rounded-lg overflow-hidden shadow-xl border bg-card">
          <div className="aspect-video bg-muted flex items-center justify-center">
            <div className="text-3xl font-bold text-muted-foreground opacity-50">
              Debate-Aible Demo
            </div>
          </div>
        </div>
        <div className="grid grid-cols-3 gap-8 mt-12 max-w-2xl w-full">
          <div className="flex flex-col items-center">
            <p className="text-2xl font-bold">30+</p>
            <p className="text-xs text-muted-foreground">Expert Personalities</p>
          </div>
          <div className="flex flex-col items-center">
            <p className="text-2xl font-bold">3x</p>
            <p className="text-xs text-muted-foreground">Critical Thinking Boost</p>
          </div>
          <div className="flex flex-col items-center">
            <p className="text-2xl font-bold">98%</p>
            <p className="text-xs text-muted-foreground">Intellectual Satisfaction</p>
          </div>
        </div>
      </section>
      {/* Features Section */}
      <section id="features" className="py-16 px-4 md:px-8 lg:py-24 bg-muted/30">
        <div className="max-w-6xl mx-auto">
          <div className="text-center mb-16">
            <h2 className="text-2xl font-bold mb-4">Powerful Features for Enriching Debates</h2>
            <p className="text-base text-muted-foreground max-w-2xl mx-auto">
              Everything you need to engage in high-quality intellectual discourse with AI-powered experts
            </p>
          </div>
          <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-8">
            <div className="bg-card p-6 rounded-lg shadow-sm border">
              <MessageSquare className="h-8 w-8 text-primary mb-4" />
              <h3 className="text-lg font-semibold mb-2">AI-Powered Expert Debates</h3>
              <p className="text-sm text-muted-foreground">
                Engage with AI-generated historical and modern experts who debate your topics with authentic perspectives and specialized knowledge.
              </p>
            </div>
            <div className="bg-card p-6 rounded-lg shadow-sm border">
              <Mic className="h-8 w-8 text-primary mb-4" />
              <h3 className="text-lg font-semibold mb-2">Voice Synthesis & Input</h3>
              <p className="text-sm text-muted-foreground">
                Listen to expert voices through AI speech synthesis and participate in debates using your own voice with speech-to-text technology.
              </p>
            </div>
            <div className="bg-card p-6 rounded-lg shadow-sm border">
              <FileText className="h-8 w-8 text-primary mb-4" />
              <h3 className="text-lg font-semibold mb-2">Content Upload & Analysis</h3>
              <p className="text-sm text-muted-foreground">
                Upload documents, articles, and research papers to extract debate topics and have experts analyze the key points automatically.
              </p>
            </div>
            <div className="bg-card p-6 rounded-lg shadow-sm border">
              <Brain className="h-8 w-8 text-primary mb-4" />
              <h3 className="text-lg font-semibold mb-2">Critical Thinking Enhancement</h3>
              <p className="text-sm text-muted-foreground">
                Break through confirmation bias by exploring multiple perspectives, strengthening your ability to analyze complex topics.
              </p>
            </div>
            <div className="bg-card p-6 rounded-lg shadow-sm border">
              <RefreshCw className="h-8 w-8 text-primary mb-4" />
              <h3 className="text-lg font-semibold mb-2">Dynamic Debate Adaptation</h3>
              <p className="text-sm text-muted-foreground">
                Debates evolve based on your input, with experts responding to your arguments and challenging your perspective in real-time.
              </p>
            </div>
            <div className="bg-card p-6 rounded-lg shadow-sm border">
              <Lightbulb className="h-8 w-8 text-primary mb-4" />
              <h3 className="text-lg font-semibold mb-2">Debate Summaries & Insights</h3>
              <p className="text-sm text-muted-foreground">
                Get comprehensive summaries of key points from both sides, helping you synthesize information and form well-rounded conclusions.
              </p>
            </div>
          </div>
        </div>
      </section>
      {/* How It Works */}
      <section id="how-it-works" className="py-16 px-4 md:px-8 lg:py-24 bg-white dark:bg-gray-800">
        <div className="max-w-6xl mx-auto">
          <div className="text-center mb-16">
            <h2 className="text-2xl font-bold mb-4">How It Works</h2>
            <p className="text-base text-muted-foreground max-w-2xl mx-auto">
              Start engaging in intellectually stimulating debates in four simple steps
            </p>
          </div>
          <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-8">
            <div className="flex flex-col items-center text-center">
              <div className="w-10 h-10 rounded-full bg-primary text-primary-foreground flex items-center justify-center font-bold text-base mb-4">1</div>
              <h3 className="text-lg font-semibold mb-2">Enter Your Topic</h3>
              <p className="text-sm text-muted-foreground">
                Submit a debate topic or upload a document to extract key discussion points automatically.
              </p>
            </div>
            <div className="flex flex-col items-center text-center">
              <div className="w-10 h-10 rounded-full bg-primary text-primary-foreground flex items-center justify-center font-bold text-base mb-4">2</div>
              <h3 className="text-lg font-semibold mb-2">AI Selects Experts</h3>
              <p className="text-sm text-muted-foreground">
                Our AI selects the most relevant historical or contemporary figures to debate your topic from different perspectives.
              </p>
            </div>
            <div className="flex flex-col items-center text-center">
              <div className="w-10 h-10 rounded-full bg-primary text-primary-foreground flex items-center justify-center font-bold text-base mb-4">3</div>
              <h3 className="text-lg font-semibold mb-2">Debate Begins</h3>
              <p className="text-sm text-muted-foreground">
                Listen to or read as expert opinions unfold in a dynamic, authentic debate based on their real-life views and expertise.
              </p>
            </div>
            <div className="flex flex-col items-center text-center">
              <div className="w-10 h-10 rounded-full bg-primary text-primary-foreground flex items-center justify-center font-bold text-base mb-4">4</div>
              <h3 className="text-lg font-semibold mb-2">Participate & Learn</h3>
              <p className="text-sm text-muted-foreground">
                Join the conversation with your own perspectives and challenge the experts, refining your understanding and critical thinking.
              </p>
            </div>
          </div>
        </div>
      </section>
      {/* Use Cases */}
      <section id="use-cases" className="py-16 px-4 md:px-8 lg:py-24 bg-muted/30">
        <div className="max-w-6xl mx-auto">
          <div className="text-center mb-16">
            <h2 className="text-2xl font-bold mb-4">Transformative Use Cases</h2>
            <p className="text-base text-muted-foreground max-w-2xl mx-auto">
              Discover how Debate-Aible enhances learning, critical thinking, and idea development across various domains
            </p>
          </div>
          <div className="grid grid-cols-1 md:grid-cols-2 gap-8">
            <div className="bg-card p-6 rounded-lg shadow-sm border">
              <Brain className="h-8 w-8 text-primary mb-4" />
              <h3 className="text-lg font-semibold mb-2">Critical Thinking Development</h3>
              <p className="text-sm text-muted-foreground mb-4">
                Break through confirmation bias by exploring opposing viewpoints on complex topics, challenging your assumptions and strengthening your analytical skills.
              </p>
              <p className="text-xs font-medium">Example debate: <span className="text-primary">"Is artificial intelligence a threat or a tool for progress?"</span> with Alan Turing vs. Elon Musk</p>
            </div>
            <div className="bg-card p-6 rounded-lg shadow-sm border">
              <BookOpen className="h-8 w-8 text-primary mb-4" />
              <h3 className="text-lg font-semibold mb-2">Academic & Learning Enhancement</h3>
              <p className="text-sm text-muted-foreground mb-4">
                Enhance your understanding of philosophy, politics, ethics, and history by engaging with the greatest minds across different eras on important topics.
              </p>
              <p className="text-xs font-medium">Example debate: <span className="text-primary">"Should we have universal basic income?"</span> with Karl Marx vs. Milton Friedman</p>
            </div>
            <div className="bg-card p-6 rounded-lg shadow-sm border">
              <FileText className="h-8 w-8 text-primary mb-4" />
              <h3 className="text-lg font-semibold mb-2">Writing & Idea Refinement</h3>
              <p className="text-sm text-muted-foreground mb-4">
                Perfect for authors, debaters, and thinkers refining arguments for essays or books, exposing you to nuanced perspectives you might not have considered.
              </p>
              <p className="text-xs font-medium">Example debate: <span className="text-primary">"Would Shakespeare approve of AI-generated poetry?"</span> with Shakespeare vs. an AI model</p>
            </div>
            <div className="bg-card p-6 rounded-lg shadow-sm border">
              <Lightbulb className="h-8 w-8 text-primary mb-4" />
              <h3 className="text-lg font-semibold mb-2">Creative Problem-Solving</h3>
              <p className="text-sm text-muted-foreground mb-4">
                Apply expert perspectives to business strategy, technology, or future trends, gaining insights from different disciplines and approaches.
              </p>
              <p className="text-xs font-medium">Example debate: <span className="text-primary">"What's the best way to colonize Mars?"</span> with Elon Musk vs. Carl Sagan</p>
            </div>
          </div>
        </div>
      </section>
      {/* Testimonials */}
      <section className="py-16 px-4 md:px-8 lg:py-24 bg-white dark:bg-gray-800">
        <div className="max-w-6xl mx-auto">
          <div className="text-center mb-16">
            <h2 className="text-2xl font-bold mb-4">What Users Are Saying</h2>
            <p className="text-base text-muted-foreground max-w-2xl mx-auto">
              See how Debate-Aible is transforming the way people learn and think
            </p>
          </div>
          <div className="grid grid-cols-1 md:grid-cols-3 gap-8">
            <div className="bg-card p-6 rounded-lg shadow-sm border">
              <div className="flex items-center mb-4">
                <div className="w-10 h-10 rounded-full bg-primary/20 flex items-center justify-center mr-4">
                  <Users className="h-5 w-5 text-primary" />
                </div>
                <div>
                  <p className="font-semibold">Sarah Johnson</p>
                  <p className="text-xs text-muted-foreground">Graduate Student</p>
                </div>
              </div>
              <p className="text-sm text-muted-foreground">
                "Debate-Aible has completely transformed my research process. Being able to hear Einstein and Bohr debate quantum theory helped me understand complex concepts in a way textbooks never could."
              </p>
            </div>
            <div className="bg-card p-6 rounded-lg shadow-sm border">
              <div className="flex items-center mb-4">
                <div className="w-10 h-10 rounded-full bg-primary/20 flex items-center justify-center mr-4">
                  <Users className="h-5 w-5 text-primary" />
                </div>
                <div>
                  <p className="font-semibold">David Chen</p>
                  <p className="text-xs text-muted-foreground">Philosophy Professor</p>
                </div>
              </div>
              <p className="text-sm text-muted-foreground">
                "I've started using Debate-Aible with my students, and the improvement in their critical thinking skills has been remarkable. They're now approaching topics with much more nuanced perspectives."
              </p>
            </div>
            <div className="bg-card p-6 rounded-lg shadow-sm border">
              <div className="flex items-center mb-4">
                <div className="w-10 h-10 rounded-full bg-primary/20 flex items-center justify-center mr-4">
                  <Users className="h-5 w-5 text-primary" />
                </div>
                <div>
                  <p className="font-semibold">Alex Rivera</p>
                  <p className="text-xs text-muted-foreground">Content Creator</p>
                </div>
              </div>
              <p className="text-sm text-muted-foreground">
                "The voice synthesis feature makes these debates come alive. Hearing 'Marx' and 'Friedman' debate economic policy with my own questions added in has made complex economic theory accessible and engaging."
              </p>
            </div>
          </div>
        </div>
      </section>
      {/* Call-to-Action */}
      <section id="start-debating" className="py-16 px-4 md:px-8 lg:py-24 bg-primary text-primary-foreground">
        <div className="max-w-4xl mx-auto text-center">
          <h2 className="text-2xl md:text-3xl font-bold mb-6">Ready to Transform Your Thinking?</h2>
          <p className="text-lg mb-8 opacity-90 max-w-2xl mx-auto">
            Join thousands of students, researchers, and curious minds who are enhancing their critical thinking through AI-powered expert debates.
          </p>
          <Button size="lg" variant="secondary" className="px-8 text-base">
            <Link href="/app/debate">Start Your First Debate</Link>
          </Button>
        </div>
      </section>
      {/* Footer */}
      <footer className="py-12 px-4 md:px-8 border-t">
        <div className="max-w-6xl mx-auto">
          <div className="grid grid-cols-1 md:grid-cols-4 gap-8">
            <div>
              <h3 className="text-base font-bold mb-4">Debate-Aible</h3>
              <p className="text-xs text-muted-foreground mb-4">
                AI-powered debate platform with expert perspectives for enhanced critical thinking.
              </p>
            </div>
            <div>
              <h4 className="font-semibold mb-4">Features</h4>
              <ul className="space-y-2">
                <li><Link href="#" className="text-xs text-muted-foreground hover:text-primary transition-colors">AI Experts</Link></li>
                <li><Link href="#" className="text-xs text-muted-foreground hover:text-primary transition-colors">Voice Synthesis</Link></li>
                <li><Link href="#" className="text-xs text-muted-foreground hover:text-primary transition-colors">Content Upload</Link></li>
                <li><Link href="#" className="text-xs text-muted-foreground hover:text-primary transition-colors">Debate Summaries</Link></li>
              </ul>
            </div>
            <div>
              <h4 className="font-semibold mb-4">Use Cases</h4>
              <ul className="space-y-2">
                <li><Link href="#" className="text-xs text-muted-foreground hover:text-primary transition-colors">Academic Research</Link></li>
                <li><Link href="#" className="text-xs text-muted-foreground hover:text-primary transition-colors">Critical Thinking</Link></li>
                <li><Link href="#" className="text-xs text-muted-foreground hover:text-primary transition-colors">Content Creation</Link></li>
                <li><Link href="#" className="text-xs text-muted-foreground hover:text-primary transition-colors">Problem Solving</Link></li>
              </ul>
            </div>
            <div>
              <h4 className="font-semibold mb-4">Company</h4>
              <ul className="space-y-2">
                <li><Link href="#" className="text-xs text-muted-foreground hover:text-primary transition-colors">About Us</Link></li>
                <li><Link href="#" className="text-xs text-muted-foreground hover:text-primary transition-colors">Contact</Link></li>
                <li><Link href="#" className="text-xs text-muted-foreground hover:text-primary transition-colors">Privacy Policy</Link></li>
                <li><Link href="#" className="text-xs text-muted-foreground hover:text-primary transition-colors">Terms of Service</Link></li>
              </ul>
            </div>
          </div>
          <div className="mt-12 pt-8 border-t text-center">
            <p className="text-xs text-muted-foreground">
              © 2023 Debate-Aible. All rights reserved.
            </p>
          </div>
        </div>
      </footer>
    </main>
  );
}
</file>

<file path="src/app/providers.tsx">
"use client";
// Re-export the Providers from lib/providers
export { Providers } from '@/lib/providers';
</file>

<file path="src/components/content-processing/ContentUploader.tsx">
"use client";
import React, { useState } from 'react';
import { useDebateStore } from '@/lib/store';
import { Button } from '@/components/ui/button';
import { Input } from '@/components/ui/input';
import {
    Loader2,
    FileText,
    Youtube,
    Mic,
    Link as LinkIcon,
    ChevronDown,
    ChevronUp,
    Check,
    Upload
} from 'lucide-react';
interface Topic {
    title: string;
    confidence: number;
    arguments: {
        claim: string;
        evidence: string;
        counterpoints?: string[];
    }[];
}
export function ContentUploader() {
    const [activeTab, setActiveTab] = useState('document');
    const [isProcessing, setIsProcessing] = useState(false);
    const [file, setFile] = useState<File | null>(null);
    const [url, setUrl] = useState('');
    const [extractedTopics, setExtractedTopics] = useState<Topic[]>([]);
    const [selectedTopic, setSelectedTopic] = useState<number | null>(null);
    const [showTopics, setShowTopics] = useState(true);
    const [error, setError] = useState<string | null>(null);
    const { setTopic } = useDebateStore();
    const handleFileChange = (e: React.ChangeEvent<HTMLInputElement>) => {
        const selectedFile = e.target.files?.[0] || null;
        setFile(selectedFile);
        setError(null);
    };
    const handleUrlChange = (e: React.ChangeEvent<HTMLInputElement>) => {
        setUrl(e.target.value);
        setError(null);
    };
    const handleTabChange = (value: string) => {
        setActiveTab(value);
        setFile(null);
        setUrl('');
        setError(null);
    };
    const handleProcessContent = async () => {
        setIsProcessing(true);
        setError(null);
        setExtractedTopics([]);
        try {
            let endpoint = '';
            const formData = new FormData();
            switch (activeTab) {
                case 'document':
                    if (!file) {
                        throw new Error('Please select a file to upload');
                    }
                    endpoint = '/api/content/document';
                    formData.append('file', file);
                    break;
                case 'youtube':
                case 'podcast':
                    if (!url) {
                        throw new Error('Please enter a valid URL');
                    }
                    endpoint = '/api/content/media';
                    formData.append('url', url);
                    formData.append('type', activeTab);
                    break;
                case 'link':
                    if (!url) {
                        throw new Error('Please enter a valid URL');
                    }
                    endpoint = '/api/content/link';
                    formData.append('url', url);
                    break;
            }
            const response = await fetch(endpoint, {
                method: 'POST',
                body: formData,
            });
            if (!response.ok) {
                const errorData = await response.json();
                throw new Error(errorData.message || 'Failed to process content');
            }
            const data = await response.json();
            setExtractedTopics(data.topics || []);
        } catch (err) {
            setError(err instanceof Error ? err.message : 'An unknown error occurred');
        } finally {
            setIsProcessing(false);
        }
    };
    const handleSelectTopic = (index: number) => {
        setSelectedTopic(index);
    };
    const handleStartDebate = () => {
        if (selectedTopic !== null && extractedTopics[selectedTopic]) {
            setTopic(extractedTopics[selectedTopic].title);
        }
    };
    return (
        <div className="w-full mb-6">
            <div className="bg-gray-50 dark:bg-gray-900 border rounded-lg shadow-sm">
                <div className="p-4 border-b">
                    <div className="flex justify-between items-center">
                        <div>
                            <h2 className="text-base font-semibold">Content Analyzer</h2>
                            <p className="text-xs text-muted-foreground">
                                Upload content to extract debate topics or enter a topic directly to start a debate between AI experts ...and yourself.
                            </p>
                        </div>
                        <Button
                            variant="ghost"
                            size="sm"
                            onClick={() => setShowTopics(!showTopics)}
                            className="h-7 px-2"
                        >
                            {showTopics ? <ChevronUp className="h-3.5 w-3.5" /> : <ChevronDown className="h-3.5 w-3.5" />}
                        </Button>
                    </div>
                </div>
                {showTopics && (
                    <div className="p-4">
                        <div className="space-y-3.5">
                            <div className="flex border-b">
                                <button
                                    className={`px-3.5 py-1.5 text-xs font-bold border-b-2 ${activeTab === 'document'
                                        ? "border-blue-500 text-blue-500"
                                        : "border-transparent text-gray-500 hover:text-blue-500 hover:border-blue-500"
                                        }`}
                                    onClick={() => handleTabChange('document')}
                                >
                                    <FileText
                                        className={`inline-block w-3.5 h-3.5 mr-1.5 ${activeTab === 'document'
                                            ? "text-blue-500"
                                            : "text-gray-400 group-hover:text-blue-500"
                                            }`}
                                    />
                                    <span className="hidden sm:inline">Document</span>
                                </button>
                                <button
                                    className={`px-3.5 py-1.5 text-xs font-bold border-b-2 ${activeTab === 'youtube'
                                        ? "border-red-500 text-red-500"
                                        : "border-transparent text-gray-500 hover:text-red-500 hover:border-red-500"
                                        }`}
                                    onClick={() => handleTabChange('youtube')}
                                >
                                    <Youtube
                                        className={`inline-block w-3.5 h-3.5 mr-1.5 ${activeTab === 'youtube'
                                            ? "text-red-500"
                                            : "text-gray-400 group-hover:text-red-500"
                                            }`}
                                    />
                                    <span className="hidden sm:inline">YouTube</span>
                                </button>
                                <button
                                    className={`px-3.5 py-1.5 text-xs font-bold border-b-2 ${activeTab === 'podcast'
                                        ? "border-green-500 text-green-500"
                                        : "border-transparent text-gray-500 hover:text-green-500 hover:border-green-500"
                                        }`}
                                    onClick={() => handleTabChange('podcast')}
                                >
                                    <Mic
                                        className={`inline-block w-3.5 h-3.5 mr-1.5 ${activeTab === 'podcast'
                                            ? "text-green-500"
                                            : "text-gray-400 group-hover:text-green-500"
                                            }`}
                                    />
                                    <span className="hidden sm:inline">Podcast</span>
                                </button>
                                <button
                                    className={`px-3.5 py-1.5 text-xs font-bold border-b-2 ${activeTab === 'link'
                                        ? "border-blue-700 text-blue-700"
                                        : "border-transparent text-gray-500 hover:text-blue-700 hover:border-blue-700"
                                        }`}
                                    onClick={() => handleTabChange('link')}
                                >
                                    <LinkIcon
                                        className={`inline-block w-3.5 h-3.5 mr-1.5 ${activeTab === 'link'
                                            ? "text-blue-700"
                                            : "text-gray-400 group-hover:text-blue-700"
                                            }`}
                                    />
                                    <span className="hidden sm:inline">Web Link</span>
                                </button>
                            </div>
                            {activeTab === 'document' && (
                                <div className="space-y-3.5">
                                    <div className="grid w-full max-w-sm items-center gap-1.5">
                                        <label htmlFor="document-upload" className="text-xs font-light text-gray-600 dark:text-gray-300">
                                            Upload Document (PDF, DOCX, TXT)
                                        </label>
                                        <div className="flex items-center justify-center w-full">
                                            <label
                                                htmlFor="document-upload"
                                                className="flex flex-col items-center justify-center w-full h-28 border-2 border-dashed rounded-lg cursor-pointer bg-gray-100 dark:bg-gray-800 border-gray-300 dark:border-gray-600 hover:border-blue-500 dark:hover:border-blue-500"
                                            >
                                                <div className="flex flex-col items-center justify-center pt-4 pb-5">
                                                    <Upload className="w-7 h-7 mb-2.5 text-gray-400" />
                                                    <p className="mb-1.5 text-xs font-light text-gray-500 dark:text-gray-400">
                                                        <span className="font-bold">Click to upload</span> or drag and drop
                                                    </p>
                                                    <p className="text-xs font-light text-gray-500 dark:text-gray-400">
                                                        PDF, DOCX, TXT (MAX. 20MB)
                                                    </p>
                                                </div>
                                                <input
                                                    id="document-upload"
                                                    type="file"
                                                    className="hidden"
                                                    onChange={handleFileChange}
                                                    accept=".pdf,.docx,.txt"
                                                />
                                            </label>
                                        </div>
                                    </div>
                                </div>
                            )}
                            {activeTab === 'youtube' && (
                                <div className="space-y-3.5">
                                    <div className="grid w-full items-center gap-1.5">
                                        <label htmlFor="youtube-url" className="text-xs font-light text-gray-600 dark:text-gray-300">
                                            YouTube Video URL
                                        </label>
                                        <Input
                                            id="youtube-url"
                                            type="url"
                                            placeholder="https://www.youtube.com/watch?v=..."
                                            value={url}
                                            onChange={handleUrlChange}
                                            disabled={isProcessing}
                                            className="font-light h-8 text-xs"
                                        />
                                    </div>
                                </div>
                            )}
                            {activeTab === 'podcast' && (
                                <div className="space-y-3.5">
                                    <div className="grid w-full items-center gap-1.5">
                                        <label htmlFor="podcast-url" className="text-xs font-light text-gray-600 dark:text-gray-300">
                                            Podcast URL
                                        </label>
                                        <Input
                                            id="podcast-url"
                                            type="url"
                                            placeholder="https://podcasts.example.com/episode..."
                                            value={url}
                                            onChange={handleUrlChange}
                                            disabled={isProcessing}
                                            className="font-light h-8 text-xs"
                                        />
                                    </div>
                                </div>
                            )}
                            {activeTab === 'link' && (
                                <div className="space-y-3.5">
                                    <div className="grid w-full items-center gap-1.5">
                                        <label htmlFor="web-url" className="text-xs font-light text-gray-600 dark:text-gray-300">
                                            Web Page URL
                                        </label>
                                        <Input
                                            id="web-url"
                                            type="url"
                                            placeholder="https://example.com/article..."
                                            value={url}
                                            onChange={handleUrlChange}
                                            disabled={isProcessing}
                                            className="font-light h-8 text-xs"
                                        />
                                    </div>
                                </div>
                            )}
                            {error && (
                                <div className="text-xs text-red-500 mt-2">{error}</div>
                            )}
                            <div className="mt-3.5">
                                <Button
                                    onClick={handleProcessContent}
                                    disabled={isProcessing || (!file && !url)}
                                    className="font-bold h-8 text-xs"
                                >
                                    {isProcessing ? (
                                        <>
                                            <Loader2 className="w-3.5 h-3.5 mr-1.5 animate-spin" />
                                            Processing...
                                        </>
                                    ) : (
                                        'Extract Topics'
                                    )}
                                </Button>
                            </div>
                        </div>
                        {extractedTopics.length > 0 && (
                            <div className="mt-5 space-y-3.5">
                                <h3 className="text-sm font-medium">Extracted Topics</h3>
                                <div className="space-y-2.5">
                                    {extractedTopics.map((topic, index) => (
                                        <div
                                            key={index}
                                            className={`border rounded-md p-2.5 cursor-pointer transition-colors ${selectedTopic === index
                                                ? "border-primary bg-primary/5"
                                                : "hover:bg-muted/50"
                                                }`}
                                            onClick={() => handleSelectTopic(index)}
                                        >
                                            <div className="flex justify-between items-start">
                                                <div className="flex-1">
                                                    <h4 className="text-xs font-medium">{topic.title}</h4>
                                                    <div className="text-xs text-muted-foreground mt-1">
                                                        {topic.arguments.length} key arguments • {Math.round(topic.confidence * 100)}% confidence
                                                    </div>
                                                </div>
                                                {selectedTopic === index && (
                                                    <Check className="h-4 w-4 text-primary" />
                                                )}
                                            </div>
                                            {selectedTopic === index && (
                                                <div className="mt-2.5 space-y-1.5">
                                                    <h5 className="text-xs font-medium">Key Arguments:</h5>
                                                    <ul className="space-y-1.5">
                                                        {topic.arguments.slice(0, 3).map((arg, i) => (
                                                            <li key={i} className="text-xs">
                                                                <span className="font-medium">{arg.claim}</span>
                                                            </li>
                                                        ))}
                                                    </ul>
                                                </div>
                                            )}
                                        </div>
                                    ))}
                                </div>
                            </div>
                        )}
                    </div>
                )}
                {extractedTopics.length > 0 && selectedTopic !== null && (
                    <div className="p-3.5 border-t flex justify-end">
                        <Button onClick={handleStartDebate} variant="success" className="h-8 text-xs">
                            Start Debate on Selected Topic
                        </Button>
                    </div>
                )}
            </div>
        </div>
    );
}
</file>

<file path="src/components/debate/CitationFooter.tsx">
import React from 'react';
import { Citation } from '@/types/message';
import { Button } from '@/components/ui/button';
import { ExternalLink } from 'lucide-react';
interface CitationFooterProps {
    citations?: Citation[];
}
export function CitationFooter({ citations }: CitationFooterProps) {
    if (!citations || citations.length === 0) {
        return null;
    }
    return (
        <div className="mt-3 pt-2 border-t border-border">
            <h4 className="text-xs font-medium text-muted-foreground mb-2">Citations</h4>
            <div className="flex flex-col gap-2">
                {citations.map((citation, index) => (
                    <div key={index} className="text-xs">
                        <div className="flex items-start gap-1">
                            <span className="font-medium">[{index + 1}]</span>
                            <div>
                                <p className="text-foreground">{citation.title || 'Untitled Source'}</p>
                                {citation.author && (
                                    <p className="text-muted-foreground">{citation.author}</p>
                                )}
                                {citation.url && (
                                    <Button
                                        variant="link"
                                        size="sm"
                                        className="h-auto p-0 text-xs"
                                        onClick={() => window.open(citation.url, '_blank')}
                                    >
                                        <ExternalLink className="h-3 w-3 mr-1" />
                                        View Source
                                    </Button>
                                )}
                            </div>
                        </div>
                    </div>
                ))}
            </div>
        </div>
    );
}
</file>

<file path="src/components/debate/DebatePanel.tsx">
"use client";
import React, { useEffect, useRef, useState, useCallback } from 'react';
import { useDebateStore } from '@/lib/store';
import { assignVoiceToExpert } from '@/lib/elevenlabs';
import { Message } from '@/types/message';
import { Expert } from '@/types/expert';
import { MessageBubble } from './MessageBubble';
import { ExpertCard } from './ExpertCard';
import { UserInput } from './UserInput';
import { DebateSummary } from './DebateSummary';
import { Loader2, ChevronDown, ChevronUp } from 'lucide-react';
import { Button } from '@/components/ui/button';
import { Switch } from '@/components/ui/switch';
import { v4 as uuidv4 } from 'uuid';
export function DebatePanel() {
    const {
        topic,
        experts,
        messages,
        isGenerating,
        useVoiceSynthesis,
        useCitations,
        expertType,
        debateId,
        error: storeError,
        setTopic,
        setExperts,
        addMessage,
        setIsGenerating,
        setUseCitations,
        setExpertType,
        initializeDebate,
        setError,
        reset
    } = useDebateStore();
    const [showSummary, setShowSummary] = useState(false);
    const [userTopic, setUserTopic] = useState('');
    const [errorMessage, setErrorMessage] = useState<string | null>(null);
    const [loadingState, setLoadingState] = useState<string>('');
    const [expertsSelected, setExpertsSelected] = useState(false);
    const [showExpertSelection, setShowExpertSelection] = useState(false);
    const [expertsLoading, setExpertsLoading] = useState(false);
    const [isLoading, setIsLoading] = useState(false);
    const [selectedParticipantType, setSelectedParticipantType] = useState<'historical' | 'domain' | null>(null);
    const [extractedTopics, setExtractedTopics] = useState<Array<{
        title: string;
        confidence: number;
        arguments: string[];
    }>>([]);
    const [selectedTopic, setSelectedTopic] = useState<string | null>(null);
    const [isContentAnalyzerOpen, setIsContentAnalyzerOpen] = useState(true);
    const messagesEndRef = useRef<HTMLDivElement>(null);
    const audioRef = useRef<HTMLAudioElement | null>(null);
    const fileInputRef = useRef<HTMLInputElement>(null);
    // Helper function to generate and handle expert responses
    const generateExpertResponses = useCallback(async (currentExperts: Expert[], currentMessages: Message[]) => {
        try {
            // Generate responses from all experts
            const responsePromises = currentExperts.map(async expert => {
                try {
                    const response = await fetch('/api/debate-simple', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({
                            action: 'generate-response',
                            expert,
                            topic,
                            messages: currentMessages,
                            useCitations: useCitations,
                            debateId
                        })
                    });
                    // Check if response is OK
                    if (!response.ok) {
                        const errorText = await response.text();
                        console.error(`API error (${response.status}):`, errorText);
                        throw new Error(`API error: ${response.status} - ${errorText.substring(0, 100)}...`);
                    }
                    const data = await response.json();
                    return { ...data, expertName: expert.name, expertId: expert.id };
                } catch (error: any) {
                    console.error(`Error generating response for expert ${expert.name}:`, error);
                    return {
                        response: `I apologize, but I'm having trouble responding right now. (Error: ${error.message})`,
                        expertName: expert.name,
                        expertId: expert.id
                    };
                }
            });
            const responses = await Promise.all(responsePromises);
            // Add all responses to the UI and process citations
            for (let i = 0; i < responses.length; i++) {
                const { response, usage, expertName, expertId } = responses[i];
                // Create a unique message ID using timestamp, expert ID, and index
                const messageId = `msg_${Date.now()}_${expertId}_${i}`;
                const newMessage = {
                    id: messageId,
                    role: 'assistant' as const,
                    content: response,
                    speaker: expertName,
                    usage: {
                        tokens: usage.totalTokens,
                        promptTokens: usage.promptTokens,
                        completionTokens: usage.completionTokens,
                        cost: usage.cost
                    }
                };
                addMessage(newMessage);
                // Process citations after adding the message
                useDebateStore.getState().processCitationsInMessage(messageId);
            }
            // Handle voice synthesis if enabled
            if (useVoiceSynthesis) {
                for (const { response, expertName } of responses) {
                    try {
                        const expert = currentExperts.find(e => e.name === expertName);
                        if (!expert?.voiceId) {
                            console.error('No voice ID found for expert:', expertName);
                            continue;
                        }
                        const audioResponse = await fetch('/api/voice', {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify({
                                action: 'synthesize',
                                text: response,
                                voiceId: expert.voiceId
                            })
                        });
                        if (!audioResponse.ok) {
                            const errorData = await audioResponse.json();
                            console.error('Error synthesizing voice:', errorData);
                            continue;
                        }
                        const audioBlob = await audioResponse.blob();
                        const audio = new Audio(URL.createObjectURL(audioBlob));
                        await new Promise(resolve => {
                            audio.onended = resolve;
                            audio.play();
                        });
                    } catch (error) {
                        console.error('Error playing audio:', error);
                    }
                }
            }
        } catch (error) {
            console.error('Error generating expert responses:', error);
            throw error;
        }
    }, [topic, experts, messages, addMessage, useCitations, debateId]);
    // Handle expert type selection
    const handleExpertTypeSelect = (type: 'historical' | 'domain') => {
        // Clear any previously selected experts when changing expert type
        setExperts([]);
        setExpertType(type);
        setSelectedParticipantType(type);
        setError('');
        setIsLoading(false);
    };
    // Handle topic selection from extracted topics
    const handleTopicSelect = (topic: string) => {
        setUserTopic(topic);
        setTopic(topic);
        setSelectedTopic(topic);
    };
    // Initialize debate after topic selection
    const initializeDebateWithTopic = async () => {
        if (!selectedTopic || !selectedParticipantType) return;
        const newDebateId = uuidv4();
        setLoadingState('Initializing debate...');
        try {
            const response = await fetch('/api/debate-simple', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    action: 'initialize-debate',
                    topic: selectedTopic,
                    expertType: selectedParticipantType,
                    userId: 'user-' + Date.now() // Simple user ID for now
                })
            });
            if (!response.ok) {
                const errorText = await response.text();
                console.error(`API error (${response.status}):`, errorText);
                throw new Error(`Failed to initialize debate: ${response.status} - ${errorText.substring(0, 100)}...`);
            }
            const data = await response.json();
            initializeDebate(data.debateId, selectedTopic);
            setLoadingState('Debate initialized!');
            // Now we can proceed to select experts
            setShowExpertSelection(true);
            selectExperts();
        } catch (error) {
            console.error('Error initializing debate:', error);
            setErrorMessage(error instanceof Error ? error.message : 'Failed to initialize debate');
            setLoadingState('');
        }
    };
    // Update selectExperts to use the selected participant type
    const selectExperts = async () => {
        if (!topic) {
            setError('Please enter a topic first');
            return;
        }
        setIsLoading(true);
        setExpertsLoading(true);
        setError('');
        try {
            console.log(`Selecting experts of type: ${expertType} for topic: ${topic}`);
            // Make the debate API call
            console.log('Making debate API call...');
            const response = await fetch('/api/debate-simple', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                    action: 'select-experts',
                    topic,
                    expertType,
                    count: 2 // Explicitly request 2 experts
                }),
            });
            console.log('Debate API response status:', response.status);
            if (!response.ok) {
                const errorText = await response.text();
                console.error(`API error (${response.status}):`, errorText);
                throw new Error(`Failed to select experts: ${response.status} - ${errorText.substring(0, 100)}...`);
            }
            const data = await response.json();
            console.log('Debate API response data:', data);
            if (!data.experts || !Array.isArray(data.experts)) {
                throw new Error('Invalid response format: experts array missing');
            }
            // Verify experts are of the correct type
            const filteredExperts = data.experts.filter((expert: Expert) => expert.type === expertType);
            console.log(`Filtered ${filteredExperts.length} ${expertType} experts`);
            if (filteredExperts.length === 0) {
                throw new Error(`No ${expertType} experts were found for this topic`);
            }
            setExperts(filteredExperts);
            setExpertsSelected(true);
            // Generate voices for experts if needed
            if (useVoiceSynthesis && filteredExperts.length > 0) {
                try {
                    const expertsWithVoices = await Promise.all(
                        filteredExperts.map(async (expert: Expert) => {
                            try {
                                const voiceResponse = await fetch('/api/voice', {
                                    method: 'POST',
                                    headers: { 'Content-Type': 'application/json' },
                                    body: JSON.stringify({
                                        action: 'assign-voice',
                                        expertName: expert.name,
                                        expertType: expert.type
                                    })
                                });
                                if (!voiceResponse.ok) {
                                    console.error(`Failed to assign voice for ${expert.name}`);
                                    return expert;
                                }
                                const voiceData = await voiceResponse.json();
                                return { ...expert, voiceId: voiceData.voiceId };
                            } catch (voiceError) {
                                console.error(`Error assigning voice to ${expert.name}:`, voiceError);
                                return expert;
                            }
                        })
                    );
                    setExperts(expertsWithVoices);
                } catch (voiceError) {
                    console.error('Error assigning voices to experts:', voiceError);
                    // Continue with experts without voices
                }
            }
        } catch (error: any) {
            console.error('Error selecting experts:', error);
            setError(error.message || 'Failed to select experts');
        } finally {
            setIsLoading(false);
            setExpertsLoading(false);
        }
    };
    // Handle starting the discussion
    const startDiscussion = async () => {
        if (!experts.length || isGenerating) return;
        setIsGenerating(true);
        setLoadingState('Generating initial responses...');
        try {
            // Generate initial responses directly
            await generateExpertResponses(experts, []);
            setLoadingState('Discussion started!');
            setTimeout(() => setLoadingState(''), 2000);
        } catch (error) {
            setErrorMessage('Failed to start the discussion');
            setLoadingState('');
        } finally {
            setIsGenerating(false);
        }
    };
    // Handle user input
    const handleUserInput = (text: string) => {
        if (text.trim() && !isGenerating && experts.length > 0) {
            const userMessage = {
                id: `msg_user_${Date.now()}`,
                role: 'user' as const,
                content: text,
                speaker: 'You'
            };
            addMessage(userMessage);
            // Generate responses from experts
            setIsGenerating(true);
            generateExpertResponses(experts, [...messages, userMessage])
                .catch(error => {
                    console.error('Error generating responses:', error);
                    setErrorMessage('Failed to generate responses');
                })
                .finally(() => {
                    setIsGenerating(false);
                });
        }
    };
    // Update error message when store error changes
    useEffect(() => {
        if (storeError) {
            setErrorMessage(storeError);
            setError(null); // Clear store error after displaying
        }
    }, [storeError, setError]);
    // Scroll to bottom when messages change
    useEffect(() => {
        messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
    }, [messages]);
    // Handle file upload
    const handleFileUpload = async (event: React.ChangeEvent<HTMLInputElement>) => {
        const file = event.target.files?.[0];
        if (!file) return;
        setLoadingState('Analyzing document...');
        const formData = new FormData();
        formData.append('file', file);
        try {
            const response = await fetch('/api/analyze', {
                method: 'POST',
                body: formData
            });
            if (!response.ok) {
                throw new Error('Failed to analyze document');
            }
            const data = await response.json();
            setExtractedTopics(data.topics);
            setLoadingState('Document analyzed!');
            setTimeout(() => setLoadingState(''), 2000);
        } catch (error) {
            console.error('Error analyzing document:', error);
            setErrorMessage('Failed to analyze document');
            setLoadingState('');
        }
    };
    // Trigger file input click
    const triggerFileUpload = () => {
        fileInputRef.current?.click();
    };
    // Toggle content analyzer
    const toggleContentAnalyzer = () => {
        setIsContentAnalyzerOpen(!isContentAnalyzerOpen);
    };
    // Test API call
    useEffect(() => {
        const testApi = async () => {
            try {
                // Test the test-api endpoint
                console.log('Testing API routes...');
                const testResponse = await fetch('/api/test-api', {
                    method: 'GET'
                });
                if (testResponse.ok) {
                    const testData = await testResponse.json();
                    console.log('Test API response:', testData);
                } else {
                    console.error('Test API error:', testResponse.status, await testResponse.text());
                }
                // Test POST to test-api
                const testPostResponse = await fetch('/api/test-api', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        message: 'Testing API POST'
                    })
                });
                if (testPostResponse.ok) {
                    const testPostData = await testPostResponse.json();
                    console.log('Test API POST response:', testPostData);
                } else {
                    console.error('Test API POST error:', testPostResponse.status, await testPostResponse.text());
                }
            } catch (error: any) {
                console.error('API test error:', error.message);
            }
        };
        testApi();
    }, []);
    // Main render
    return (
        <div className="flex flex-col h-full">
            {/* Loading and Error States */}
            {loadingState && (
                <div className="fixed top-0 left-0 right-0 bg-primary text-primary-foreground p-2 text-center z-50 animate-fade-in-down">
                    <div className="flex items-center justify-center gap-2">
                        <Loader2 className="h-4 w-4 animate-spin" />
                        <span>{loadingState}</span>
                    </div>
                </div>
            )}
            {errorMessage && (
                <div className="fixed top-0 left-0 right-0 bg-destructive text-destructive-foreground p-2 text-center z-50">
                    {errorMessage}
                </div>
            )}
            <div className="flex flex-col h-full max-w-4xl mx-auto p-4">
                {/* Expert Type Selection */}
                {!selectedParticipantType && (
                    <div className="mb-8">
                        <h2 className="text-xl font-semibold text-white mb-4">Choose Your Debate Participants</h2>
                        <p className="text-gray-400 mb-4">Select who you want to debate with on your chosen topic</p>
                        <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
                            <button
                                onClick={() => handleExpertTypeSelect('historical')}
                                className={`p-6 rounded-lg border ${selectedParticipantType === 'historical'
                                    ? 'border-primary bg-primary/10'
                                    : 'border-gray-700 bg-gray-800/50 hover:bg-gray-800'
                                    } transition-all`}
                            >
                                <h3 className="text-lg font-semibold text-white mb-2">Historical Figures</h3>
                                <p className="text-gray-400 text-sm">
                                    Debate with notable personalities from history like Einstein, Aristotle,
                                    Marie Curie, and others who bring their historical perspectives.
                                </p>
                            </button>
                            <button
                                onClick={() => handleExpertTypeSelect('domain')}
                                className={`p-6 rounded-lg border ${selectedParticipantType === 'domain'
                                    ? 'border-primary bg-primary/10'
                                    : 'border-gray-700 bg-gray-800/50 hover:bg-gray-800'
                                    } transition-all`}
                            >
                                <h3 className="text-lg font-semibold text-white mb-2">Domain Specialists</h3>
                                <p className="text-gray-400 text-sm">
                                    Engage with AI-powered domain experts who specialize in specific fields
                                    like technology, medicine, economics, and more.
                                </p>
                            </button>
                        </div>
                    </div>
                )}
                {/* Content Analysis or Direct Topic Input */}
                {selectedParticipantType && !topic && (
                    <div className="space-y-8">
                        {/* Remove Content Analysis Section and keep only Direct Topic Input */}
                        <div className="border rounded-lg p-6 bg-gray-800/50">
                            <h2 className="text-xl font-semibold text-white mb-4">Enter Debate Topic</h2>
                            <div className="flex gap-2">
                                <input
                                    type="text"
                                    placeholder="Enter your topic..."
                                    className="flex-1 bg-gray-700 border border-gray-600 rounded-lg px-4 py-2 text-white"
                                    value={userTopic}
                                    onChange={(e) => setUserTopic(e.target.value)}
                                />
                                <Button
                                    onClick={() => {
                                        handleTopicSelect(userTopic);
                                        setTimeout(() => {
                                            initializeDebateWithTopic();
                                        }, 100);
                                    }}
                                    disabled={!userTopic.trim()}
                                >
                                    Set Topic
                                </Button>
                            </div>
                        </div>
                    </div>
                )}
                {/* Meet Experts Button */}
                {topic && !experts.length && !showExpertSelection && (
                    <div className="flex justify-center my-8">
                        <Button
                            onClick={() => {
                                setShowExpertSelection(true);
                                selectExperts();
                            }}
                            size="lg"
                            className="animate-pulse"
                        >
                            Meet Your Experts
                        </Button>
                    </div>
                )}
                {/* Expert Display and Debate Section */}
                {experts.length > 0 && (
                    <div className="space-y-6 mt-8">
                        <h3 className="text-xl font-semibold text-white text-center">Your Debate Experts</h3>
                        <div className="flex gap-4 overflow-x-auto pb-4 justify-center">
                            {experts.map((expert) => (
                                <ExpertCard key={expert.id} expert={expert} />
                            ))}
                        </div>
                        {/* Step 4: Start Discussion */}
                        {expertsSelected && messages.length === 0 && (
                            <div className="mt-6 flex justify-center">
                                <Button
                                    onClick={startDiscussion}
                                    disabled={isGenerating}
                                    size="lg"
                                >
                                    {isGenerating ? (
                                        <>
                                            <Loader2 className="mr-2 h-4 w-4 animate-spin" />
                                            Starting Discussion...
                                        </>
                                    ) : (
                                        'Start Debate on Selected Topic'
                                    )}
                                </Button>
                            </div>
                        )}
                    </div>
                )}
                {/* Debate Section */}
                {messages.length > 0 && (
                    <>
                        <div className="flex-1 overflow-y-auto space-y-4 mb-4">
                            {messages.map((message) => (
                                <MessageBubble
                                    key={message.id}
                                    message={message}
                                    experts={experts}
                                    audioRef={audioRef}
                                />
                            ))}
                            {isGenerating && (
                                <div className="flex justify-center">
                                    <Loader2 className="h-6 w-6 animate-spin text-muted-foreground" />
                                </div>
                            )}
                            <div ref={messagesEndRef} />
                        </div>
                        <UserInput onSubmit={handleUserInput} disabled={isGenerating} />
                    </>
                )}
            </div>
        </div>
    );
}
</file>

<file path="src/components/debate/DebateSummary.tsx">
"use client";
import React from 'react';
import { Message } from '@/types/message';
import { Expert } from '@/types/expert';
import { Button } from '@/components/ui/button';
import { cn } from '@/lib/utils';
import { BookOpen, BrainCircuit, MessageSquareQuote, ListChecks } from 'lucide-react';
interface DebateSummaryProps {
    topic: string;
    experts: Expert[];
    messages: Message[];
    className?: string;
}
export function DebateSummary({ topic, experts, messages, className }: DebateSummaryProps) {
    // Filter out system messages and group by expert
    const expertMessages = messages.filter(m => m.role === 'assistant').reduce((acc, message) => {
        const expert = experts.find(e => e.name === message.speaker);
        if (expert) {
            if (!acc[expert.stance]) {
                acc[expert.stance] = [];
            }
            acc[expert.stance].push(message);
        }
        return acc;
    }, {} as Record<string, Message[]>);
    // Get user's messages
    const userMessages = messages.filter(m => m.role === 'user');
    // Extract key points from each stance
    const proMessages = expertMessages['pro'] || [];
    const conMessages = expertMessages['con'] || [];
    // Extract key points from all expert messages
    const extractKeyPoints = () => {
        const allExpertMessages = [...(proMessages || []), ...(conMessages || [])];
        const points = new Set<string>();
        allExpertMessages.forEach(message => {
            // Split into sentences and filter out short ones
            const sentences = message.content
                .split(/[.!?]+/)
                .map(s => s.trim())
                .filter(s => s.length > 20 && s.length < 150);
            // Prioritize sentences that contain key phrases
            const keyPhrases = ['importantly', 'key', 'significant', 'crucial', 'essential', 'primary', 'main', 'fundamental'];
            const prioritizedSentences = sentences.sort((a, b) => {
                const aScore = keyPhrases.reduce((score, phrase) =>
                    score + (a.toLowerCase().includes(phrase) ? 1 : 0), 0);
                const bScore = keyPhrases.reduce((score, phrase) =>
                    score + (b.toLowerCase().includes(phrase) ? 1 : 0), 0);
                return bScore - aScore;
            });
            // Take the top sentences
            prioritizedSentences.slice(0, 2).forEach(s => points.add(s));
        });
        return Array.from(points).slice(0, 5);
    };
    const keyPoints = extractKeyPoints();
    return (
        <div className={cn("space-y-6 p-6 border rounded-lg", className)}>
            <div className="space-y-2">
                <h2 className="text-xl font-semibold flex items-center gap-2">
                    <BrainCircuit className="h-5 w-5" />
                    Debate Summary
                </h2>
                <p className="text-muted-foreground">
                    Key insights and arguments from the debate on: <span className="font-medium text-foreground">{topic}</span>
                </p>
            </div>
            {/* Key Points Section */}
            {keyPoints.length > 0 && (
                <div className="space-y-3 bg-accent/50 rounded-lg p-4">
                    <h3 className="text-lg font-medium flex items-center gap-2">
                        <ListChecks className="h-4 w-4" />
                        Key Points
                    </h3>
                    <ul className="space-y-2">
                        {keyPoints.map((point, index) => (
                            <li key={index} className="flex gap-2 text-sm">
                                <span className="font-medium text-primary">{index + 1}.</span>
                                <span>{point}</span>
                            </li>
                        ))}
                    </ul>
                </div>
            )}
            {/* User's Perspective */}
            {userMessages.length > 0 && (
                <div className="space-y-2">
                    <h3 className="text-lg font-medium">Your Perspective</h3>
                    <div className="bg-primary/5 rounded-lg p-4">
                        <p className="text-sm">{userMessages[userMessages.length - 1].content}</p>
                    </div>
                </div>
            )}
            {/* Supporting Arguments */}
            {proMessages.length > 0 && (
                <div className="space-y-2">
                    <h3 className="text-lg font-medium flex items-center gap-2">
                        <MessageSquareQuote className="h-4 w-4 text-[hsl(142,76%,36%)]" />
                        Supporting Arguments
                    </h3>
                    <div className="space-y-2">
                        {proMessages.map((message, index) => (
                            <div key={index} className="bg-green-100 dark:bg-green-900/20 rounded-lg p-4">
                                <p className="text-sm font-medium mb-1">{message.speaker}</p>
                                <p className="text-sm">{message.content}</p>
                            </div>
                        ))}
                    </div>
                </div>
            )}
            {/* Opposing Arguments */}
            {conMessages.length > 0 && (
                <div className="space-y-2">
                    <h3 className="text-lg font-medium flex items-center gap-2">
                        <MessageSquareQuote className="h-4 w-4 text-destructive" />
                        Opposing Arguments
                    </h3>
                    <div className="space-y-2">
                        {conMessages.map((message, index) => (
                            <div key={index} className="bg-red-100 dark:bg-red-900/20 rounded-lg p-4">
                                <p className="text-sm font-medium mb-1">{message.speaker}</p>
                                <p className="text-sm">{message.content}</p>
                            </div>
                        ))}
                    </div>
                </div>
            )}
            {/* Recommended Reading */}
            <div className="space-y-2">
                <h3 className="text-lg font-medium flex items-center gap-2">
                    <BookOpen className="h-4 w-4" />
                    Recommended Reading
                </h3>
                <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
                    {experts.map((expert) => (
                        <Button
                            key={expert.name}
                            variant="outline"
                            className="justify-start h-auto p-4"
                            onClick={() => window.open(`https://www.google.com/search?q=${encodeURIComponent(`${expert.name} ${topic} research papers`)}`, '_blank')}
                        >
                            <div className="text-left">
                                <p className="font-medium">{expert.name}'s Work</p>
                                <p className="text-sm text-muted-foreground">
                                    Research and publications related to this topic
                                </p>
                            </div>
                        </Button>
                    ))}
                </div>
            </div>
        </div>
    );
}
</file>

<file path="src/components/debate/ExpertCard.tsx">
import React from 'react';
import { Expert } from '@/types/expert';
import { Avatar } from '@/components/ui/avatar';
import { cn } from '@/lib/utils';
import { useTheme } from '@/lib/theme';
interface ExpertCardProps {
    expert: Expert;
    className?: string;
}
export function ExpertCard({ expert, className }: ExpertCardProps) {
    const { theme } = useTheme();
    return (
        <div
            className={cn(
                'flex flex-col items-center p-4 rounded-lg border transition-colors duration-200',
                'border-[hsl(var(--border))]',
                theme === 'light' ? 'hover:bg-accent/50' : 'hover:bg-accent/50',
                className
            )}
        >
            <Avatar className="h-16 w-16 mb-2">
                <div className={cn(
                    'w-full h-full flex items-center justify-center text-lg font-semibold',
                    'bg-muted text-muted-foreground'
                )}>
                    {expert.name.charAt(0)}
                </div>
            </Avatar>
            <h3 className="text-lg font-semibold text-foreground">{expert.name}</h3>
            <p className={cn(
                'text-sm text-center mb-2',
                expert.stance === 'pro'
                    ? 'text-[hsl(142,76%,36%)]'
                    : 'text-destructive',
                theme === 'dark' && (
                    expert.stance === 'pro'
                        ? 'text-[hsl(142,76%,42%)]'
                        : 'text-destructive/90'
                )
            )}>
                {expert.stance === 'pro' ? 'Supporting' : 'Opposing'}
            </p>
            <p className="text-sm text-center mb-2 text-muted-foreground">{expert.background}</p>
            <div className="flex flex-wrap gap-1 justify-center">
                {expert.expertise && expert.expertise.map((area, index) => (
                    <span
                        key={index}
                        className={cn(
                            'text-xs px-2 py-1 rounded-full',
                            'bg-secondary text-secondary-foreground'
                        )}
                    >
                        {area}
                    </span>
                ))}
            </div>
        </div>
    );
}
</file>

<file path="src/components/debate/ExpertProfile.tsx">
"use client";
import React from 'react';
import { ExpertProfile as ExpertProfileType } from '@/lib/openai';
import { Avatar } from '@/components/ui/avatar';
import { cn } from '@/lib/utils';
import { useTheme } from '@/lib/theme';
interface ExpertProfileProps {
    expert: ExpertProfileType;
    isActive?: boolean;
    className?: string;
}
export function ExpertProfile({ expert, isActive, className }: ExpertProfileProps) {
    const { theme } = useTheme();
    return (
        <div
            className={cn(
                'flex flex-col items-center p-4 rounded-lg border transition-colors duration-200',
                isActive && 'border-primary bg-primary/5',
                !isActive && 'border-[hsl(var(--border))]',
                theme === 'light' ? 'hover:bg-accent/50' : 'hover:bg-accent/50',
                className
            )}
        >
            <Avatar className="h-16 w-16 mb-2">
                <div className={cn(
                    'w-full h-full flex items-center justify-center text-lg font-semibold',
                    'bg-muted text-muted-foreground'
                )}>
                    {expert.name.charAt(0)}
                </div>
            </Avatar>
            <h3 className="text-lg font-semibold text-foreground">{expert.name}</h3>
            <p className={cn(
                'text-sm text-center mb-2',
                expert.stance === 'pro'
                    ? 'text-[hsl(142,76%,36%)]'
                    : 'text-destructive',
                theme === 'dark' && (
                    expert.stance === 'pro'
                        ? 'text-[hsl(142,76%,42%)]'
                        : 'text-destructive/90'
                )
            )}>
                {expert.stance === 'pro' ? 'Supporting' : 'Opposing'}
            </p>
            <p className="text-sm text-center mb-2 text-muted-foreground">{expert.background}</p>
            <div className="flex flex-wrap gap-1 justify-center">
                {expert.expertise.map((area, index) => (
                    <span
                        key={index}
                        className={cn(
                            'text-xs px-2 py-1 rounded-full',
                            'bg-secondary text-secondary-foreground'
                        )}
                    >
                        {area}
                    </span>
                ))}
            </div>
        </div>
    );
}
</file>

<file path="src/components/debate/ExpertTypeSelector.tsx">
'use client';
import React from 'react';
import { useDebateStore } from '@/lib/store';
import { Button } from '@/components/ui/button';
import { History, Briefcase } from 'lucide-react';
export function ExpertTypeSelector() {
    const { expertType, setExpertType } = useDebateStore();
    return (
        <div className="w-full mb-6">
            <div className="bg-gray-50 dark:bg-gray-900 border rounded-lg shadow-sm">
                <div className="p-4 border-b">
                    <h2 className="text-base font-semibold">Choose Your Debate Participants</h2>
                    <p className="text-xs text-muted-foreground">
                        Select who you want to debate with on your chosen topic
                    </p>
                </div>
                <div className="p-4">
                    <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
                        <div
                            className={`border rounded-lg p-4 cursor-pointer transition-all ${expertType === 'historical'
                                    ? 'border-primary bg-primary/5'
                                    : 'hover:border-primary/50'
                                }`}
                            onClick={() => setExpertType('historical')}
                        >
                            <div className="flex items-center gap-3 mb-2">
                                <History className="h-5 w-5 text-primary" />
                                <h3 className="font-medium">Historical Figures</h3>
                            </div>
                            <p className="text-xs text-muted-foreground">
                                Debate with notable personalities from history like Einstein, Aristotle,
                                Marie Curie, and others who bring their historical perspectives.
                            </p>
                        </div>
                        <div
                            className={`border rounded-lg p-4 cursor-pointer transition-all ${expertType === 'domain'
                                    ? 'border-primary bg-primary/5'
                                    : 'hover:border-primary/50'
                                }`}
                            onClick={() => setExpertType('domain')}
                        >
                            <div className="flex items-center gap-3 mb-2">
                                <Briefcase className="h-5 w-5 text-primary" />
                                <h3 className="font-medium">Domain Specialists</h3>
                            </div>
                            <p className="text-xs text-muted-foreground">
                                Engage with AI-powered domain experts who specialize in specific fields
                                like technology, medicine, economics, and more.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    );
}
</file>

<file path="src/components/debate/Message.tsx">
"use client";
import React from 'react';
import { DebateMessage } from '@/lib/openai';
import { cn } from '@/lib/utils';
import { Play, Pause } from 'lucide-react';
import { Button } from '@/components/ui/button';
import { useDebateStore } from '@/lib/store';
import { useTheme } from '@/lib/theme';
interface MessageProps {
    message: DebateMessage;
    isPlaying?: boolean;
    onPlayPause?: () => void;
    className?: string;
}
export function Message({ message, isPlaying, onPlayPause, className }: MessageProps) {
    const { currentSpeaker } = useDebateStore();
    const { theme } = useTheme();
    const isUser = message.role === 'user';
    const isActive = currentSpeaker === message.name;
    return (
        <div
            className={cn(
                'flex gap-4 p-4 rounded-lg transition-colors duration-200',
                isUser ? 'flex-row-reverse' : 'flex-row',
                isActive && 'bg-accent/10',
                className
            )}
        >
            <div className="flex flex-col items-center gap-2">
                {!isUser && message.name && onPlayPause && (
                    <Button
                        variant={isPlaying ? "destructive" : "success"}
                        size="icon"
                        onClick={onPlayPause}
                        className="h-8 w-8"
                    >
                        {isPlaying ? <Pause className="h-4 w-4" /> : <Play className="h-4 w-4" />}
                    </Button>
                )}
            </div>
            <div
                className={cn(
                    'flex flex-col flex-1 gap-2 rounded-lg p-4',
                    isUser
                        ? 'bg-primary text-primary-foreground'
                        : theme === 'light'
                            ? 'bg-secondary text-secondary-foreground'
                            : 'bg-secondary text-secondary-foreground'
                )}
            >
                {message.name && (
                    <div className="text-sm font-semibold">
                        {message.name}
                    </div>
                )}
                <div className="text-sm whitespace-pre-wrap">{message.content}</div>
            </div>
        </div>
    );
}
</file>

<file path="src/components/debate/MessageBubble.tsx">
import React, { useState, useRef, useEffect } from 'react';
import { Message } from '@/types/message';
import { Expert } from '@/types/expert';
import { Button } from '@/components/ui/button';
import { Volume2, Loader2, Info, StopCircle } from 'lucide-react';
import { useDebateStore } from '@/lib/store';
import { cn } from '@/lib/utils';
import { CitationFooter } from './CitationFooter';
import { processCitationMarkers } from '@/lib/utils/citation-processor';
interface MessageBubbleProps {
    message: Message;
    experts: Expert[];
    audioRef?: React.RefObject<HTMLAudioElement | null>;
    showCitations?: boolean; // Control whether to show citations (default: true)
}
export function MessageBubble({
    message,
    experts,
    audioRef: externalAudioRef,
    showCitations = true
}: MessageBubbleProps) {
    const [isPlaying, setIsPlaying] = useState(false);
    const [isLoading, setIsLoading] = useState(false);
    const [audioBlob, setAudioBlob] = useState<Blob | null>(null);
    const internalAudioRef = useRef<HTMLAudioElement | null>(null);
    const { useVoiceSynthesis } = useDebateStore();
    // Find the expert based on the message's speaker
    const expert = message.speaker ? experts.find(e => e.name === message.speaker) : undefined;
    // Process citations if needed
    useEffect(() => {
        if (
            !message.hasProcessedCitations &&
            message.role === 'assistant' &&
            expert?.backgroundKnowledge &&
            !message.citations
        ) {
            // Find sources for this expert
            const sources = expert.sourceReferences || [];
            if (sources.length > 0) {
                const { processedText, citations } = processCitationMarkers(message.content, sources);
                message.content = processedText;
                message.citations = citations;
                message.hasProcessedCitations = true;
            }
        }
    }, [message, expert]);
    const stopAudio = () => {
        const audioRef = externalAudioRef?.current || internalAudioRef.current;
        if (audioRef) {
            audioRef.pause();
            audioRef.currentTime = 0;
            setIsPlaying(false);
            if (!externalAudioRef) {
                internalAudioRef.current = null;
            }
        }
    };
    const handlePlayVoice = async () => {
        if (!expert?.voiceId || !useVoiceSynthesis) return;
        try {
            // First, stop any currently playing audio
            stopAudio();
            // Generate audio if not already cached
            if (!audioBlob) {
                setIsLoading(true);
                const response = await fetch('/api/voice', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        text: message.content,
                        voiceId: expert.voiceId
                    })
                });
                if (!response.ok) {
                    console.error('Error synthesizing voice:', await response.text());
                    setIsLoading(false);
                    return;
                }
                const blob = await response.blob();
                setAudioBlob(blob);
                setIsLoading(false);
            }
            // Create and setup new audio instance
            const audio = new Audio(URL.createObjectURL(audioBlob));
            audio.onended = () => {
                setIsPlaying(false);
                if (!externalAudioRef) {
                    internalAudioRef.current = null;
                }
            };
            audio.onpause = () => {
                setIsPlaying(false);
            };
            audio.onerror = () => {
                console.error('Audio playback error:', audio.error);
                setIsPlaying(false);
                if (!externalAudioRef) {
                    internalAudioRef.current = null;
                }
            };
            // Set up audio reference and start playback
            if (externalAudioRef) {
                externalAudioRef.current = audio;
            } else {
                internalAudioRef.current = audio;
            }
            setIsPlaying(true);
            try {
                await audio.play();
            } catch (playError) {
                console.error('Error playing audio:', playError);
                setIsPlaying(false);
                if (!externalAudioRef) {
                    internalAudioRef.current = null;
                }
            }
        } catch (error) {
            console.error('Error in handlePlayVoice:', error);
            setIsLoading(false);
            setIsPlaying(false);
            if (!externalAudioRef) {
                internalAudioRef.current = null;
            }
        }
    };
    // Cleanup on unmount
    React.useEffect(() => {
        return () => {
            if (!externalAudioRef && internalAudioRef.current) {
                internalAudioRef.current.pause();
                internalAudioRef.current = null;
            }
        };
    }, [externalAudioRef]);
    // Skip rendering for system messages
    if (message.role === 'system') {
        return null;
    }
    // For user messages
    if (message.role === 'user') {
        return (
            <div className="rounded-lg p-4 bg-primary/10 dark:bg-primary/20">
                <div className="flex items-start gap-2 mb-2">
                    <h3 className="font-semibold text-foreground">You</h3>
                </div>
                <p className="text-sm whitespace-pre-wrap">{message.content}</p>
            </div>
        );
    }
    // For assistant messages (experts)
    const getStanceColor = (stance: string) => {
        switch (stance?.toLowerCase()) {
            case 'pro':
                return 'bg-green-100 dark:bg-green-900/50';
            case 'con':
                return 'bg-red-100 dark:bg-red-900/50';
            default:
                return 'bg-gray-100 dark:bg-gray-800/50';
        }
    };
    const getStanceText = (stance: string) => {
        switch (stance?.toLowerCase()) {
            case 'pro':
                return 'Supporting';
            case 'con':
                return 'Opposing';
            default:
                return '';
        }
    };
    return (
        <div className={cn(
            "rounded-lg p-4",
            "transition-colors duration-200",
            getStanceColor(expert?.stance || '')
        )}>
            <div className="flex items-start gap-2 mb-2">
                <div className="flex-1">
                    <div className="flex items-center gap-2">
                        <h3 className="font-semibold text-foreground">
                            {expert?.name || 'Unknown Expert'}
                            {expert && (
                                <span className="ml-2 text-sm font-normal text-muted-foreground">
                                    ({getStanceText(expert.stance)})
                                </span>
                            )}
                        </h3>
                        {message.usage && (
                            <div className="flex items-center gap-1 text-xs text-muted-foreground" title="Token usage and cost">
                                <Info className="h-3 w-3" />
                                <span>{message.usage.tokens} tokens</span>
                                <span className="text-destructive">
                                    (${typeof message.usage.cost === 'number' ? message.usage.cost.toFixed(4) : '0.0000'})
                                </span>
                            </div>
                        )}
                    </div>
                    {expert?.expertise && (
                        <p className="text-xs text-muted-foreground">
                            {expert.expertise.join(', ')}
                        </p>
                    )}
                </div>
                {useVoiceSynthesis && expert?.voiceId && (
                    <div className="flex items-center gap-2">
                        {isLoading && (
                            <p className="text-xs text-muted-foreground">
                                Generating voice (30s)...
                            </p>
                        )}
                        <div className="flex gap-1">
                            <Button
                                variant="ghost"
                                size="sm"
                                onClick={handlePlayVoice}
                                disabled={isLoading || isPlaying}
                                className="shrink-0"
                                title="Play voice"
                            >
                                {isLoading ? (
                                    <Loader2 className="h-4 w-4 animate-spin" />
                                ) : (
                                    <Volume2 className="h-4 w-4" />
                                )}
                            </Button>
                            <Button
                                variant="ghost"
                                size="sm"
                                onClick={stopAudio}
                                disabled={!isPlaying}
                                className={cn(
                                    "shrink-0",
                                    !isPlaying && "opacity-50"
                                )}
                                title="Stop voice"
                            >
                                <StopCircle className="h-4 w-4" />
                            </Button>
                        </div>
                    </div>
                )}
            </div>
            <p className="text-sm whitespace-pre-wrap">{message.content}</p>
            {/* Add citation footer if citations exist and showCitations is true */}
            {showCitations && message.citations && message.citations.length > 0 && (
                <CitationFooter citations={message.citations} />
            )}
        </div>
    );
}
</file>

<file path="src/components/debate/UserInput.tsx">
"use client";
import React, { useState, useEffect, useRef } from 'react';
import { Button } from '@/components/ui/button';
import { Textarea } from '@/components/ui/textarea';
import { useDebateStore } from '@/lib/store';
import { Mic, Send, StopCircle, Loader2, Volume2, VolumeX } from 'lucide-react';
import { useTheme } from '@/lib/theme';
import { cn } from '@/lib/utils';
interface UserInputProps {
    onSubmit?: (text: string) => void;
    placeholder?: string;
    buttonText?: string;
    disabled?: boolean;
}
export function UserInput({
    onSubmit,
    placeholder = "Enter your message...",
    buttonText = "Send",
    disabled = false
}: UserInputProps) {
    const [input, setInput] = useState('');
    const [isRecording, setIsRecording] = useState(false);
    const [isSpeechSupported, setIsSpeechSupported] = useState(false);
    const recognitionRef = useRef<any>(null);
    const {
        setTopic,
        setUserStance,
        isGenerating,
        topic,
        useVoiceSynthesis,
        setUseVoiceSynthesis
    } = useDebateStore();
    const { theme } = useTheme();
    // Initialize speech recognition
    useEffect(() => {
        // Check if browser supports speech recognition
        const browserSpeechRecognition =
            // @ts-ignore - TypeScript doesn't know about these browser-specific APIs
            window.SpeechRecognition || window.webkitSpeechRecognition;
        if (browserSpeechRecognition) {
            setIsSpeechSupported(true);
        }
    }, []);
    const handleSubmit = async (e: React.FormEvent) => {
        e.preventDefault();
        if (!input.trim() || disabled || isGenerating) return;
        if (onSubmit) {
            onSubmit(input);
        } else {
            // Default behavior if no onSubmit is provided
            if (!topic) {
                setTopic(input);
            } else {
                setUserStance(input);
            }
        }
        setInput('');
    };
    const handleKeyDown = (e: React.KeyboardEvent) => {
        if (e.key === 'Enter' && !e.shiftKey) {
            e.preventDefault();
            handleSubmit(e);
        }
    };
    const toggleRecording = async () => {
        if (!isSpeechSupported) {
            console.error('Speech recognition not supported in this browser');
            return;
        }
        if (!isRecording) {
            try {
                // Create a new recognition instance
                // @ts-ignore - TypeScript doesn't know about these browser-specific APIs
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                recognitionRef.current = new SpeechRecognition();
                const recognition = recognitionRef.current;
                recognition.continuous = true;
                recognition.interimResults = true;
                recognition.lang = 'en-US';
                recognition.onresult = (event: any) => {
                    const transcript = Array.from(event.results)
                        .map((result: any) => result[0])
                        .map((result: any) => result.transcript)
                        .join('');
                    setInput(transcript);
                };
                recognition.onerror = (event: any) => {
                    console.error('Speech recognition error', event.error);
                    setIsRecording(false);
                };
                recognition.onend = () => {
                    setIsRecording(false);
                };
                // Start recording
                recognition.start();
                setIsRecording(true);
            } catch (error) {
                console.error('Error starting speech recognition:', error);
                setIsRecording(false);
            }
        } else {
            // Stop recording
            if (recognitionRef.current) {
                recognitionRef.current.stop();
            }
            setIsRecording(false);
        }
    };
    return (
        <form onSubmit={handleSubmit} className="flex flex-col gap-2 w-full">
            {!topic && !onSubmit && (
                <div className="flex items-center gap-2 mb-2">
                    <Button
                        type="button"
                        variant={useVoiceSynthesis ? "success" : "destructive"}
                        size="sm"
                        onClick={() => setUseVoiceSynthesis(!useVoiceSynthesis)}
                        className="flex items-center gap-1.5 text-xs h-7 px-2"
                    >
                        {useVoiceSynthesis ? (
                            <>
                                <Volume2 className="h-3 w-3" />
                                <span>Voice On</span>
                            </>
                        ) : (
                            <>
                                <VolumeX className="h-3 w-3" />
                                <span>Voice Off</span>
                            </>
                        )}
                    </Button>
                    <p className={cn(
                        "text-xs",
                        useVoiceSynthesis
                            ? "text-[hsl(142,76%,36%)] dark:text-[hsl(142,76%,42%)]"
                            : "text-muted-foreground"
                    )}>
                        {useVoiceSynthesis
                            ? "Experts will respond with voice synthesis (additional cost)"
                            : "Text-only responses (no additional cost)"}
                    </p>
                </div>
            )}
            <div className="flex flex-col gap-2 w-full">
                <div className="w-full relative">
                    <Textarea
                        value={input}
                        onChange={(e) => setInput(e.target.value)}
                        onKeyDown={handleKeyDown}
                        placeholder={isRecording ? "Listening..." : placeholder}
                        className={cn(
                            "w-full min-h-[60px] max-h-[200px] resize-none",
                            "transition-colors duration-200",
                            "bg-gray-50 dark:bg-gray-900 border-input focus:border-ring",
                            isRecording && "border-red-500"
                        )}
                        disabled={disabled || isGenerating}
                    />
                    {isGenerating && (
                        <div className="absolute right-3 top-3 text-muted-foreground text-sm flex items-center gap-2">
                            <Loader2 className="h-4 w-4 animate-spin" />
                            Generating...
                        </div>
                    )}
                    {isRecording && (
                        <div className="absolute right-3 top-3 text-red-500 text-sm flex items-center gap-2">
                            <div className="h-2 w-2 rounded-full bg-red-500 animate-pulse"></div>
                            Recording...
                        </div>
                    )}
                </div>
                <div className="flex justify-end gap-2">
                    <Button
                        type="button"
                        variant={isRecording ? "destructive" : "secondary"}
                        size="icon"
                        onClick={toggleRecording}
                        disabled={disabled || isGenerating || !isSpeechSupported}
                        className="hover:border-red-500 hover:text-red-500 transition-colors duration-200"
                    >
                        {isRecording ?
                            <StopCircle className="h-4 w-4 text-red-500" /> :
                            <Mic className="h-4 w-4" />
                        }
                    </Button>
                    <Button
                        type="submit"
                        variant="success"
                        disabled={!input.trim() || disabled || isGenerating}
                        className="min-w-[80px]"
                    >
                        {isGenerating ? (
                            <Loader2 className="h-4 w-4 animate-spin" />
                        ) : buttonText ? (
                            buttonText
                        ) : (
                            <Send className="h-4 w-4" />
                        )}
                    </Button>
                </div>
            </div>
        </form>
    );
}
</file>

<file path="src/components/ui/AccountDetails.tsx">
"use client";
import { useState } from "react";
import { Button } from "./button";
import { Input } from "./input";
import { Check, Edit2, Save, X } from "lucide-react";
interface AccountDetailsProps {
    name: string;
    email: string;
    isEditable?: boolean;
    onSave?: (data: { name: string }) => Promise<boolean>;
}
export function AccountDetails({
    name,
    email,
    isEditable = true,
    onSave
}: AccountDetailsProps) {
    const [isEditing, setIsEditing] = useState(false);
    const [editedName, setEditedName] = useState(name);
    const [isSaving, setIsSaving] = useState(false);
    const [saveSuccess, setSaveSuccess] = useState(false);
    const handleSave = async () => {
        if (!onSave) return;
        setIsSaving(true);
        try {
            const success = await onSave({ name: editedName });
            if (success) {
                setSaveSuccess(true);
                setTimeout(() => setSaveSuccess(false), 3000);
                setIsEditing(false);
            } else {
                throw new Error("Failed to save account details");
            }
        } catch (error) {
            console.error("Error saving account details:", error);
            alert("Failed to save account details. Please try again.");
        } finally {
            setIsSaving(false);
        }
    };
    const handleCancel = () => {
        setEditedName(name);
        setIsEditing(false);
    };
    return (
        <div className="space-y-6">
            <div className="space-y-3">
                <div className="flex items-center justify-between">
                    <label className="text-xs font-medium text-gray-700 dark:text-gray-300">
                        Name
                    </label>
                    {isEditable && !isEditing && (
                        <Button
                            variant="ghost"
                            size="sm"
                            className="flex items-center gap-1 text-xs h-7 px-2"
                            onClick={() => setIsEditing(true)}
                        >
                            <Edit2 size={12} />
                            Edit
                        </Button>
                    )}
                </div>
                {isEditing ? (
                    <div className="space-y-2">
                        <Input
                            value={editedName}
                            onChange={(e) => setEditedName(e.target.value)}
                            placeholder="Your name"
                            className="w-full text-sm"
                        />
                        <div className="flex items-center gap-2">
                            <Button
                                size="sm"
                                className="flex items-center gap-1 text-xs h-7"
                                onClick={handleSave}
                                disabled={isSaving || editedName === name || !editedName.trim()}
                            >
                                {isSaving ? (
                                    "Saving..."
                                ) : (
                                    <>
                                        <Save size={12} />
                                        Save
                                    </>
                                )}
                            </Button>
                            <Button
                                variant="outline"
                                size="sm"
                                className="flex items-center gap-1 text-xs h-7"
                                onClick={handleCancel}
                                disabled={isSaving}
                            >
                                <X size={12} />
                                Cancel
                            </Button>
                        </div>
                    </div>
                ) : (
                    <div className="flex items-center">
                        <p className="text-base">{name}</p>
                        {saveSuccess && (
                            <span className="ml-2 text-green-500 flex items-center text-xs">
                                <Check size={12} className="mr-1" />
                                Saved
                            </span>
                        )}
                    </div>
                )}
            </div>
            <div className="space-y-2">
                <label className="text-xs font-medium text-gray-700 dark:text-gray-300">
                    Email
                </label>
                <p className="text-base">{email}</p>
                <p className="text-xs text-gray-500 dark:text-gray-400">
                    Your email address is used for login and notifications
                </p>
            </div>
        </div>
    );
}
</file>

<file path="src/components/ui/alert-dialog.tsx">
"use client"
import * as React from "react"
import * as AlertDialogPrimitive from "@radix-ui/react-alert-dialog"
import { cn } from "@/lib/utils"
import { buttonVariants } from "@/components/ui/button"
const AlertDialog = AlertDialogPrimitive.Root
const AlertDialogTrigger = AlertDialogPrimitive.Trigger
const AlertDialogPortal = AlertDialogPrimitive.Portal
const AlertDialogOverlay = React.forwardRef<
    React.ElementRef<typeof AlertDialogPrimitive.Overlay>,
    React.ComponentPropsWithoutRef<typeof AlertDialogPrimitive.Overlay>
>(({ className, ...props }, ref) => (
    <AlertDialogPrimitive.Overlay
        className={cn(
            "fixed inset-0 z-50 bg-black/80 data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0",
            className
        )}
        {...props}
        ref={ref}
    />
))
AlertDialogOverlay.displayName = AlertDialogPrimitive.Overlay.displayName
const AlertDialogContent = React.forwardRef<
    React.ElementRef<typeof AlertDialogPrimitive.Content>,
    React.ComponentPropsWithoutRef<typeof AlertDialogPrimitive.Content>
>(({ className, ...props }, ref) => (
    <AlertDialogPortal>
        <AlertDialogOverlay />
        <AlertDialogPrimitive.Content
            ref={ref}
            className={cn(
                "fixed left-[50%] top-[50%] z-50 grid w-full max-w-lg translate-x-[-50%] translate-y-[-50%] gap-4 border bg-background p-6 shadow-lg duration-200 data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[state=closed]:slide-out-to-left-1/2 data-[state=closed]:slide-out-to-top-[48%] data-[state=open]:slide-in-from-left-1/2 data-[state=open]:slide-in-from-top-[48%] sm:rounded-lg",
                className
            )}
            {...props}
        />
    </AlertDialogPortal>
))
AlertDialogContent.displayName = AlertDialogPrimitive.Content.displayName
const AlertDialogHeader = ({
    className,
    ...props
}: React.HTMLAttributes<HTMLDivElement>) => (
    <div
        className={cn(
            "flex flex-col space-y-2 text-center sm:text-left",
            className
        )}
        {...props}
    />
)
AlertDialogHeader.displayName = "AlertDialogHeader"
const AlertDialogFooter = ({
    className,
    ...props
}: React.HTMLAttributes<HTMLDivElement>) => (
    <div
        className={cn(
            "flex flex-col-reverse sm:flex-row sm:justify-end sm:space-x-2",
            className
        )}
        {...props}
    />
)
AlertDialogFooter.displayName = "AlertDialogFooter"
const AlertDialogTitle = React.forwardRef<
    React.ElementRef<typeof AlertDialogPrimitive.Title>,
    React.ComponentPropsWithoutRef<typeof AlertDialogPrimitive.Title>
>(({ className, ...props }, ref) => (
    <AlertDialogPrimitive.Title
        ref={ref}
        className={cn("text-lg font-semibold", className)}
        {...props}
    />
))
AlertDialogTitle.displayName = AlertDialogPrimitive.Title.displayName
const AlertDialogDescription = React.forwardRef<
    React.ElementRef<typeof AlertDialogPrimitive.Description>,
    React.ComponentPropsWithoutRef<typeof AlertDialogPrimitive.Description>
>(({ className, ...props }, ref) => (
    <AlertDialogPrimitive.Description
        ref={ref}
        className={cn("text-sm text-muted-foreground", className)}
        {...props}
    />
))
AlertDialogDescription.displayName =
    AlertDialogPrimitive.Description.displayName
const AlertDialogAction = React.forwardRef<
    React.ElementRef<typeof AlertDialogPrimitive.Action>,
    React.ComponentPropsWithoutRef<typeof AlertDialogPrimitive.Action>
>(({ className, ...props }, ref) => (
    <AlertDialogPrimitive.Action
        ref={ref}
        className={cn(buttonVariants(), className)}
        {...props}
    />
))
AlertDialogAction.displayName = AlertDialogPrimitive.Action.displayName
const AlertDialogCancel = React.forwardRef<
    React.ElementRef<typeof AlertDialogPrimitive.Cancel>,
    React.ComponentPropsWithoutRef<typeof AlertDialogPrimitive.Cancel>
>(({ className, ...props }, ref) => (
    <AlertDialogPrimitive.Cancel
        ref={ref}
        className={cn(
            buttonVariants({ variant: "outline" }),
            "mt-2 sm:mt-0",
            className
        )}
        {...props}
    />
))
AlertDialogCancel.displayName = AlertDialogPrimitive.Cancel.displayName
export {
    AlertDialog,
    AlertDialogPortal,
    AlertDialogOverlay,
    AlertDialogTrigger,
    AlertDialogContent,
    AlertDialogHeader,
    AlertDialogFooter,
    AlertDialogTitle,
    AlertDialogDescription,
    AlertDialogAction,
    AlertDialogCancel,
}
</file>

<file path="src/components/ui/avatar.tsx">
"use client";
import * as React from "react";
import * as AvatarPrimitive from "@radix-ui/react-avatar";
import { cn } from "@/lib/utils";
const Avatar = React.forwardRef<
    React.ElementRef<typeof AvatarPrimitive.Root>,
    React.ComponentPropsWithoutRef<typeof AvatarPrimitive.Root>
>(({ className, ...props }, ref) => (
    <AvatarPrimitive.Root
        ref={ref}
        className={cn(
            "relative flex h-10 w-10 shrink-0 overflow-hidden rounded-full",
            className
        )}
        {...props}
    />
));
Avatar.displayName = AvatarPrimitive.Root.displayName;
const AvatarImage = React.forwardRef<
    React.ElementRef<typeof AvatarPrimitive.Image>,
    React.ComponentPropsWithoutRef<typeof AvatarPrimitive.Image>
>(({ className, ...props }, ref) => (
    <AvatarPrimitive.Image
        ref={ref}
        className={cn("aspect-square h-full w-full", className)}
        {...props}
    />
));
AvatarImage.displayName = AvatarPrimitive.Image.displayName;
const AvatarFallback = React.forwardRef<
    React.ElementRef<typeof AvatarPrimitive.Fallback>,
    React.ComponentPropsWithoutRef<typeof AvatarPrimitive.Fallback>
>(({ className, ...props }, ref) => (
    <AvatarPrimitive.Fallback
        ref={ref}
        className={cn(
            "flex h-full w-full items-center justify-center rounded-full bg-muted",
            className
        )}
        {...props}
    />
));
AvatarFallback.displayName = AvatarPrimitive.Fallback.displayName;
export { Avatar, AvatarImage, AvatarFallback };
</file>

<file path="src/components/ui/button.tsx">
"use client";
import * as React from "react";
import { cn } from "@/lib/utils";
export interface ButtonProps
    extends React.ButtonHTMLAttributes<HTMLButtonElement> {
    variant?: "default" | "secondary" | "ghost" | "link" | "success" | "destructive";
    size?: "default" | "sm" | "lg" | "icon";
    isLoading?: boolean;
}
const Button = React.forwardRef<HTMLButtonElement, ButtonProps>(
    ({ className, variant = "default", size = "default", isLoading, children, ...props }, ref) => {
        const baseStyles = "inline-flex items-center justify-center rounded-md font-medium transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:opacity-50 disabled:pointer-events-none ring-offset-background";
        const variants = {
            default: "bg-primary text-primary-foreground hover:bg-primary/90",
            secondary: "bg-secondary text-secondary-foreground hover:bg-secondary/80",
            ghost: "hover:bg-accent hover:text-accent-foreground",
            link: "underline-offset-4 hover:underline text-primary",
            success: "bg-green-600 text-white hover:bg-green-700 dark:bg-green-500 dark:hover:bg-green-600",
            destructive: "bg-red-600 text-white hover:bg-red-700 dark:bg-red-500 dark:hover:bg-red-600",
        };
        const sizes = {
            default: "h-10 py-2 px-4",
            sm: "h-9 px-3 rounded-md",
            lg: "h-11 px-8 rounded-md",
            icon: "h-10 w-10",
        };
        return (
            <button
                className={cn(
                    baseStyles,
                    variants[variant],
                    sizes[size],
                    isLoading && "opacity-50 cursor-wait",
                    className
                )}
                ref={ref}
                disabled={isLoading}
                {...props}
            >
                {isLoading ? (
                    <span className="mr-2 animate-spin">⏳</span>
                ) : null}
                {children}
            </button>
        );
    }
);
Button.displayName = "Button";
export { Button };
</file>

<file path="src/components/ui/card.tsx">
import * as React from "react"
import { cn } from "@/lib/utils"
const Card = React.forwardRef<
    HTMLDivElement,
    React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
    <div
        ref={ref}
        className={cn(
            "rounded-lg border bg-card text-card-foreground shadow-sm",
            className
        )}
        {...props}
    />
))
Card.displayName = "Card"
const CardHeader = React.forwardRef<
    HTMLDivElement,
    React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
    <div
        ref={ref}
        className={cn("flex flex-col space-y-1.5 p-6", className)}
        {...props}
    />
))
CardHeader.displayName = "CardHeader"
const CardTitle = React.forwardRef<
    HTMLParagraphElement,
    React.HTMLAttributes<HTMLHeadingElement>
>(({ className, ...props }, ref) => (
    <h3
        ref={ref}
        className={cn(
            "text-2xl font-semibold leading-none tracking-tight",
            className
        )}
        {...props}
    />
))
CardTitle.displayName = "CardTitle"
const CardDescription = React.forwardRef<
    HTMLParagraphElement,
    React.HTMLAttributes<HTMLParagraphElement>
>(({ className, ...props }, ref) => (
    <p
        ref={ref}
        className={cn("text-sm text-muted-foreground", className)}
        {...props}
    />
))
CardDescription.displayName = "CardDescription"
const CardContent = React.forwardRef<
    HTMLDivElement,
    React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
    <div ref={ref} className={cn("p-6 pt-0", className)} {...props} />
))
CardContent.displayName = "CardContent"
const CardFooter = React.forwardRef<
    HTMLDivElement,
    React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
    <div
        ref={ref}
        className={cn("flex items-center p-6 pt-0", className)}
        {...props}
    />
))
CardFooter.displayName = "CardFooter"
export { Card, CardHeader, CardTitle, CardDescription, CardContent, CardFooter }
</file>

<file path="src/components/ui/dropdown-menu.tsx">
import * as React from "react"
import * as DropdownMenuPrimitive from "@radix-ui/react-dropdown-menu"
import { Check, ChevronRight, Circle } from "lucide-react"
import { cn } from "@/lib/utils"
const DropdownMenu = DropdownMenuPrimitive.Root
const DropdownMenuTrigger = DropdownMenuPrimitive.Trigger
const DropdownMenuGroup = DropdownMenuPrimitive.Group
const DropdownMenuPortal = DropdownMenuPrimitive.Portal
const DropdownMenuSub = DropdownMenuPrimitive.Sub
const DropdownMenuRadioGroup = DropdownMenuPrimitive.RadioGroup
const DropdownMenuSubTrigger = React.forwardRef<
    React.ElementRef<typeof DropdownMenuPrimitive.SubTrigger>,
    React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.SubTrigger> & {
        inset?: boolean
    }
>(({ className, inset, children, ...props }, ref) => (
    <DropdownMenuPrimitive.SubTrigger
        ref={ref}
        className={cn(
            "flex cursor-default select-none items-center rounded-sm px-2 py-1.5 text-sm outline-none focus:bg-accent data-[state=open]:bg-accent",
            inset && "pl-8",
            className
        )}
        {...props}
    >
        {children}
        <ChevronRight className="ml-auto h-4 w-4" />
    </DropdownMenuPrimitive.SubTrigger>
))
DropdownMenuSubTrigger.displayName =
    DropdownMenuPrimitive.SubTrigger.displayName
const DropdownMenuSubContent = React.forwardRef<
    React.ElementRef<typeof DropdownMenuPrimitive.SubContent>,
    React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.SubContent>
>(({ className, ...props }, ref) => (
    <DropdownMenuPrimitive.SubContent
        ref={ref}
        className={cn(
            "z-50 min-w-[8rem] overflow-hidden rounded-md border bg-popover p-1 text-popover-foreground shadow-md animate-in data-[side=bottom]:slide-in-from-top-1 data-[side=left]:slide-in-from-right-1 data-[side=right]:slide-in-from-left-1 data-[side=top]:slide-in-from-bottom-1",
            className
        )}
        {...props}
    />
))
DropdownMenuSubContent.displayName =
    DropdownMenuPrimitive.SubContent.displayName
const DropdownMenuContent = React.forwardRef<
    React.ElementRef<typeof DropdownMenuPrimitive.Content>,
    React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.Content>
>(({ className, sideOffset = 4, ...props }, ref) => (
    <DropdownMenuPrimitive.Portal>
        <DropdownMenuPrimitive.Content
            ref={ref}
            sideOffset={sideOffset}
            className={cn(
                "z-50 min-w-[8rem] overflow-hidden rounded-md border bg-popover p-1 text-popover-foreground shadow-md animate-in data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2",
                className
            )}
            {...props}
        />
    </DropdownMenuPrimitive.Portal>
))
DropdownMenuContent.displayName = DropdownMenuPrimitive.Content.displayName
const DropdownMenuItem = React.forwardRef<
    React.ElementRef<typeof DropdownMenuPrimitive.Item>,
    React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.Item> & {
        inset?: boolean
    }
>(({ className, inset, ...props }, ref) => (
    <DropdownMenuPrimitive.Item
        ref={ref}
        className={cn(
            "relative flex cursor-default select-none items-center rounded-sm px-2 py-1.5 text-sm outline-none transition-colors focus:bg-accent focus:text-accent-foreground data-[disabled]:pointer-events-none data-[disabled]:opacity-50",
            inset && "pl-8",
            className
        )}
        {...props}
    />
))
DropdownMenuItem.displayName = DropdownMenuPrimitive.Item.displayName
const DropdownMenuCheckboxItem = React.forwardRef<
    React.ElementRef<typeof DropdownMenuPrimitive.CheckboxItem>,
    React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.CheckboxItem>
>(({ className, children, checked, ...props }, ref) => (
    <DropdownMenuPrimitive.CheckboxItem
        ref={ref}
        className={cn(
            "relative flex cursor-default select-none items-center rounded-sm py-1.5 pl-8 pr-2 text-sm outline-none transition-colors focus:bg-accent focus:text-accent-foreground data-[disabled]:pointer-events-none data-[disabled]:opacity-50",
            className
        )}
        checked={checked}
        {...props}
    >
        <span className="absolute left-2 flex h-3.5 w-3.5 items-center justify-center">
            <DropdownMenuPrimitive.ItemIndicator>
                <Check className="h-4 w-4" />
            </DropdownMenuPrimitive.ItemIndicator>
        </span>
        {children}
    </DropdownMenuPrimitive.CheckboxItem>
))
DropdownMenuCheckboxItem.displayName =
    DropdownMenuPrimitive.CheckboxItem.displayName
const DropdownMenuRadioItem = React.forwardRef<
    React.ElementRef<typeof DropdownMenuPrimitive.RadioItem>,
    React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.RadioItem>
>(({ className, children, ...props }, ref) => (
    <DropdownMenuPrimitive.RadioItem
        ref={ref}
        className={cn(
            "relative flex cursor-default select-none items-center rounded-sm py-1.5 pl-8 pr-2 text-sm outline-none transition-colors focus:bg-accent focus:text-accent-foreground data-[disabled]:pointer-events-none data-[disabled]:opacity-50",
            className
        )}
        {...props}
    >
        <span className="absolute left-2 flex h-3.5 w-3.5 items-center justify-center">
            <DropdownMenuPrimitive.ItemIndicator>
                <Circle className="h-2 w-2 fill-current" />
            </DropdownMenuPrimitive.ItemIndicator>
        </span>
        {children}
    </DropdownMenuPrimitive.RadioItem>
))
DropdownMenuRadioItem.displayName = DropdownMenuPrimitive.RadioItem.displayName
const DropdownMenuLabel = React.forwardRef<
    React.ElementRef<typeof DropdownMenuPrimitive.Label>,
    React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.Label> & {
        inset?: boolean
    }
>(({ className, inset, ...props }, ref) => (
    <DropdownMenuPrimitive.Label
        ref={ref}
        className={cn(
            "px-2 py-1.5 text-sm font-semibold",
            inset && "pl-8",
            className
        )}
        {...props}
    />
))
DropdownMenuLabel.displayName = DropdownMenuPrimitive.Label.displayName
const DropdownMenuSeparator = React.forwardRef<
    React.ElementRef<typeof DropdownMenuPrimitive.Separator>,
    React.ComponentPropsWithoutRef<typeof DropdownMenuPrimitive.Separator>
>(({ className, ...props }, ref) => (
    <DropdownMenuPrimitive.Separator
        ref={ref}
        className={cn("-mx-1 my-1 h-px bg-muted", className)}
        {...props}
    />
))
DropdownMenuSeparator.displayName = DropdownMenuPrimitive.Separator.displayName
const DropdownMenuShortcut = ({
    className,
    ...props
}: React.HTMLAttributes<HTMLSpanElement>) => {
    return (
        <span
            className={cn("ml-auto text-xs tracking-widest opacity-60", className)}
            {...props}
        />
    )
}
DropdownMenuShortcut.displayName = "DropdownMenuShortcut"
export {
    DropdownMenu,
    DropdownMenuTrigger,
    DropdownMenuContent,
    DropdownMenuItem,
    DropdownMenuCheckboxItem,
    DropdownMenuRadioItem,
    DropdownMenuLabel,
    DropdownMenuSeparator,
    DropdownMenuShortcut,
    DropdownMenuGroup,
    DropdownMenuPortal,
    DropdownMenuSub,
    DropdownMenuSubContent,
    DropdownMenuSubTrigger,
    DropdownMenuRadioGroup,
}
</file>

<file path="src/components/ui/input.tsx">
"use client";
import * as React from "react";
import { cn } from "@/lib/utils";
export interface InputProps
    extends React.InputHTMLAttributes<HTMLInputElement> { }
const Input = React.forwardRef<HTMLInputElement, InputProps>(
    ({ className, type, ...props }, ref) => {
        return (
            <input
                type={type}
                className={cn(
                    "flex h-10 w-full rounded-md border border-input bg-background px-3 py-2 text-sm ring-offset-background file:border-0 file:bg-transparent file:text-sm file:font-medium placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50",
                    className
                )}
                ref={ref}
                {...props}
            />
        );
    }
);
Input.displayName = "Input";
export { Input };
</file>

<file path="src/components/ui/PreferenceSettings.tsx">
"use client";
import { useState, useEffect } from "react";
import { Switch } from "./switch";
import { Button } from "./button";
import { Check, Save } from "lucide-react";
import { useTheme } from "next-themes";
import {
    Select,
    SelectContent,
    SelectItem,
    SelectTrigger,
    SelectValue,
} from "./select";
interface UserPreferences {
    defaultExpertType: 'historical' | 'domain';
    useVoiceSynthesis: boolean;
    theme: 'light' | 'dark' | 'system';
}
interface PreferenceSettingsProps {
    preferences: UserPreferences;
    onSave: (preferences: UserPreferences) => Promise<boolean>;
}
export function PreferenceSettings({ preferences, onSave }: PreferenceSettingsProps) {
    const { setTheme } = useTheme();
    const [editedPreferences, setEditedPreferences] = useState<UserPreferences>({ ...preferences });
    const [isSaving, setIsSaving] = useState(false);
    const [saveSuccess, setSaveSuccess] = useState(false);
    useEffect(() => {
        if (editedPreferences.theme !== preferences.theme) {
            setTheme(editedPreferences.theme);
        }
    }, [editedPreferences.theme, preferences.theme, setTheme]);
    const handleSave = async () => {
        setIsSaving(true);
        try {
            const success = await onSave(editedPreferences);
            if (success) {
                setSaveSuccess(true);
                setTimeout(() => setSaveSuccess(false), 3000);
            } else {
                throw new Error("Failed to save preferences");
            }
        } catch (error) {
            console.error("Error saving preferences:", error);
            alert("Failed to save preferences. Please try again.");
        } finally {
            setIsSaving(false);
        }
    };
    const hasChanges = JSON.stringify(preferences) !== JSON.stringify(editedPreferences);
    return (
        <div className="space-y-6">
            <div className="space-y-3">
                <label className="text-xs font-medium text-gray-700 dark:text-gray-300">
                    Default Expert Type
                </label>
                <Select
                    value={editedPreferences.defaultExpertType}
                    onValueChange={(value) =>
                        setEditedPreferences({
                            ...editedPreferences,
                            defaultExpertType: value as 'historical' | 'domain'
                        })
                    }
                >
                    <SelectTrigger className="w-full text-sm">
                        <SelectValue placeholder="Select expert type" />
                    </SelectTrigger>
                    <SelectContent>
                        <SelectItem value="historical" className="text-sm">Historical Figures</SelectItem>
                        <SelectItem value="domain" className="text-sm">Domain Experts</SelectItem>
                    </SelectContent>
                </Select>
                <p className="text-xs text-gray-500 dark:text-gray-400">
                    Choose your preferred type of experts for debates
                </p>
            </div>
            <div className="space-y-3">
                <div className="flex items-center justify-between">
                    <label className="text-xs font-medium text-gray-700 dark:text-gray-300">
                        Voice Synthesis
                    </label>
                    <Switch
                        checked={editedPreferences.useVoiceSynthesis}
                        onCheckedChange={(checked) =>
                            setEditedPreferences({
                                ...editedPreferences,
                                useVoiceSynthesis: checked
                            })
                        }
                    />
                </div>
                <p className="text-xs text-gray-500 dark:text-gray-400">
                    Enable voice synthesis for expert responses
                </p>
            </div>
            <div className="space-y-3">
                <label className="text-xs font-medium text-gray-700 dark:text-gray-300">
                    Theme
                </label>
                <Select
                    value={editedPreferences.theme}
                    onValueChange={(value) =>
                        setEditedPreferences({
                            ...editedPreferences,
                            theme: value as 'light' | 'dark' | 'system'
                        })
                    }
                >
                    <SelectTrigger className="w-full text-sm">
                        <SelectValue placeholder="Select theme" />
                    </SelectTrigger>
                    <SelectContent>
                        <SelectItem value="light" className="text-sm">Light</SelectItem>
                        <SelectItem value="dark" className="text-sm">Dark</SelectItem>
                        <SelectItem value="system" className="text-sm">System</SelectItem>
                    </SelectContent>
                </Select>
                <p className="text-xs text-gray-500 dark:text-gray-400">
                    Choose your preferred application theme (changes applied immediately)
                </p>
            </div>
            <div className="pt-4">
                <Button
                    className="w-full flex items-center justify-center gap-2 text-sm"
                    onClick={handleSave}
                    disabled={!hasChanges || isSaving}
                >
                    {isSaving ? (
                        "Saving..."
                    ) : saveSuccess ? (
                        <>
                            <Check size={14} />
                            Saved
                        </>
                    ) : (
                        <>
                            <Save size={14} />
                            Save Preferences
                        </>
                    )}
                </Button>
            </div>
        </div>
    );
}
</file>

<file path="src/components/ui/ProfilePicture.tsx">
"use client";
import { useState, useRef } from "react";
import Image from "next/image";
import { Camera, Upload, X, AlertCircle } from "lucide-react";
import { Button } from "./button";
import {
    AlertDialog,
    AlertDialogAction,
    AlertDialogCancel,
    AlertDialogContent,
    AlertDialogDescription,
    AlertDialogFooter,
    AlertDialogHeader,
    AlertDialogTitle,
} from "./alert-dialog";
interface ProfilePictureProps {
    imageUrl?: string | null;
    userName: string;
    onImageChange: (imageDataUrl: string | null) => Promise<boolean>;
    className?: string;
    size?: "small" | "medium" | "large";
}
export function ProfilePicture({
    imageUrl,
    userName,
    onImageChange,
    className = "",
    size = "medium"
}: ProfilePictureProps) {
    const [isEditMode, setIsEditMode] = useState(false);
    const [isRemoving, setIsRemoving] = useState(false);
    const [showDeleteDialog, setShowDeleteDialog] = useState(false);
    const [isLoading, setIsLoading] = useState(false);
    const fileInputRef = useRef<HTMLInputElement>(null);
    // Get first letter of name for fallback avatar
    const nameInitial = userName?.charAt(0)?.toUpperCase() || "?";
    // Map size string to pixel value
    const sizeMap = {
        small: 64,
        medium: 120,
        large: 160
    };
    const pixelSize = typeof size === "string" ? sizeMap[size] : size;
    // Handle profile picture upload
    const handleFileChange = async (e: React.ChangeEvent<HTMLInputElement>) => {
        const file = e.target.files?.[0];
        if (!file) return;
        // Check file size (max 5MB)
        if (file.size > 5 * 1024 * 1024) {
            alert("Image is too large. Maximum size is 5MB.");
            return;
        }
        // Check file type
        if (!file.type.startsWith("image/")) {
            alert("Please upload an image file.");
            return;
        }
        setIsLoading(true);
        try {
            const reader = new FileReader();
            reader.onload = async (e) => {
                const dataUrl = e.target?.result as string;
                const success = await onImageChange(dataUrl);
                if (success) {
                    setIsEditMode(false);
                } else {
                    alert("Failed to update profile picture. Please try again.");
                }
                setIsLoading(false);
            };
            reader.readAsDataURL(file);
        } catch (error) {
            console.error("Error uploading image:", error);
            alert("Failed to upload image. Please try again.");
            setIsLoading(false);
        }
    };
    const confirmRemoveImage = () => {
        setShowDeleteDialog(true);
    };
    const handleRemoveImage = async () => {
        setIsRemoving(true);
        try {
            const success = await onImageChange(null);
            if (success) {
                setIsEditMode(false);
                setShowDeleteDialog(false);
            } else {
                alert("Failed to remove profile picture. Please try again.");
            }
        } catch (error) {
            console.error("Error removing image:", error);
        } finally {
            setIsRemoving(false);
        }
    };
    return (
        <div className={`relative ${className}`}>
            {/* Profile Image */}
            {imageUrl ? (
                <Image
                    src={imageUrl}
                    alt={`${userName}'s profile`}
                    width={pixelSize}
                    height={pixelSize}
                    className="rounded-full object-cover"
                />
            ) : (
                <div
                    className="rounded-full bg-primary flex items-center justify-center text-white font-bold"
                    style={{ width: pixelSize, height: pixelSize }}
                >
                    {nameInitial}
                </div>
            )}
            {/* Edit Overlay */}
            <div
                className="absolute inset-0 rounded-full flex items-center justify-center bg-black bg-opacity-40 opacity-0 hover:opacity-100 transition cursor-pointer"
                onClick={() => setIsEditMode(true)}
            >
                <div className="bg-black bg-opacity-50 p-3 rounded-full">
                    <Camera className="text-white" size={pixelSize / 2.5} strokeWidth={2} />
                </div>
            </div>
            {/* Upload Dialog */}
            {isEditMode && (
                <div className="absolute top-full left-1/2 transform -translate-x-1/2 mt-2 bg-white dark:bg-gray-800 p-4 rounded-lg shadow-lg z-10 min-w-[200px] w-max">
                    <div className="flex flex-col gap-3">
                        <Button
                            variant="outline"
                            size="sm"
                            className="flex items-center justify-center gap-2 w-full px-4 py-2"
                            onClick={() => fileInputRef.current?.click()}
                            disabled={isLoading}
                        >
                            {isLoading ? (
                                <span className="animate-spin mr-2">⏳</span>
                            ) : (
                                <Upload size={18} />
                            )}
                            {isLoading ? "Uploading..." : "Upload Photo"}
                        </Button>
                        {imageUrl && (
                            <Button
                                variant="destructive"
                                size="sm"
                                className="flex items-center justify-center gap-2 w-full px-4 py-2"
                                onClick={confirmRemoveImage}
                                disabled={isRemoving}
                            >
                                <X size={18} />
                                {isRemoving ? "Removing..." : "Remove Photo"}
                            </Button>
                        )}
                        <Button
                            variant="secondary"
                            size="sm"
                            className="w-full px-4 py-2"
                            onClick={() => setIsEditMode(false)}
                            disabled={isLoading || isRemoving}
                        >
                            Cancel
                        </Button>
                    </div>
                    <input
                        type="file"
                        ref={fileInputRef}
                        onChange={handleFileChange}
                        className="hidden"
                        accept="image/*"
                    />
                </div>
            )}
            {/* Delete Confirmation Dialog */}
            <AlertDialog open={showDeleteDialog} onOpenChange={setShowDeleteDialog}>
                <AlertDialogContent>
                    <AlertDialogHeader>
                        <AlertDialogTitle>Remove Profile Picture</AlertDialogTitle>
                        <AlertDialogDescription>
                            Are you sure you want to remove your profile picture?
                            This action cannot be undone.
                        </AlertDialogDescription>
                    </AlertDialogHeader>
                    <AlertDialogFooter>
                        <AlertDialogCancel disabled={isRemoving}>Cancel</AlertDialogCancel>
                        <AlertDialogAction
                            onClick={handleRemoveImage}
                            disabled={isRemoving}
                            className="bg-destructive text-destructive-foreground hover:bg-destructive/90"
                        >
                            {isRemoving ? "Removing..." : "Remove"}
                        </AlertDialogAction>
                    </AlertDialogFooter>
                </AlertDialogContent>
            </AlertDialog>
        </div>
    );
}
</file>

<file path="src/components/ui/select.tsx">
"use client"
import * as React from "react"
import * as SelectPrimitive from "@radix-ui/react-select"
import { Check, ChevronDown, ChevronUp } from "lucide-react"
import { cn } from "@/lib/utils"
const Select = SelectPrimitive.Root
const SelectGroup = SelectPrimitive.Group
const SelectValue = SelectPrimitive.Value
const SelectTrigger = React.forwardRef<
    React.ElementRef<typeof SelectPrimitive.Trigger>,
    React.ComponentPropsWithoutRef<typeof SelectPrimitive.Trigger>
>(({ className, children, ...props }, ref) => (
    <SelectPrimitive.Trigger
        ref={ref}
        className={cn(
            "flex h-10 w-full items-center justify-between rounded-md border border-input bg-background px-3 py-2 text-sm ring-offset-background placeholder:text-muted-foreground focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50 [&>span]:line-clamp-1",
            className
        )}
        {...props}
    >
        {children}
        <SelectPrimitive.Icon asChild>
            <ChevronDown className="h-4 w-4 opacity-50" />
        </SelectPrimitive.Icon>
    </SelectPrimitive.Trigger>
))
SelectTrigger.displayName = SelectPrimitive.Trigger.displayName
const SelectScrollUpButton = React.forwardRef<
    React.ElementRef<typeof SelectPrimitive.ScrollUpButton>,
    React.ComponentPropsWithoutRef<typeof SelectPrimitive.ScrollUpButton>
>(({ className, ...props }, ref) => (
    <SelectPrimitive.ScrollUpButton
        ref={ref}
        className={cn(
            "flex cursor-default items-center justify-center py-1",
            className
        )}
        {...props}
    >
        <ChevronUp className="h-4 w-4" />
    </SelectPrimitive.ScrollUpButton>
))
SelectScrollUpButton.displayName = SelectPrimitive.ScrollUpButton.displayName
const SelectScrollDownButton = React.forwardRef<
    React.ElementRef<typeof SelectPrimitive.ScrollDownButton>,
    React.ComponentPropsWithoutRef<typeof SelectPrimitive.ScrollDownButton>
>(({ className, ...props }, ref) => (
    <SelectPrimitive.ScrollDownButton
        ref={ref}
        className={cn(
            "flex cursor-default items-center justify-center py-1",
            className
        )}
        {...props}
    >
        <ChevronDown className="h-4 w-4" />
    </SelectPrimitive.ScrollDownButton>
))
SelectScrollDownButton.displayName =
    SelectPrimitive.ScrollDownButton.displayName
const SelectContent = React.forwardRef<
    React.ElementRef<typeof SelectPrimitive.Content>,
    React.ComponentPropsWithoutRef<typeof SelectPrimitive.Content>
>(({ className, children, position = "popper", ...props }, ref) => (
    <SelectPrimitive.Portal>
        <SelectPrimitive.Content
            ref={ref}
            className={cn(
                "relative z-50 max-h-96 min-w-[8rem] overflow-hidden rounded-md border bg-popover text-popover-foreground shadow-md data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2",
                position === "popper" &&
                "data-[side=bottom]:translate-y-1 data-[side=left]:-translate-x-1 data-[side=right]:translate-x-1 data-[side=top]:-translate-y-1",
                className
            )}
            position={position}
            {...props}
        >
            <SelectScrollUpButton />
            <SelectPrimitive.Viewport
                className={cn(
                    "p-1",
                    position === "popper" &&
                    "h-[var(--radix-select-trigger-height)] w-full min-w-[var(--radix-select-trigger-width)]"
                )}
            >
                {children}
            </SelectPrimitive.Viewport>
            <SelectScrollDownButton />
        </SelectPrimitive.Content>
    </SelectPrimitive.Portal>
))
SelectContent.displayName = SelectPrimitive.Content.displayName
const SelectLabel = React.forwardRef<
    React.ElementRef<typeof SelectPrimitive.Label>,
    React.ComponentPropsWithoutRef<typeof SelectPrimitive.Label>
>(({ className, ...props }, ref) => (
    <SelectPrimitive.Label
        ref={ref}
        className={cn("py-1.5 pl-8 pr-2 text-sm font-semibold", className)}
        {...props}
    />
))
SelectLabel.displayName = SelectPrimitive.Label.displayName
const SelectItem = React.forwardRef<
    React.ElementRef<typeof SelectPrimitive.Item>,
    React.ComponentPropsWithoutRef<typeof SelectPrimitive.Item>
>(({ className, children, ...props }, ref) => (
    <SelectPrimitive.Item
        ref={ref}
        className={cn(
            "relative flex w-full cursor-default select-none items-center rounded-sm py-1.5 pl-8 pr-2 text-sm outline-none focus:bg-accent focus:text-accent-foreground data-[disabled]:pointer-events-none data-[disabled]:opacity-50",
            className
        )}
        {...props}
    >
        <span className="absolute left-2 flex h-3.5 w-3.5 items-center justify-center">
            <SelectPrimitive.ItemIndicator>
                <Check className="h-4 w-4" />
            </SelectPrimitive.ItemIndicator>
        </span>
        <SelectPrimitive.ItemText>{children}</SelectPrimitive.ItemText>
    </SelectPrimitive.Item>
))
SelectItem.displayName = SelectPrimitive.Item.displayName
const SelectSeparator = React.forwardRef<
    React.ElementRef<typeof SelectPrimitive.Separator>,
    React.ComponentPropsWithoutRef<typeof SelectPrimitive.Separator>
>(({ className, ...props }, ref) => (
    <SelectPrimitive.Separator
        ref={ref}
        className={cn("-mx-1 my-1 h-px bg-muted", className)}
        {...props}
    />
))
SelectSeparator.displayName = SelectPrimitive.Separator.displayName
export {
    Select,
    SelectGroup,
    SelectValue,
    SelectTrigger,
    SelectContent,
    SelectLabel,
    SelectItem,
    SelectSeparator,
    SelectScrollUpButton,
    SelectScrollDownButton,
}
</file>

<file path="src/components/ui/skeleton.tsx">
import { cn } from "@/lib/utils"
function Skeleton({
    className,
    ...props
}: React.HTMLAttributes<HTMLDivElement>) {
    return (
        <div
            className={cn("animate-pulse rounded-md bg-muted", className)}
            {...props}
        />
    )
}
export { Skeleton }
</file>

<file path="src/components/ui/spinner.tsx">
"use client";
import { cn } from "@/lib/utils";
interface SpinnerProps {
    size?: "sm" | "md" | "lg";
    className?: string;
}
export function Spinner({ size = "md", className }: SpinnerProps) {
    const sizeClasses = {
        sm: "h-4 w-4 border-2",
        md: "h-8 w-8 border-3",
        lg: "h-12 w-12 border-4",
    };
    return (
        <div
            className={cn(
                "animate-spin rounded-full border-primary border-t-transparent",
                sizeClasses[size],
                className
            )}
        />
    );
}
interface LoadingProps {
    text?: string;
    size?: "sm" | "md" | "lg";
    className?: string;
}
export function Loading({ text = "Loading...", size = "md", className }: LoadingProps) {
    return (
        <div className={cn("flex flex-col items-center justify-center gap-3", className)}>
            <Spinner size={size} />
            {text && <p className="text-muted-foreground text-sm">{text}</p>}
        </div>
    );
}
</file>

<file path="src/components/ui/switch.tsx">
"use client"
import * as React from "react"
import * as SwitchPrimitives from "@radix-ui/react-switch"
import { cn } from "@/lib/utils"
const Switch = React.forwardRef<
    React.ElementRef<typeof SwitchPrimitives.Root>,
    React.ComponentPropsWithoutRef<typeof SwitchPrimitives.Root>
>(({ className, ...props }, ref) => (
    <SwitchPrimitives.Root
        className={cn(
            "peer inline-flex h-6 w-11 shrink-0 cursor-pointer items-center rounded-full border-2 border-transparent transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 focus-visible:ring-offset-background disabled:cursor-not-allowed disabled:opacity-50 data-[state=checked]:bg-primary data-[state=unchecked]:bg-input",
            className
        )}
        {...props}
        ref={ref}
    >
        <SwitchPrimitives.Thumb
            className={cn(
                "pointer-events-none block h-5 w-5 rounded-full bg-background shadow-lg ring-0 transition-transform data-[state=checked]:translate-x-5 data-[state=unchecked]:translate-x-0"
            )}
        />
    </SwitchPrimitives.Root>
))
Switch.displayName = SwitchPrimitives.Root.displayName
export { Switch }
</file>

<file path="src/components/ui/tabs.tsx">
"use client"
import * as React from "react"
import * as TabsPrimitive from "@radix-ui/react-tabs"
import { cn } from "@/lib/utils"
const Tabs = TabsPrimitive.Root
const TabsList = React.forwardRef<
    React.ElementRef<typeof TabsPrimitive.List>,
    React.ComponentPropsWithoutRef<typeof TabsPrimitive.List>
>(({ className, ...props }, ref) => (
    <TabsPrimitive.List
        ref={ref}
        className={cn(
            "inline-flex h-10 items-center justify-center rounded-md bg-muted p-1 text-muted-foreground",
            className
        )}
        {...props}
    />
))
TabsList.displayName = TabsPrimitive.List.displayName
const TabsTrigger = React.forwardRef<
    React.ElementRef<typeof TabsPrimitive.Trigger>,
    React.ComponentPropsWithoutRef<typeof TabsPrimitive.Trigger>
>(({ className, ...props }, ref) => (
    <TabsPrimitive.Trigger
        ref={ref}
        className={cn(
            "inline-flex items-center justify-center whitespace-nowrap rounded-sm px-3 py-1.5 text-sm font-medium ring-offset-background transition-all focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 data-[state=active]:bg-background data-[state=active]:text-foreground data-[state=active]:shadow-sm",
            className
        )}
        {...props}
    />
))
TabsTrigger.displayName = TabsPrimitive.Trigger.displayName
const TabsContent = React.forwardRef<
    React.ElementRef<typeof TabsPrimitive.Content>,
    React.ComponentPropsWithoutRef<typeof TabsPrimitive.Content>
>(({ className, ...props }, ref) => (
    <TabsPrimitive.Content
        ref={ref}
        className={cn(
            "mt-2 ring-offset-background focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2",
            className
        )}
        {...props}
    />
))
TabsContent.displayName = TabsPrimitive.Content.displayName
export { Tabs, TabsList, TabsTrigger, TabsContent }
</file>

<file path="src/components/ui/textarea.tsx">
"use client";
import * as React from "react";
import { cn } from "@/lib/utils";
export interface TextareaProps
    extends React.TextareaHTMLAttributes<HTMLTextAreaElement> { }
const Textarea = React.forwardRef<HTMLTextAreaElement, TextareaProps>(
    ({ className, ...props }, ref) => {
        return (
            <textarea
                className={cn(
                    "flex min-h-[80px] w-full rounded-md border border-input bg-background px-3 py-2 text-sm ring-offset-background placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50",
                    className
                )}
                ref={ref}
                {...props}
            />
        );
    }
);
Textarea.displayName = "Textarea";
export { Textarea };
</file>

<file path="src/components/ui/toast.tsx">
"use client"
import * as React from "react"
import * as ToastPrimitives from "@radix-ui/react-toast"
import { cva, type VariantProps } from "class-variance-authority"
import { X } from "lucide-react"
import { cn } from "@/lib/utils"
const ToastProvider = ToastPrimitives.Provider
const ToastViewport = React.forwardRef<
    React.ElementRef<typeof ToastPrimitives.Viewport>,
    React.ComponentPropsWithoutRef<typeof ToastPrimitives.Viewport>
>(({ className, ...props }, ref) => (
    <ToastPrimitives.Viewport
        ref={ref}
        className={cn(
            "fixed top-0 z-[100] flex max-h-screen w-full flex-col-reverse p-4 sm:bottom-0 sm:right-0 sm:top-auto sm:flex-col md:max-w-[420px]",
            className
        )}
        {...props}
    />
))
ToastViewport.displayName = ToastPrimitives.Viewport.displayName
const toastVariants = cva(
    "group pointer-events-auto relative flex w-full items-center justify-between space-x-4 overflow-hidden rounded-md border p-6 pr-8 shadow-lg transition-all data-[swipe=cancel]:translate-x-0 data-[swipe=end]:translate-x-[var(--radix-toast-swipe-end-x)] data-[swipe=move]:translate-x-[var(--radix-toast-swipe-move-x)] data-[swipe=move]:transition-none data-[state=open]:animate-in data-[state=closed]:animate-out data-[swipe=end]:animate-out data-[state=closed]:fade-out-80 data-[state=closed]:slide-out-to-right-full data-[state=open]:slide-in-from-top-full data-[state=open]:sm:slide-in-from-bottom-full",
    {
        variants: {
            variant: {
                default: "border bg-background text-foreground",
                destructive:
                    "destructive group border-destructive bg-destructive text-destructive-foreground",
            },
        },
        defaultVariants: {
            variant: "default",
        },
    }
)
const Toast = React.forwardRef<
    React.ElementRef<typeof ToastPrimitives.Root>,
    React.ComponentPropsWithoutRef<typeof ToastPrimitives.Root> &
    VariantProps<typeof toastVariants>
>(({ className, variant, ...props }, ref) => {
    return (
        <ToastPrimitives.Root
            ref={ref}
            className={cn(toastVariants({ variant }), className)}
            {...props}
        />
    )
})
Toast.displayName = ToastPrimitives.Root.displayName
const ToastAction = React.forwardRef<
    React.ElementRef<typeof ToastPrimitives.Action>,
    React.ComponentPropsWithoutRef<typeof ToastPrimitives.Action>
>(({ className, ...props }, ref) => (
    <ToastPrimitives.Action
        ref={ref}
        className={cn(
            "inline-flex h-8 shrink-0 items-center justify-center rounded-md border bg-transparent px-3 text-sm font-medium ring-offset-background transition-colors hover:bg-secondary focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 group-[.destructive]:border-muted/40 group-[.destructive]:hover:border-destructive/30 group-[.destructive]:hover:bg-destructive group-[.destructive]:hover:text-destructive-foreground group-[.destructive]:focus:ring-destructive",
            className
        )}
        {...props}
    />
))
ToastAction.displayName = ToastPrimitives.Action.displayName
const ToastClose = React.forwardRef<
    React.ElementRef<typeof ToastPrimitives.Close>,
    React.ComponentPropsWithoutRef<typeof ToastPrimitives.Close>
>(({ className, ...props }, ref) => (
    <ToastPrimitives.Close
        ref={ref}
        className={cn(
            "absolute right-2 top-2 rounded-md p-1 text-foreground/50 opacity-0 transition-opacity hover:text-foreground focus:opacity-100 focus:outline-none focus:ring-2 group-hover:opacity-100 group-[.destructive]:text-red-300 group-[.destructive]:hover:text-red-50 group-[.destructive]:focus:ring-red-400 group-[.destructive]:focus:ring-offset-red-600",
            className
        )}
        toast-close=""
        {...props}
    >
        <X className="h-4 w-4" />
    </ToastPrimitives.Close>
))
ToastClose.displayName = ToastPrimitives.Close.displayName
const ToastTitle = React.forwardRef<
    React.ElementRef<typeof ToastPrimitives.Title>,
    React.ComponentPropsWithoutRef<typeof ToastPrimitives.Title>
>(({ className, ...props }, ref) => (
    <ToastPrimitives.Title
        ref={ref}
        className={cn("text-sm font-semibold", className)}
        {...props}
    />
))
ToastTitle.displayName = ToastPrimitives.Title.displayName
const ToastDescription = React.forwardRef<
    React.ElementRef<typeof ToastPrimitives.Description>,
    React.ComponentPropsWithoutRef<typeof ToastPrimitives.Description>
>(({ className, ...props }, ref) => (
    <ToastPrimitives.Description
        ref={ref}
        className={cn("text-sm opacity-90", className)}
        {...props}
    />
))
ToastDescription.displayName = ToastPrimitives.Description.displayName
type ToastProps = React.ComponentPropsWithoutRef<typeof Toast>
type ToastActionElement = React.ReactElement<typeof ToastAction>
export {
    type ToastProps,
    type ToastActionElement,
    ToastProvider,
    ToastViewport,
    Toast,
    ToastTitle,
    ToastDescription,
    ToastClose,
    ToastAction,
}
</file>

<file path="src/components/ui/toaster.tsx">
"use client"
import {
    Toast,
    ToastClose,
    ToastDescription,
    ToastProvider,
    ToastTitle,
    ToastViewport,
} from "@/components/ui/toast"
import { useToast } from "@/components/ui/use-toast"
export function Toaster() {
    const { toasts } = useToast()
    return (
        <ToastProvider>
            {toasts.map(function ({ id, title, description, action, ...props }) {
                return (
                    <Toast key={id} {...props}>
                        <div className="grid gap-1">
                            {title && <ToastTitle>{title}</ToastTitle>}
                            {description && (
                                <ToastDescription>{description}</ToastDescription>
                            )}
                        </div>
                        {action}
                        <ToastClose />
                    </Toast>
                )
            })}
            <ToastViewport />
        </ToastProvider>
    )
}
</file>

<file path="src/components/ui/use-toast.ts">
"use client"
import * as React from "react"
import type { ToastActionElement, ToastProps } from "@/components/ui/toast"
const TOAST_LIMIT = 5
const TOAST_REMOVE_DELAY = 1000
type ToasterToast = ToastProps & {
    id: string
    title?: React.ReactNode
    description?: React.ReactNode
    action?: ToastActionElement
}
const actionTypes = {
    ADD_TOAST: "ADD_TOAST",
    UPDATE_TOAST: "UPDATE_TOAST",
    DISMISS_TOAST: "DISMISS_TOAST",
    REMOVE_TOAST: "REMOVE_TOAST",
} as const
let count = 0
function genId() {
    count = (count + 1) % Number.MAX_VALUE
    return count.toString()
}
type ActionType = typeof actionTypes
type Action =
    | {
        type: ActionType["ADD_TOAST"]
        toast: ToasterToast
    }
    | {
        type: ActionType["UPDATE_TOAST"]
        toast: Partial<ToasterToast>
    }
    | {
        type: ActionType["DISMISS_TOAST"]
        toastId?: string
    }
    | {
        type: ActionType["REMOVE_TOAST"]
        toastId?: string
    }
interface State {
    toasts: ToasterToast[]
}
const toastTimeouts = new Map<string, ReturnType<typeof setTimeout>>()
const reducer = (state: State, action: Action): State => {
    switch (action.type) {
        case actionTypes.ADD_TOAST:
            return {
                ...state,
                toasts: [action.toast, ...state.toasts].slice(0, TOAST_LIMIT),
            }
        case actionTypes.UPDATE_TOAST:
            return {
                ...state,
                toasts: state.toasts.map((t) =>
                    t.id === action.toast.id ? { ...t, ...action.toast } : t
                ),
            }
        case actionTypes.DISMISS_TOAST: {
            const { toastId } = action
            // ! Side effects should not be here, but this is a special case
            if (toastId) {
                if (toastTimeouts.has(toastId)) {
                    clearTimeout(toastTimeouts.get(toastId))
                    toastTimeouts.delete(toastId)
                }
            } else {
                for (const [id, timeout] of toastTimeouts.entries()) {
                    clearTimeout(timeout)
                    toastTimeouts.delete(id)
                }
            }
            return {
                ...state,
                toasts: state.toasts.map((t) =>
                    t.id === toastId || toastId === undefined
                        ? {
                            ...t,
                            open: false,
                        }
                        : t
                ),
            }
        }
        case actionTypes.REMOVE_TOAST:
            if (action.toastId === undefined) {
                return {
                    ...state,
                    toasts: [],
                }
            }
            return {
                ...state,
                toasts: state.toasts.filter((t) => t.id !== action.toastId),
            }
    }
}
const listeners: Array<(state: State) => void> = []
let memoryState: State = { toasts: [] }
function dispatch(action: Action) {
    memoryState = reducer(memoryState, action)
    listeners.forEach((listener) => {
        listener(memoryState)
    })
}
type Toast = Omit<ToasterToast, "id">
function toast({ ...props }: Toast) {
    const id = genId()
    const update = (props: ToasterToast) =>
        dispatch({
            type: actionTypes.UPDATE_TOAST,
            toast: { ...props, id },
        })
    const dismiss = () => dispatch({ type: actionTypes.DISMISS_TOAST, toastId: id })
    dispatch({
        type: actionTypes.ADD_TOAST,
        toast: {
            ...props,
            id,
            open: true,
            onOpenChange: (open) => {
                if (!open) dismiss()
            },
        },
    })
    return {
        id,
        dismiss,
        update,
    }
}
function useToast() {
    const [state, setState] = React.useState<State>(memoryState)
    React.useEffect(() => {
        listeners.push(setState)
        return () => {
            const index = listeners.indexOf(setState)
            if (index > -1) {
                listeners.splice(index, 1)
            }
        }
    }, [state])
    return {
        ...state,
        toast,
        dismiss: (toastId?: string) => dispatch({ type: actionTypes.DISMISS_TOAST, toastId }),
    }
}
export { useToast, toast }
</file>

<file path="src/components/ThemeProvider.tsx">
'use client';
import React, { useState, useEffect } from 'react';
import { ThemeContext, Theme } from '@/lib/theme';
export function ThemeProvider({ children }: { children: React.ReactNode }) {
    const [theme, setTheme] = useState<Theme>('light');
    useEffect(() => {
        // Check for saved theme preference
        const savedTheme = localStorage.getItem('theme') as Theme;
        if (savedTheme) {
            setTheme(savedTheme);
        } else {
            // Check system preference
            const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
            setTheme(prefersDark ? 'dark' : 'light');
        }
    }, []);
    useEffect(() => {
        // Update document class when theme changes
        document.documentElement.classList.remove('light', 'dark');
        document.documentElement.classList.add(theme);
        localStorage.setItem('theme', theme);
    }, [theme]);
    const toggleTheme = () => {
        setTheme(prev => prev === 'light' ? 'dark' : 'light');
    };
    return (
        <ThemeContext.Provider value={{ theme, toggleTheme }}>
            {children}
        </ThemeContext.Provider>
    );
}
</file>

<file path="src/components/ThemeToggle.tsx">
'use client';
import { useTheme } from '@/lib/theme';
import { Sun, Moon } from 'lucide-react';
import { Button } from './ui/button';
export function ThemeToggle() {
    const { theme, toggleTheme } = useTheme();
    return (
        <Button
            variant="ghost"
            size="icon"
            onClick={toggleTheme}
            title={`Switch to ${theme === 'light' ? 'dark' : 'light'} mode`}
        >
            {theme === 'light' ? (
                <Moon className="h-5 w-5" />
            ) : (
                <Sun className="h-5 w-5" />
            )}
        </Button>
    );
}
</file>

<file path="src/components/ThinkingIndicator.tsx">
"use client";
import React from 'react';
import { motion } from 'framer-motion';
interface ThinkingIndicatorProps {
    isThinking?: boolean;
    speakerName?: string;
    className?: string;
    duration?: number; // in milliseconds
}
/**
 * A component that displays an animated "thinking" indicator when an expert is generating a response
 */
export const ThinkingIndicator: React.FC<ThinkingIndicatorProps> = ({
    isThinking = false,
    speakerName = 'Expert',
    className = '',
    duration = 3000,
}) => {
    if (!isThinking) {
        return null;
    }
    return (
        <div className={`flex items-center ${className}`}>
            <div className="mr-2 text-sm text-gray-600 font-medium">
                {speakerName} is thinking
            </div>
            <motion.div
                className="flex space-x-1"
                initial={{ opacity: 0.5 }}
                animate={{ opacity: 1 }}
                transition={{ duration: 0.8, repeat: Infinity, repeatType: 'reverse' }}
            >
                <Dot delay={0} />
                <Dot delay={0.2} />
                <Dot delay={0.4} />
            </motion.div>
        </div>
    );
};
// Helper component for the animated dots
const Dot: React.FC<{ delay?: number }> = ({ delay = 0 }) => (
    <motion.div
        className="w-1.5 h-1.5 bg-gray-500 rounded-full"
        initial={{ y: 0 }}
        animate={{ y: [0, -5, 0] }}
        transition={{
            duration: 0.6,
            repeat: Infinity,
            repeatType: 'loop',
            delay,
            ease: 'easeInOut',
        }}
    />
);
export default ThinkingIndicator;
</file>

<file path="src/components/UserNavigation.tsx">
"use client";
import { useState } from 'react';
import { useSession, signIn, signOut } from 'next-auth/react';
import Link from 'next/link';
import { Button } from './ui/button';
import {
    User,
    LogOut,
    Settings,
    History,
    Heart,
    PlusCircle
} from 'lucide-react';
import { ThemeToggle } from './ThemeToggle';
import {
    DropdownMenu,
    DropdownMenuContent,
    DropdownMenuItem,
    DropdownMenuLabel,
    DropdownMenuSeparator,
    DropdownMenuTrigger,
} from '@/components/ui/dropdown-menu';
export function UserNavigation() {
    const { data: session, status } = useSession();
    const [isMenuOpen, setIsMenuOpen] = useState(false);
    return (
        <div className="flex items-center gap-4">
            <ThemeToggle />
            {status === 'loading' ? (
                <div className="h-9 w-9 rounded-full bg-gray-200 dark:bg-gray-700 animate-pulse" />
            ) : session ? (
                <DropdownMenu open={isMenuOpen} onOpenChange={setIsMenuOpen}>
                    <DropdownMenuTrigger asChild>
                        <Button
                            variant="ghost"
                            className="relative h-9 w-9 rounded-full"
                            aria-label="User menu"
                        >
                            {session.user?.image ? (
                                <img
                                    src={session.user.image}
                                    alt={session.user.name || 'User'}
                                    className="h-full w-full rounded-full object-cover"
                                />
                            ) : (
                                <User className="h-5 w-5" />
                            )}
                        </Button>
                    </DropdownMenuTrigger>
                    <DropdownMenuContent align="end" className="w-56">
                        <DropdownMenuLabel>
                            <div className="flex flex-col space-y-1">
                                <p className="text-sm font-medium">{session.user?.name}</p>
                                <p className="text-xs text-muted-foreground">{session.user?.email}</p>
                            </div>
                        </DropdownMenuLabel>
                        <DropdownMenuSeparator />
                        <DropdownMenuItem asChild>
                            <Link
                                href="/app/debate"
                                onClick={() => setIsMenuOpen(false)}
                                className="flex items-center gap-2 cursor-pointer"
                            >
                                <PlusCircle className="h-4 w-4" />
                                <span>New Debate</span>
                            </Link>
                        </DropdownMenuItem>
                        <DropdownMenuItem asChild>
                            <Link
                                href="/history"
                                onClick={() => setIsMenuOpen(false)}
                                className="flex items-center gap-2 cursor-pointer"
                            >
                                <History className="h-4 w-4" />
                                <span>Debate History</span>
                            </Link>
                        </DropdownMenuItem>
                        <DropdownMenuItem asChild>
                            <Link
                                href="/favorites"
                                onClick={() => setIsMenuOpen(false)}
                                className="flex items-center gap-2 cursor-pointer"
                            >
                                <Heart className="h-4 w-4" />
                                <span>Favorites</span>
                            </Link>
                        </DropdownMenuItem>
                        <DropdownMenuSeparator />
                        <DropdownMenuItem asChild>
                            <Link
                                href="/profile"
                                onClick={() => setIsMenuOpen(false)}
                                className="flex items-center gap-2 cursor-pointer"
                            >
                                <Settings className="h-4 w-4" />
                                <span>Profile Settings</span>
                            </Link>
                        </DropdownMenuItem>
                        <DropdownMenuSeparator />
                        <DropdownMenuItem
                            className="flex items-center gap-2 cursor-pointer"
                            onClick={() => {
                                setIsMenuOpen(false);
                                signOut({ callbackUrl: '/' });
                            }}
                        >
                            <LogOut className="h-4 w-4" />
                            <span>Sign Out</span>
                        </DropdownMenuItem>
                    </DropdownMenuContent>
                </DropdownMenu>
            ) : (
                <Button
                    variant="outline"
                    size="sm"
                    onClick={() => signIn()}
                >
                    Sign In
                </Button>
            )}
        </div>
    );
}
</file>

<file path="src/lib/agents/context-management.ts">
/**
 * Context Management Agent
 * 
 * This module manages the debate context across multiple turns,
 * providing memory, speaker tracking, and "thinking" simulation.
 */
import { Message, DebateContext, ExpertContext, TurnRecord } from '@/types/message';
import { Expert } from '@/types/expert';
import { createChatModel, agentConfig } from '../langchain-config';
import { HumanMessage, SystemMessage } from "@langchain/core/messages";
import { getDebateById, updateDebateContext as updateDebateContextInDB } from '@/lib/db/models/debate';
// In-memory store for context while the debate is active
const activeDebateContexts: Record<string, DebateContext> = {};
/**
 * Initialize a new debate context
 * 
 * @param debateId The ID of the debate
 * @param topic The debate topic
 * @returns The initialized context
 */
export async function initializeDebateContext(
    debateId: string,
    topic: string
): Promise<DebateContext> {
    console.log(`Initializing debate context for debate ${debateId} on topic "${topic}"`);
    // Create a new context
    const newContext: DebateContext = {
        debateId,
        expertContexts: {},
        mainPoints: [],
        userQuestions: [],
        turnHistory: [],
    };
    // Store in memory for quick access
    activeDebateContexts[debateId] = newContext;
    // Update in the database
    try {
        await updateDebateContextInDB(debateId, newContext);
        console.log(`Successfully initialized debate context for ${debateId}`);
    } catch (error) {
        console.error('Error saving debate context to database:', error);
    }
    return newContext;
}
/**
 * Update the debate context with a new message
 * 
 * @param message The new message to incorporate into the context
 * @returns Updated context
 */
export async function updateDebateContext(
    message: Message
): Promise<DebateContext> {
    const debateId = message.debateContext?.debateId;
    if (!debateId) {
        throw new Error('Message is missing debate context ID');
    }
    // Get the current context from memory or database
    let context = activeDebateContexts[debateId];
    if (!context) {
        // Try to load from database
        try {
            const debate = await getDebateById(debateId);
            context = debate?.context || { debateId, expertContexts: {}, mainPoints: [], userQuestions: [] };
            activeDebateContexts[debateId] = context;
        } catch (error) {
            console.error(`Error loading debate context for ${debateId}:`, error);
            context = { debateId, expertContexts: {}, mainPoints: [], userQuestions: [] };
            activeDebateContexts[debateId] = context;
        }
    }
    // Record the turn in history
    const turnRecord: TurnRecord = {
        speakerId: message.senderInfo?.id || 'unknown',
        timestamp: message.timestamp || new Date().toISOString(),
        messageId: message.id || 'unknown-message'
    };
    context.turnHistory = [...(context.turnHistory || []), turnRecord];
    // If this is a user message, extract questions
    if (message.role === 'user') {
        try {
            const questions = await extractQuestionsFromMessage(message.content);
            context.userQuestions = [...(context.userQuestions || []), ...questions];
        } catch (error) {
            console.error('Error extracting questions from user message:', error);
        }
    }
    // If this is an expert message, update their context
    if (message.role === 'assistant' && message.senderInfo?.type === 'expert') {
        const expertId = message.senderInfo.id;
        const expertName = message.senderInfo.name || 'Unknown Expert';
        // Create expert context if it doesn't exist
        if (!context.expertContexts) {
            context.expertContexts = {};
        }
        if (!context.expertContexts[expertName]) {
            context.expertContexts[expertName] = {
                expertId,
                keyPoints: [],
                recentArguments: []
            };
        }
        // Extract key points from the message
        try {
            const keyPoints = await extractKeyPointsFromMessage(message.content);
            context.expertContexts[expertName].keyPoints = [
                ...(context.expertContexts[expertName].keyPoints || []),
                ...keyPoints
            ].slice(-5); // Keep only the 5 most recent points
            // Add to recent arguments
            context.expertContexts[expertName].recentArguments = [
                ...(context.expertContexts[expertName].recentArguments || []),
                message.content
            ].slice(-2); // Keep only the 2 most recent arguments
        } catch (error) {
            console.error(`Error extracting key points for expert ${expertName}:`, error);
        }
    }
    // Extract main points for the overall debate
    try {
        const mainPoints = await extractMainPointsFromMessage(message.content);
        context.mainPoints = [...(context.mainPoints || []), ...mainPoints].slice(-10); // Keep last 10 main points
    } catch (error) {
        console.error('Error extracting main points from message:', error);
    }
    // Update the next speaker based on turn history
    context.nextSpeaker = determineNextSpeaker(context.turnHistory || []);
    // Update the context in memory and database
    activeDebateContexts[debateId] = context;
    try {
        await updateDebateContextInDB(debateId, context);
    } catch (error) {
        console.error('Error updating debate context in database:', error);
    }
    return context;
}
/**
 * Get a concise summary of the current debate context
 * 
 * @param debateId Optional debate ID to get context for
 * @returns A string summary of the debate context
 */
export async function getDebateContextSummary(debateId?: string): Promise<string> {
    // If no debate ID is specified, provide a generic summary
    if (!debateId) {
        return "The debate is ongoing. Consider the points raised so far and respond accordingly.";
    }
    // Get the context from memory or database
    let context = activeDebateContexts[debateId];
    if (!context) {
        try {
            const debate = await getDebateById(debateId);
            context = debate?.context;
            if (context) {
                activeDebateContexts[debateId] = context;
            }
        } catch (error) {
            console.error(`Error loading debate context for ${debateId}:`, error);
            return "Unable to retrieve debate context. Please respond based on the most recent messages.";
        }
    }
    // If still no context, return generic message
    if (!context) {
        return "The debate is just starting. Provide your opening perspective on the topic.";
    }
    // Format the main points
    const mainPointsList = (context.mainPoints || [])
        .slice(-5) // Only the 5 most recent main points
        .map(point => `- ${point}`)
        .join('\n');
    // Format the user questions
    const userQuestionsList = (context.userQuestions || [])
        .slice(-3) // Only the 3 most recent questions
        .map(question => `- ${question}`)
        .join('\n');
    // Create the summary
    const summary = `
Current Debate Context:
${mainPointsList ? `Main points raised:\n${mainPointsList}\n` : 'No main points have been established yet.'}
${userQuestionsList ? `Recent user questions:\n${userQuestionsList}\n` : 'No user questions have been asked yet.'}
${context.nextSpeaker ? `The next speaker should be: ${context.nextSpeaker}` : ''}
`.trim();
    return summary;
}
/**
 * Determine which expert should speak next based on turn history
 * 
 * @param turnHistory The history of turns in the debate
 * @returns The ID or name of the next speaker
 */
export function determineNextSpeaker(
    turnHistory: TurnRecord[] | Message[]
): string {
    // If no turn history, return empty string (any speaker can go first)
    if (!turnHistory || turnHistory.length === 0) {
        return '';
    }
    // For typed TurnRecord array
    if ('speakerId' in turnHistory[turnHistory.length - 1]) {
        const records = turnHistory as TurnRecord[];
        // Get unique speaker IDs excluding 'user'
        const expertIds = [...new Set(records
            .map(turn => turn.speakerId)
            .filter(id => id !== 'user')
        )];
        // If only one expert, they should speak after the user
        if (expertIds.length === 1) {
            const lastSpeakerId = records[records.length - 1].speakerId;
            return lastSpeakerId === 'user' ? expertIds[0] : 'user';
        }
        // If multiple experts, they should take turns
        if (expertIds.length > 1) {
            const lastSpeakerId = records[records.length - 1].speakerId;
            // If last speaker was user, first expert should speak
            if (lastSpeakerId === 'user') {
                return expertIds[0];
            }
            // If last speaker was an expert, find the next one
            const lastExpertIndex = expertIds.indexOf(lastSpeakerId);
            if (lastExpertIndex >= 0) {
                // Next expert in the list, or back to the first if we're at the end
                return expertIds[(lastExpertIndex + 1) % expertIds.length];
            }
            // Fallback
            return expertIds[0];
        }
    }
    // For Message array
    else if ('role' in turnHistory[turnHistory.length - 1]) {
        const messages = turnHistory as Message[];
        // Get unique expert names
        const expertNames = [...new Set(messages
            .filter(msg => msg.role === 'assistant' && msg.senderInfo?.type === 'expert')
            .map(msg => msg.senderInfo?.name || '')
            .filter(name => name.length > 0)
        )];
        // Simple alternating logic
        const lastMsg = messages[messages.length - 1];
        // If last message was from user, first expert should speak
        if (lastMsg.role === 'user') {
            return expertNames[0] || '';
        }
        // If last message was from an expert, find the next one
        if (lastMsg.role === 'assistant' && lastMsg.senderInfo?.type === 'expert') {
            const lastExpertName = lastMsg.senderInfo.name || '';
            const lastExpertIndex = expertNames.indexOf(lastExpertName);
            if (lastExpertIndex >= 0) {
                // Next expert in the list, or back to the first if we're at the end
                return expertNames[(lastExpertIndex + 1) % expertNames.length];
            }
        }
    }
    // Fallback
    return '';
}
/**
 * Simulate "thinking" by adding a delay before responding
 * 
 * @param minSeconds Minimum seconds to delay
 * @param maxSeconds Maximum seconds to delay
 * @returns A promise that resolves after the delay
 */
export async function simulateThinking(
    minSeconds: number = 2,
    maxSeconds: number = 5
): Promise<void> {
    // Calculate a random delay within the specified range
    const delayMs = Math.floor(Math.random() * (maxSeconds - minSeconds + 1) + minSeconds) * 1000;
    // Return a promise that resolves after the delay
    return new Promise(resolve => setTimeout(resolve, delayMs));
}
/**
 * Extract key points from a message
 * 
 * @param messageContent The content of the message
 * @returns Array of key points
 */
async function extractKeyPointsFromMessage(messageContent: string): Promise<string[]> {
    try {
        // Skip short messages
        if (messageContent.length < 50) {
            return [];
        }
        const model = createChatModel({
            temperature: 0.3,
            maxTokens: 300
        });
        const systemPrompt = `Extract the 2-3 most important key points from the following message.
Return each point as a concise sentence on a new line.
Focus on the core claims or arguments, not background details.
Do not add any commentary, numbering, or bullet points.`;
        const response = await model.call([
            new SystemMessage(systemPrompt),
            new HumanMessage(messageContent)
        ]);
        // Split by newlines and remove empty lines
        return (response.content as string)
            .split('\n')
            .map(line => line.trim())
            .filter(line => line.length > 0);
    } catch (error) {
        console.error('Error extracting key points:', error);
        return [];
    }
}
/**
 * Extract main points from a message
 * 
 * @param messageContent The content of the message
 * @returns Array of main points
 */
async function extractMainPointsFromMessage(messageContent: string): Promise<string[]> {
    // This could have more sophisticated logic to extract debate-level points
    // For now, we'll reuse the key points extraction logic
    return extractKeyPointsFromMessage(messageContent);
}
/**
 * Extract questions from a user message
 * 
 * @param messageContent The content of the user message
 * @returns Array of questions
 */
async function extractQuestionsFromMessage(messageContent: string): Promise<string[]> {
    try {
        const model = createChatModel({
            temperature: 0.2,
            maxTokens: 200
        });
        const systemPrompt = `Identify any explicit or implicit questions in the following user message.
For each question, extract or reformulate it as a clear, standalone question.
Return each question on a new line.
If there are no questions, return an empty response.`;
        const response = await model.call([
            new SystemMessage(systemPrompt),
            new HumanMessage(messageContent)
        ]);
        // Split by newlines and remove empty lines
        return (response.content as string)
            .split('\n')
            .map(line => line.trim())
            .filter(line => line.length > 0 && line.endsWith('?'));
    } catch (error) {
        console.error('Error extracting questions:', error);
        return [];
    }
}
</file>

<file path="src/lib/agents/fact-checking.ts">
/**
 * Fact Checking Agent
 * 
 * This module provides fact checking functionality for debate statements.
 * It uses LangChain to evaluate claims made during the debate.
 */
import { FactCheck, SourceReference } from '@/types/message';
import { createChatModel, agentConfig } from '../langchain-config';
import { HumanMessage, SystemMessage } from "@langchain/core/messages";
// In-memory cache for fact checks
const factCheckCache: Record<string, FactCheck> = {};
/**
 * Check the factual accuracy of a claim
 * 
 * @param claim The claim to check
 * @param topic The debate topic for context
 * @returns A fact check result
 */
export async function checkFactualAccuracy(
    claim: string,
    topic: string
): Promise<FactCheck> {
    // Create a cache key for this claim
    const cacheKey = `${claim.substring(0, 100)}`;
    // Return cached result if available
    if (factCheckCache[cacheKey]) {
        return factCheckCache[cacheKey];
    }
    console.log(`Checking factual accuracy of claim: "${claim.substring(0, 50)}..."`);
    try {
        // Create model for fact checking
        const model = createChatModel({
            temperature: 0.2, // Lower temperature for more factual evaluation
            maxTokens: 800
        });
        // Create the system prompt for fact checking
        const systemPrompt = `You are a fact-checking assistant evaluating claims made in a debate about "${topic}".
Your task is to assess the following claim for factual accuracy. Consider:
1. Is the claim objectively verifiable?
2. Is it supported by evidence and expert consensus?
3. Does it make reasonable interpretations of facts?
4. Does it include any logical fallacies or misleading statistics?
Provide your assessment of accuracy as one of the following:
- "true" (claim is factually accurate and fairly presented)
- "false" (claim is demonstrably incorrect)
- "partially true" (claim contains some truth but is missing context or has inaccuracies)
- "uncertain" (insufficient evidence to determine accuracy)
Format your response as JSON:
{
  "accuracy": "true|false|partially true|uncertain",
  "explanation": "Your detailed explanation of the assessment",
  "confidence": 0.XX, // your confidence in the assessment from 0 to 1
  "sources": [optional array of source references]
}`;
        // Get the response from the model
        const response = await model.call([
            new SystemMessage(systemPrompt),
            new HumanMessage(`Claim to fact-check: "${claim}"`)
        ]);
        // Parse the JSON response
        const content = response.content as string;
        const jsonMatch = content.match(/{[\s\S]*}/);
        let factCheck: FactCheck;
        if (jsonMatch) {
            try {
                factCheck = JSON.parse(jsonMatch[0]) as FactCheck;
            } catch (e) {
                // Fallback if JSON parsing fails
                factCheck = {
                    claim,
                    accuracy: 'uncertain',
                    explanation: 'Unable to assess due to technical issues',
                    confidence: 0.0
                };
            }
        } else {
            // Fallback if no JSON is found
            factCheck = {
                claim,
                accuracy: 'uncertain',
                explanation: 'Unable to extract a structured assessment',
                confidence: 0.0
            };
        }
        // Cache the result
        factCheckCache[cacheKey] = factCheck;
        return factCheck;
    } catch (error) {
        console.error('Error checking factual accuracy:', error);
        // Return a default fact check on error
        const defaultFactCheck: FactCheck = {
            claim,
            accuracy: 'uncertain',
            explanation: 'An error occurred during fact checking',
            confidence: 0.0
        };
        return defaultFactCheck;
    }
}
/**
 * Extract potential claims from a message that should be fact-checked
 * 
 * @param messageContent The message content to analyze
 * @param topic The debate topic
 * @returns Array of potential claims to check
 */
export async function extractClaimsToCheck(
    messageContent: string,
    topic: string
): Promise<string[]> {
    // Skip short messages
    if (messageContent.length < 50) {
        return [];
    }
    try {
        // Create model
        const model = createChatModel({
            temperature: 0.2,
            maxTokens: 500
        });
        // Create the system prompt
        const systemPrompt = `You are an assistant identifying factual claims within a debate message about "${topic}".
Analyze the following message and extract specific factual claims that should be fact-checked.
Focus on statements that:
1. Present specific statistics, numbers, or percentages
2. Make historical claims
3. Attribute opinions or actions to individuals or organizations
4. Present causal relationships
5. Make generalizations about groups
Return ONLY the claims, one per line, with no additional commentary.
Extract no more than 3 of the most important claims to verify.`;
        // Get response
        const response = await model.call([
            new SystemMessage(systemPrompt),
            new HumanMessage(messageContent)
        ]);
        // Split the response by lines and filter empty lines
        const claims = (response.content as string)
            .split('\n')
            .map(line => line.trim())
            .filter(line => line.length > 0);
        return claims;
    } catch (error) {
        console.error('Error extracting claims to check:', error);
        return [];
    }
}
</file>

<file path="src/lib/agents/index.ts">
/**
 * LangChain Agents Index
 * 
 * This file exports all the agent functionality for use in the application.
 */
import { retrieveBackgroundKnowledge } from './knowledge-retrieval';
import { checkFactualAccuracy } from './fact-checking';
import {
    initializeDebateContext,
    updateDebateContext,
    getDebateContextSummary,
    determineNextSpeaker,
    simulateThinking
} from './context-management';
// Export all agent functions
export {
    // Knowledge retrieval
    retrieveBackgroundKnowledge,
    // Fact checking
    checkFactualAccuracy,
    // Context management
    initializeDebateContext,
    updateDebateContext,
    getDebateContextSummary,
    determineNextSpeaker,
    simulateThinking
};
</file>

<file path="src/lib/agents/knowledge-retrieval.ts">
/**
 * Knowledge Retrieval Agent
 * 
 * This module provides background knowledge retrieval for experts.
 * It uses LangChain to gather relevant information about the expert's
 * domain and stance, improving response quality.
 */
import { Expert } from '@/types/expert';
import { SourceReference } from '@/types/message';
import { createChatModel, agentConfig } from '../langchain-config';
import { ChatOpenAI } from "@langchain/openai";
import { HumanMessage, SystemMessage } from "@langchain/core/messages";
// In-memory cache for knowledge retrieval
const knowledgeCache: Record<string, {
    data: string,
    timestamp: number,
    sources: SourceReference[]
}> = {};
/**
 * Retrieve background knowledge for an expert on a specific topic
 * 
 * @param expert The expert to retrieve knowledge for
 * @param topic The debate topic
 * @returns Background knowledge and sources
 */
export async function retrieveBackgroundKnowledge(
    expert: Expert,
    topic: string
): Promise<string> {
    // Create a cache key combining expert and topic
    const cacheKey = `${expert.id || expert.name}_${topic}`;
    // Check cache if enabled
    if (agentConfig.knowledgeRetrieval.useCache && knowledgeCache[cacheKey]) {
        const cached = knowledgeCache[cacheKey];
        const now = Date.now();
        const ttl = agentConfig.knowledgeRetrieval.cacheTTL * 1000;
        // Return cached knowledge if not expired
        if (now - cached.timestamp < ttl) {
            console.log(`Using cached knowledge for ${expert.name} on ${topic}`);
            return cached.data;
        }
    }
    console.log(`Retrieving background knowledge for ${expert.name} on ${topic}`);
    try {
        // Create model
        const model = createChatModel({
            temperature: 0.3, // Lower temperature for more factual responses
            maxTokens: 1000
        });
        // Create the system prompt for expert knowledge retrieval
        const expertiseStr = expert.expertise ? expert.expertise.join(", ") : "general knowledge";
        const systemPrompt = `You are a research assistant helping to compile background knowledge for ${expert.name}, 
who is a ${expert.stance} expert on the topic of "${topic}".
Their background is: ${expert.background}
Their areas of expertise include: ${expertiseStr}
Please provide factual, objective background knowledge that would be helpful for this expert to reference when 
discussing "${topic}" from a ${expert.stance} perspective. Include:
1. Key facts and statistics relevant to the topic
2. Commonly referenced studies or research
3. Important historical context
4. Major arguments typically made from the ${expert.stance} position
5. Key terminology and concepts
Format your response as a concise briefing document with clear sections. 
Focus on factual information that would strengthen the expert's position.
Do not include personal opinions or speculative claims.
Limit your response to 3-4 paragraphs.`;
        // Query the model
        const response = await model.call([
            new SystemMessage(systemPrompt),
            new HumanMessage(`I need background knowledge for ${expert.name} on the topic: ${topic}`)
        ]);
        // Extract the background knowledge
        const backgroundKnowledge = response.content as string;
        // Cache the result if caching is enabled
        if (agentConfig.knowledgeRetrieval.useCache) {
            knowledgeCache[cacheKey] = {
                data: backgroundKnowledge,
                timestamp: Date.now(),
                sources: [] // In a full implementation, we'd extract sources
            };
        }
        return backgroundKnowledge;
    } catch (error) {
        console.error('Error retrieving background knowledge:', error);
        return `Error retrieving background knowledge for ${expert.name}. Using default knowledge based on expertise in ${expert.expertise?.join(", ") || "general knowledge"}.`;
    }
}
/**
 * Extract source references from background knowledge
 * Note: In a real implementation, this would connect to a search API
 * 
 * @param backgroundKnowledge The background knowledge text
 * @param topic The debate topic
 * @returns Array of source references
 */
export async function extractSourceReferences(
    backgroundKnowledge: string,
    topic: string
): Promise<SourceReference[]> {
    // This is a simplified implementation
    // In production, we would use a real search API or knowledge base
    const model = createChatModel({
        temperature: 0.2,
        maxTokens: 500
    });
    const systemPrompt = `Based on the following background knowledge about "${topic}", 
identify and extract potential source references. For each source, provide:
- A likely title
- Potential author(s)
- Approximate publication date
- A short excerpt
- Relevance score (0-1)
Format as JSON array. Be realistic - only include sources that likely exist.`;
    try {
        const response = await model.call([
            new SystemMessage(systemPrompt),
            new HumanMessage(backgroundKnowledge)
        ]);
        // Parse the JSON response
        // The model should return a JSON array of sources
        const content = response.content as string;
        const jsonMatch = content.match(/\[[\s\S]*\]/);
        if (jsonMatch) {
            return JSON.parse(jsonMatch[0]) as SourceReference[];
        }
        return [];
    } catch (error) {
        console.error('Error extracting source references:', error);
        return [];
    }
}
</file>

<file path="src/lib/agents/README.md">
# LangChain Integration for Great Debate

This directory contains the enhanced debate functionality using LangChain. The goal is to provide more substantive, informed debates with better context management and fact-checking.

## Key Components

### 1. Knowledge Retrieval (knowledge-retrieval.ts)

Provides background knowledge for debate experts before they respond, making their arguments more substantive and accurate:

- Retrieves relevant facts, statistics, and research for each expert's stance
- Uses LangChain's structured prompts to get tailored information
- Operates asynchronously to avoid slowing down initial debate setup

### 2. Fact Checking (fact-checking.ts)

Verifies factual claims made during debates:

- Identifies potential factual claims using heuristics
- Assesses claim accuracy with a structured evaluation system
- Returns formatted results with accuracy ratings and explanations
- Runs in the background without blocking the main conversation flow

### 3. Context Management (context-management.ts)

Maintains debate flow and structure:

- Tracks conversation history with LangChain's memory components
- Manages turn-based debate structure
- Adds simulated "thinking" delays for a more natural feel
- Summarizes debate context for better continuity

## Integration with Debate API

The debate API route (/api/debate/route.ts) has been updated to use these components:

1. When a debate starts:
   - Experts are selected as before
   - Background knowledge retrieval is triggered asynchronously
   - Debate context is initialized

2. During response generation:
   - Context from previous messages is summarized
   - Background knowledge is incorporated into prompts
   - Simulated thinking is applied for more natural timing
   - Generated responses are fact-checked in the background

3. When user messages are added:
   - Message is stored and context is updated
   - The next speaker is determined based on turn-taking rules

## Future Improvements

- Storing fact-check results in the database and displaying them to users
- Integrating additional knowledge sources (e.g., web search)
- Adding bias detection and logical fallacy identification
- Implementing real-time notifications for when an expert is "thinking"

## Usage

The agents work automatically as part of the debate API. No manual intervention is needed beyond the initial setup.
</file>

<file path="src/lib/agents/test-integration.ts">
/**
 * LangChain Integration Test
 * 
 * This file contains test functions for verifying the LangChain integration.
 * It provides functions to test each agent module independently.
 */
import { Expert } from '@/types/expert';
import { Message } from '@/types/message';
import { retrieveBackgroundKnowledge } from './knowledge-retrieval';
import { checkFactualAccuracy, extractClaimsToCheck } from './fact-checking';
import {
    initializeDebateContext,
    updateDebateContext,
    getDebateContextSummary,
    simulateThinking
} from './context-management';
/**
 * Test types for running different integration tests
 */
export type TestType =
    | 'knowledge-retrieval'
    | 'fact-checking'
    | 'context-management'
    | 'all';
/**
 * Test options interface
 */
export interface TestOptions {
    topic?: string;
    testType?: TestType;
    verbose?: boolean;
}
/**
 * Test result interface
 */
export interface TestResult {
    success: boolean;
    message: string;
    data?: any;
    error?: Error;
}
/**
 * Run all integration tests
 * 
 * @param options Test options
 * @returns Test results
 */
export async function runIntegrationTests(options: TestOptions = {}): Promise<Record<string, TestResult>> {
    const results: Record<string, TestResult> = {};
    const testType = options.testType || 'all';
    const topic = options.topic || 'climate change';
    console.log(`Starting LangChain integration tests for topic: "${topic}"`);
    // Test knowledge retrieval
    if (testType === 'all' || testType === 'knowledge-retrieval') {
        results['knowledge-retrieval'] = await testKnowledgeRetrieval(topic, options.verbose);
    }
    // Test fact checking
    if (testType === 'all' || testType === 'fact-checking') {
        results['fact-checking'] = await testFactChecking(topic, options.verbose);
    }
    // Test context management
    if (testType === 'all' || testType === 'context-management') {
        results['context-management'] = await testContextManagement(topic, options.verbose);
    }
    return results;
}
/**
 * Test knowledge retrieval functionality
 * 
 * @param topic The topic to test with
 * @param verbose Whether to log detailed results
 * @returns Test result
 */
async function testKnowledgeRetrieval(topic: string, verbose = false): Promise<TestResult> {
    console.log(`Testing knowledge retrieval for topic: "${topic}"`);
    try {
        // Create test experts
        const proExpert: Expert = {
            name: "Dr. Alex Johnson",
            stance: "pro",
            background: "Climate scientist with 15 years experience in atmospheric research",
            expertise: ["Climate science", "Environmental policy", "Renewable energy"],
            id: "test-pro-expert"
        };
        const conExpert: Expert = {
            name: "Dr. Morgan Smith",
            stance: "con",
            background: "Economist specializing in energy markets and industry impacts",
            expertise: ["Economics", "Energy policy", "Industrial development"],
            id: "test-con-expert"
        };
        // Test pro expert knowledge retrieval
        const proKnowledge = await retrieveBackgroundKnowledge(proExpert, topic);
        if (verbose) {
            console.log(`\nPro Expert Knowledge:\n${proKnowledge}\n`);
        }
        // Test con expert knowledge retrieval
        const conKnowledge = await retrieveBackgroundKnowledge(conExpert, topic);
        if (verbose) {
            console.log(`\nCon Expert Knowledge:\n${conKnowledge}\n`);
        }
        // Validate results
        const isValid =
            typeof proKnowledge === 'string' &&
            proKnowledge.length > 100 &&
            typeof conKnowledge === 'string' &&
            conKnowledge.length > 100;
        return {
            success: isValid,
            message: isValid
                ? "Successfully retrieved background knowledge for experts"
                : "Failed to retrieve valid background knowledge",
            data: { proKnowledge, conKnowledge }
        };
    } catch (error) {
        console.error("Error in knowledge retrieval test:", error);
        return {
            success: false,
            message: "Knowledge retrieval test failed with an error",
            error: error instanceof Error ? error : new Error(String(error))
        };
    }
}
/**
 * Test fact checking functionality
 * 
 * @param topic The topic to test with
 * @param verbose Whether to log detailed results
 * @returns Test result
 */
async function testFactChecking(topic: string, verbose = false): Promise<TestResult> {
    console.log(`Testing fact checking for topic: "${topic}"`);
    try {
        // Create test claims
        const trueClaim = `The IPCC has stated that human activities are the dominant cause of observed warming since the mid-20th century.`;
        const falseClaim = `There has been no global warming measured in the last 30 years according to NASA data.`;
        const uncertainClaim = `Implementing carbon taxes will lead to 15% GDP growth within 5 years.`;
        // Check claims
        const trueResult = await checkFactualAccuracy(trueClaim, topic);
        const falseResult = await checkFactualAccuracy(falseClaim, topic);
        const uncertainResult = await checkFactualAccuracy(uncertainClaim, topic);
        if (verbose) {
            console.log('\nTrue Claim Check:', JSON.stringify(trueResult, null, 2));
            console.log('\nFalse Claim Check:', JSON.stringify(falseResult, null, 2));
            console.log('\nUncertain Claim Check:', JSON.stringify(uncertainResult, null, 2));
        }
        // Test claim extraction from a message
        const testMessage = `Climate change will cause sea levels to rise by 2 meters by 2100. 
The majority of scientists agree that we have only 10 years to act before irreversible damage. 
China produces more carbon emissions than any other country in history.`;
        const extractedClaims = await extractClaimsToCheck(testMessage, topic);
        if (verbose && extractedClaims.length > 0) {
            console.log('\nExtracted Claims:');
            extractedClaims.forEach((claim, i) => console.log(`${i + 1}. ${claim}`));
        }
        // Validate results
        const isValid =
            trueResult && trueResult.accuracy &&
            falseResult && falseResult.accuracy &&
            uncertainResult && uncertainResult.accuracy &&
            Array.isArray(extractedClaims) &&
            extractedClaims.length > 0;
        return {
            success: isValid,
            message: isValid
                ? "Successfully performed fact checking on test claims"
                : "Failed to properly fact check test claims",
            data: {
                trueResult,
                falseResult,
                uncertainResult,
                extractedClaims
            }
        };
    } catch (error) {
        console.error("Error in fact checking test:", error);
        return {
            success: false,
            message: "Fact checking test failed with an error",
            error: error instanceof Error ? error : new Error(String(error))
        };
    }
}
/**
 * Test context management functionality
 * 
 * @param topic The topic to test with
 * @param verbose Whether to log detailed results
 * @returns Test result
 */
async function testContextManagement(topic: string, verbose = false): Promise<TestResult> {
    console.log(`Testing context management for topic: "${topic}"`);
    try {
        // Create test debate ID
        const debateId = `test-debate-${Date.now()}`;
        // Initialize context
        const initialContext = await initializeDebateContext(debateId, topic);
        if (verbose) {
            console.log('\nInitial Context:', JSON.stringify(initialContext, null, 2));
        }
        // Create test messages
        const userMessage: Message = {
            id: 'msg1',
            role: 'user',
            content: `I'd like to understand more about the economic impacts of ${topic}. What about jobs and growth?`,
            timestamp: new Date().toISOString(),
            debateContext: { debateId }
        };
        const expertMessage: Message = {
            id: 'msg2',
            role: 'assistant',
            content: `When examining the economic dimensions of ${topic}, research from the International Labor Organization suggests significant job creation potential in renewable sectors. Studies show that investments in green infrastructure can generate more jobs per dollar than fossil fuel industries. However, regions dependent on traditional energy sectors may experience short-term economic challenges during the transition period. It's important to implement policies that support these communities through the shift.`,
            timestamp: new Date().toISOString(),
            senderInfo: {
                id: 'test-expert-1',
                name: 'Dr. Alex Johnson',
                type: 'expert'
            },
            debateContext: { debateId }
        };
        // Update context with messages
        await updateDebateContext(userMessage);
        await updateDebateContext(expertMessage);
        // Get context summary
        const summary = await getDebateContextSummary(debateId);
        if (verbose) {
            console.log('\nContext Summary:', summary);
        }
        // Test thinking simulation
        console.log('Testing thinking simulation (brief delay)...');
        await simulateThinking(1, 2);
        // Validate results
        const isValid =
            initialContext &&
            typeof summary === 'string' &&
            summary.length > 50;
        return {
            success: isValid,
            message: isValid
                ? "Successfully tested context management functionality"
                : "Failed to properly manage debate context",
            data: {
                debateId,
                summary
            }
        };
    } catch (error) {
        console.error("Error in context management test:", error);
        return {
            success: false,
            message: "Context management test failed with an error",
            error: error instanceof Error ? error : new Error(String(error))
        };
    }
}
</file>

<file path="src/lib/ai/document-processor.ts">
import { PineconeClient } from '@pinecone-database/pinecone';
import { OpenAIEmbeddings } from '@langchain/openai';
import { Document } from '@langchain/core/documents';
import * as pdfParse from 'pdf-parse';
import { v4 as uuidv4 } from 'uuid';
// Initialize Pinecone client
let pineconeClient: PineconeClient | null = null;
let pineconeIndex: any = null;
let embeddings: OpenAIEmbeddings | null = null;
// Initialize the Pinecone client
async function initPinecone() {
    if (!pineconeClient) {
        try {
            pineconeClient = new PineconeClient();
            await pineconeClient.init({
                apiKey: process.env.PINECONE_API_KEY || '',
                environment: process.env.PINECONE_ENVIRONMENT || '',
            });
            const indexName = process.env.PINECONE_INDEX || 'debate-documents';
            const indexList = await pineconeClient.listIndexes();
            if (!indexList.includes(indexName)) {
                console.warn(`Pinecone index ${indexName} does not exist. Please create it in the Pinecone console.`);
                return false;
            }
            pineconeIndex = pineconeClient.Index(indexName);
            // Initialize OpenAI embeddings with 1024 dimensions to match Pinecone
            embeddings = new OpenAIEmbeddings({
                openAIApiKey: process.env.OPENAI_API_KEY,
                dimensions: 1024, // Match Pinecone's available dimension option
            });
            return true;
        } catch (error) {
            console.error('Failed to initialize Pinecone:', error);
            return false;
        }
    }
    return true;
}
// Extract text from PDF buffer
async function extractTextFromPdf(pdfBuffer: Buffer): Promise<string> {
    try {
        const pdfData = await pdfParse(pdfBuffer);
        return pdfData.text;
    } catch (error) {
        console.error('Error extracting text from PDF:', error);
        throw new Error('Failed to extract text from PDF');
    }
}
// Custom text splitter function to replace LangChain's RecursiveCharacterTextSplitter
async function splitTextIntoChunks(text: string): Promise<Document[]> {
    // Split by paragraphs first
    const paragraphs = text.split(/\n\s*\n/);
    const chunks: Document[] = [];
    const chunkSize = 1000;
    const chunkOverlap = 200;
    for (const paragraph of paragraphs) {
        // If paragraph is smaller than chunk size, add it as is
        if (paragraph.length < chunkSize) {
            chunks.push(new Document({ pageContent: paragraph }));
            continue;
        }
        // Otherwise, split into overlapping chunks
        let startIndex = 0;
        while (startIndex < paragraph.length) {
            const endIndex = Math.min(startIndex + chunkSize, paragraph.length);
            const chunk = paragraph.substring(startIndex, endIndex);
            chunks.push(new Document({ pageContent: chunk }));
            // Move start index, accounting for overlap
            startIndex = endIndex - chunkOverlap;
            // If we're near the end, break to avoid tiny chunks
            if (startIndex + chunkSize >= paragraph.length) {
                break;
            }
        }
    }
    return chunks;
}
// Store document chunks in Pinecone
export async function processDocument(
    fileBuffer: Buffer,
    fileName: string,
    debateId: string
): Promise<{ success: boolean; chunkCount?: number; error?: string }> {
    try {
        // Initialize Pinecone
        const initialized = await initPinecone();
        if (!initialized || !pineconeIndex || !embeddings) {
            return {
                success: false,
                error: 'Vector database not initialized. Check your environment variables.'
            };
        }
        // Extract text from PDF
        const text = await extractTextFromPdf(fileBuffer);
        // Split text into chunks
        const chunks = await splitTextIntoChunks(text);
        // Create vectors with metadata
        const vectors = await Promise.all(
            chunks.map(async (chunk, i) => {
                const embedding = await embeddings!.embedQuery(chunk.pageContent);
                return {
                    id: `${debateId}_chunk_${i}`,
                    values: embedding,
                    metadata: {
                        debateId,
                        fileName,
                        text: chunk.pageContent,
                        chunkIndex: i,
                    },
                };
            })
        );
        // Upsert vectors to Pinecone
        await pineconeIndex.upsert({
            upsertRequest: {
                vectors,
                namespace: debateId,
            },
        });
        return {
            success: true,
            chunkCount: chunks.length,
        };
    } catch (error) {
        console.error('Error processing document:', error);
        return {
            success: false,
            error: error instanceof Error ? error.message : 'Unknown error processing document',
        };
    }
}
// Retrieve relevant content from Pinecone
export async function retrieveRelevantContent(
    query: string,
    debateId: string,
    topK: number = 5
): Promise<{ text: string; score: number }[]> {
    try {
        // Initialize Pinecone
        const initialized = await initPinecone();
        if (!initialized || !pineconeIndex || !embeddings) {
            console.error('Vector database not initialized');
            return [];
        }
        // Generate embedding for the query
        const queryEmbedding = await embeddings.embedQuery(query);
        // Query Pinecone
        const queryResponse = await pineconeIndex.query({
            queryRequest: {
                vector: queryEmbedding,
                topK,
                includeMetadata: true,
                namespace: debateId,
            },
        });
        // Extract and return relevant content
        return queryResponse.matches.map((match: any) => ({
            text: match.metadata.text,
            score: match.score,
        }));
    } catch (error) {
        console.error('Error retrieving content:', error);
        return [];
    }
}
// Mock implementation for development when Pinecone is not available
export class MockDocumentProcessor {
    private static storage: Record<string, any[]> = {};
    static async processDocument(
        fileBuffer: Buffer,
        fileName: string,
        debateId: string
    ): Promise<{ success: boolean; chunkCount?: number; error?: string }> {
        try {
            // Extract text from PDF
            const text = await extractTextFromPdf(fileBuffer);
            // Split text into chunks (simplified for mock)
            const chunks = text.split('\n\n').filter(chunk => chunk.trim().length > 0);
            // Store chunks with metadata
            MockDocumentProcessor.storage[debateId] = chunks.map((chunk, i) => ({
                id: `${debateId}_chunk_${i}`,
                text: chunk,
                metadata: {
                    debateId,
                    fileName,
                    chunkIndex: i,
                },
            }));
            return {
                success: true,
                chunkCount: chunks.length,
            };
        } catch (error) {
            console.error('Error in mock document processing:', error);
            return {
                success: false,
                error: error instanceof Error ? error.message : 'Unknown error in mock processing',
            };
        }
    }
    static async retrieveRelevantContent(
        query: string,
        debateId: string,
        topK: number = 5
    ): Promise<{ text: string; score: number }[]> {
        // Simple keyword matching for mock implementation
        const chunks = MockDocumentProcessor.storage[debateId] || [];
        const queryWords = query.toLowerCase().split(/\s+/);
        // Score chunks based on word overlap
        const scoredChunks = chunks.map(chunk => {
            const text = chunk.text.toLowerCase();
            const wordMatches = queryWords.filter(word => text.includes(word)).length;
            const score = wordMatches / queryWords.length;
            return {
                text: chunk.text,
                score: score,
            };
        });
        // Sort by score and return top K
        return scoredChunks
            .sort((a, b) => b.score - a.score)
            .slice(0, topK)
            .filter(chunk => chunk.score > 0);
    }
}
// Export the appropriate implementation based on environment
export const documentProcessor = process.env.USE_MOCK_DATA === 'true'
    ? MockDocumentProcessor
    : { processDocument, retrieveRelevantContent };
</file>

<file path="src/lib/ai/expert-selector.ts">
import { Expert } from '@/types/expert';
import { v4 as uuidv4 } from 'uuid';
import openai, { getModel } from './openai-client';
export async function selectExperts(
    topic: string,
    expertType: 'historical' | 'domain' = 'historical',
    count: number = 2
): Promise<Expert[]> {
    try {
        console.log(`Selecting ${count} ${expertType} experts for topic: ${topic}`);
        const response = await openai.chat.completions.create({
            model: getModel(),
            messages: [
                { role: 'system', content: getSystemPrompt(expertType) },
                { role: 'user', content: getUserPrompt(topic, expertType, count) }
            ],
            temperature: 0.7,
            response_format: { type: 'json_object' }
        });
        const content = response.choices[0]?.message?.content;
        if (!content) {
            throw new Error('No response from OpenAI');
        }
        try {
            const parsedResponse = JSON.parse(content);
            // Check if the response has an experts property (which should be an array)
            const expertsArray = parsedResponse.experts || parsedResponse;
            if (!Array.isArray(expertsArray)) {
                console.error('OpenAI response is not properly formatted:', parsedResponse);
                throw new Error('Invalid format: OpenAI response does not contain an experts array');
            }
            // Map the response to our Expert interface and ensure type is set correctly
            const experts = expertsArray.map(expert => ({
                id: uuidv4(),
                name: expert.name || 'Unknown Expert',
                background: expert.background || (expert.bio || ''),
                stance: expert.stance || 'pro',
                perspective: expert.perspective || '',
                type: expertType, // Explicitly set the type based on what was selected
                expertise: Array.isArray(expert.expertise) ? expert.expertise :
                    (expert.expertise ? [expert.expertise] : []),
            }));
            console.log(`Successfully selected ${experts.length} ${expertType} experts`);
            return experts;
        } catch (error) {
            console.error('Error parsing OpenAI response:', content, error);
            throw new Error('Failed to parse OpenAI response');
        }
    } catch (error) {
        console.error('Error selecting experts:', error);
        throw error;
    }
}
function getSystemPrompt(expertType: 'historical' | 'domain'): string {
    return `You are an expert debate coordinator. Your task is to select 2 ${expertType === 'historical' ? 'historical figures' : 'domain experts'} who would have interesting and contrasting perspectives on a given topic.
Return a JSON object with an "experts" array containing objects with these fields:
1. name: Full name ${expertType === 'domain' ? 'with relevant title (Dr., Prof., etc.)' : 'of the historical figure'}
2. background: Brief description of ${expertType === 'historical' ? 'who they were' : 'their field and credentials'} (1-2 sentences)
3. stance: One expert should be 'pro' and one should be 'con' regarding the topic
4. perspective: ${expertType === 'historical' ? 'How they would approach this topic based on their historical context' : 'Their approach to this topic based on their expertise'} (2-3 sentences)
5. expertise: An array of 2-4 short phrases describing their ${expertType === 'historical' ? 'areas of expertise or knowledge domains' : 'specific areas of expertise or specializations'}
Format your response as a valid JSON object with an "experts" array containing these expert objects.`;
}
function getUserPrompt(topic: string, expertType: 'historical' | 'domain', count: number): string {
    return `Select ${count} ${expertType === 'historical' ? 'historical figures' : 'domain experts'} who would have the most interesting and contrasting perspectives on the topic: "${topic}".
Ensure you select experts with opposing viewpoints - one should be generally "pro" and one should be generally "con" on this topic.
Make sure each expert has:
- A name
- A background description
- A clear stance (one pro, one con)
- A detailed perspective on the topic
- An array of expertise areas (2-4 specific domains)
Return only a JSON object with an "experts" array.`;
}
</file>

<file path="src/lib/ai/openai-client.ts">
import OpenAI from 'openai';
// Initialize a single OpenAI client instance to be shared across the application
const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
});
// Validate the API key and log information about the configuration
function validateApiKey(): boolean {
    if (!process.env.OPENAI_API_KEY) {
        console.error("OpenAI API key is missing");
        return false;
    }
    // Log the API key format (first few chars) for debugging
    const keyFormat = process.env.OPENAI_API_KEY.substring(0, 7) + "...";
    console.log(`OpenAI API key format: ${keyFormat}`);
    // Log the model being used
    const model = process.env.OPENAI_MODEL || "gpt-4-turbo";
    console.log(`Using OpenAI model: ${model}`);
    // Warn if using project-based OpenAI API key
    if (process.env.OPENAI_API_KEY.startsWith('sk-proj-')) {
        console.warn("WARNING: Using a project-based API key (sk-proj-...). If you encounter authentication issues, you may need to use a standard API key (sk-...) instead.");
    }
    return true;
}
// Helper function to calculate cost based on token usage
export function calculateCost(tokens: number): number {
    // GPT-4 Turbo pricing: $0.01 per 1K input tokens, $0.03 per 1K output tokens
    // This is a simplified calculation
    const costPer1KTokens = 0.02; // Average cost
    return (tokens / 1000) * costPer1KTokens;
}
// Get the preferred model to use
export function getModel(): string {
    return process.env.OPENAI_MODEL || "gpt-4-turbo";
}
// Validate the API key when this module is imported
validateApiKey();
// Export the shared OpenAI client
export default openai;
</file>

<file path="src/lib/ai/response-generator.ts">
import { Expert } from '@/types/expert';
import { Message } from '@/types/message';
import openai, { calculateCost, getModel } from './openai-client';
import { documentProcessor } from './document-processor';
export async function generateResponse(
    expert: Expert,
    topic: string,
    messages: Message[],
    useCitations: boolean = true,
    debateId?: string
): Promise<{ response: string; usage: any }> {
    try {
        const lastUserMessage = messages
            .filter(m => m.role === 'user')
            .pop();
        let relevantContent: string = '';
        if (debateId && lastUserMessage) {
            try {
                const results = await documentProcessor.retrieveRelevantContent(
                    lastUserMessage.content,
                    debateId
                );
                if (results.length > 0) {
                    relevantContent = results
                        .map((result, index) => `[${index + 1}] ${result.text.trim()} (relevance: ${Math.round(result.score * 100)}%)`)
                        .join('\n\n');
                }
            } catch (error) {
                console.error('Error retrieving relevant content:', error);
            }
        }
        const systemPrompt = getSystemPrompt(expert, topic, useCitations, relevantContent);
        const formattedMessages = formatMessagesForAPI(messages);
        const response = await openai.chat.completions.create({
            model: getModel(),
            messages: [
                { role: 'system', content: systemPrompt },
                ...formattedMessages
            ],
            temperature: 0.7,
            max_tokens: 1000
        });
        const content = response.choices[0]?.message?.content;
        if (!content) {
            throw new Error('No response from OpenAI');
        }
        const usage = {
            promptTokens: response.usage?.prompt_tokens || 0,
            completionTokens: response.usage?.completion_tokens || 0,
            totalTokens: response.usage?.total_tokens || 0,
            cost: calculateCost(response.usage?.total_tokens || 0)
        };
        return { response: content, usage };
    } catch (error) {
        console.error('Error generating response:', error);
        throw error;
    }
}
function getSystemPrompt(
    expert: Expert,
    topic: string,
    useCitations: boolean,
    relevantContent?: string
): string {
    let prompt = `You are ${expert.name}, ${expert.title}`;
    if ('era' in expert) {
        prompt += ` from ${expert.era}`;
    } else if ('field' in expert) {
        prompt += `, an expert in ${expert.field}`;
    }
    prompt += `. ${expert.bio}
  You are participating in a debate on the topic: "${topic}"
  Your perspective on this topic is: ${expert.perspective}
  Respond in the first person as if you are ${expert.name}. Use language, references, and examples that would be authentic to your character and time period. Keep your responses concise (3-5 sentences) but insightful.`;
    if (relevantContent) {
        prompt += `
  RELEVANT DOCUMENT CONTENT:
  ${relevantContent}
  When answering, use the provided document content to inform your response. Cite specific information from the document when possible. If the document content is relevant to the question, prioritize using that information over general knowledge.`;
    }
    if (useCitations && expert.sourceReferences) {
        prompt += `
    When appropriate, cite sources using the format [Citation: X] where X is a number. For example: "The data shows a clear trend [Citation: 1]."
    You have access to the following sources:
    ${expert.sourceReferences.map((ref, i) => `${i + 1}. ${ref.title} - ${ref.author || 'Unknown'} (${ref.year || 'Unknown'})`).join('\n')}`;
    }
    return prompt;
}
function formatMessagesForAPI(messages: Message[]): { role: string; content: string }[] {
    return messages.map(message => ({
        role: message.role === 'user' ? 'user' : 'assistant',
        content: message.role === 'assistant'
            ? `${message.speaker}: ${message.content}`
            : message.content
    }));
}
</file>

<file path="src/lib/content-processing/document-parser.ts">
import { readFile } from 'fs/promises';
import pdfParse from 'pdf-parse';
import mammoth from 'mammoth';
import {
    DocumentMetadata,
    DocumentParserOptions,
    DocumentParserResult,
    ParsedDocument,
    SupportedDocumentType,
} from '@/types/content-processing';
const DEFAULT_OPTIONS: DocumentParserOptions = {
    extractSections: true,
    maxSizeInMB: 10,
    preserveFormatting: true,
};
export class DocumentParser {
    private options: DocumentParserOptions;
    constructor(options: Partial<DocumentParserOptions> = {}) {
        this.options = { ...DEFAULT_OPTIONS, ...options };
    }
    async parseFile(filePath: string): Promise<DocumentParserResult> {
        try {
            const fileBuffer = await readFile(filePath);
            const fileType = this.getFileType(filePath);
            if (!this.validateFile(fileBuffer, fileType)) {
                return {
                    success: false,
                    error: 'File validation failed: File too large or unsupported type',
                };
            }
            const metadata = await this.extractMetadata(filePath, fileBuffer, fileType);
            const parsedContent = await this.parseContent(fileBuffer, fileType);
            const parsedDocument: ParsedDocument = {
                metadata,
                content: parsedContent.content,
                rawText: parsedContent.rawText,
                sections: parsedContent.sections,
            };
            return {
                success: true,
                parsedDocument,
            };
        } catch (error) {
            return {
                success: false,
                error: `Failed to parse document: ${error.message}`,
            };
        }
    }
    private getFileType(filePath: string): SupportedDocumentType {
        const extension = filePath.split('.').pop()?.toLowerCase();
        switch (extension) {
            case 'pdf':
                return 'pdf';
            case 'docx':
                return 'docx';
            case 'txt':
                return 'txt';
            default:
                throw new Error(`Unsupported file type: ${extension}`);
        }
    }
    private validateFile(buffer: Buffer, fileType: SupportedDocumentType): boolean {
        const fileSizeInMB = buffer.length / (1024 * 1024);
        return fileSizeInMB <= (this.options.maxSizeInMB || DEFAULT_OPTIONS.maxSizeInMB!);
    }
    private async extractMetadata(
        filePath: string,
        buffer: Buffer,
        fileType: SupportedDocumentType
    ): Promise<DocumentMetadata> {
        const stats = await readFile(filePath).then(buffer => ({
            size: buffer.length,
            // In a real implementation, we'd use proper file stats
            createdAt: new Date(),
            lastModified: new Date(),
        }));
        const metadata: DocumentMetadata = {
            fileName: filePath.split('/').pop() || '',
            fileType,
            fileSize: stats.size,
            createdAt: stats.createdAt,
            lastModified: stats.lastModified,
        };
        if (fileType === 'pdf') {
            const pdfData = await pdfParse(buffer);
            metadata.pageCount = pdfData.numpages;
        }
        return metadata;
    }
    private async parseContent(
        buffer: Buffer,
        fileType: SupportedDocumentType
    ): Promise<Omit<ParsedDocument, 'metadata'>> {
        switch (fileType) {
            case 'pdf':
                return this.parsePDF(buffer);
            case 'docx':
                return this.parseDocx(buffer);
            case 'txt':
                return this.parseTxt(buffer);
            default:
                throw new Error(`Unsupported file type: ${fileType}`);
        }
    }
    private async parsePDF(buffer: Buffer) {
        const pdfData = await pdfParse(buffer);
        const content = pdfData.text;
        let sections = [];
        if (this.options.extractSections) {
            // Basic section extraction based on line breaks and potential headers
            sections = content
                .split(/\n\s*\n/)
                .filter(section => section.trim().length > 0)
                .map((section, index) => ({
                    content: section.trim(),
                    pageNumber: Math.floor(index / 3) + 1, // Rough estimation
                }));
        }
        return {
            content: this.options.preserveFormatting ? content : content.replace(/\s+/g, ' ').trim(),
            rawText: content,
            sections,
        };
    }
    private async parseDocx(buffer: Buffer) {
        const result = await mammoth.extractRawText({ buffer });
        const content = result.value;
        let sections = [];
        if (this.options.extractSections) {
            // Extract sections based on headings or double line breaks
            sections = content
                .split(/\n\s*\n/)
                .filter(section => section.trim().length > 0)
                .map(section => ({
                    content: section.trim(),
                }));
        }
        return {
            content: this.options.preserveFormatting ? content : content.replace(/\s+/g, ' ').trim(),
            rawText: content,
            sections,
        };
    }
    private parseTxt(buffer: Buffer) {
        const content = buffer.toString('utf-8');
        let sections = [];
        if (this.options.extractSections) {
            // Simple section extraction based on double line breaks
            sections = content
                .split(/\n\s*\n/)
                .filter(section => section.trim().length > 0)
                .map(section => ({
                    content: section.trim(),
                }));
        }
        return {
            content: this.options.preserveFormatting ? content : content.replace(/\s+/g, ' ').trim(),
            rawText: content,
            sections,
        };
    }
}
</file>

<file path="src/lib/content-processing/index.ts">
export * from './document-parser';
export * from './topic-extractor';
export * from './media-processor';
// Re-export types
export * from '@/types/content-processing';
</file>

<file path="src/lib/content-processing/media-processor.ts">
import youtubeDl from 'youtube-dl-exec';
import ffmpeg from 'fluent-ffmpeg';
import fetch from 'node-fetch';
import { TopicExtractor } from './topic-extractor';
import {
    MediaType,
    MediaMetadata,
    TranscriptSegment,
    KeyPoint,
    ProcessedMedia,
    MediaProcessorOptions,
} from '@/types/content-processing';
const DEFAULT_OPTIONS: MediaProcessorOptions = {
    downloadMedia: true,
    extractAudio: true,
    generateTranscript: true,
    maxDuration: 3600, // 1 hour
    language: 'en',
};
export class MediaProcessor {
    private options: MediaProcessorOptions;
    private topicExtractor: TopicExtractor;
    constructor(options: Partial<MediaProcessorOptions> = {}) {
        this.options = { ...DEFAULT_OPTIONS, ...options };
        this.topicExtractor = new TopicExtractor();
    }
    async processMedia(url: string, type: MediaType): Promise<ProcessedMedia> {
        try {
            // Validate URL and media type
            if (!this.isValidUrl(url)) {
                throw new Error('Invalid URL provided');
            }
            // Get media metadata
            const metadata = await this.getMediaMetadata(url, type);
            // Check duration limit
            if (metadata.duration > this.options.maxDuration) {
                throw new Error('Media duration exceeds maximum allowed length');
            }
            // Process based on media type
            let transcript: TranscriptSegment[] = [];
            if (this.options.generateTranscript) {
                transcript = await this.generateTranscript(url, type);
            }
            // Extract key points from transcript
            const keyPoints = await this.extractKeyPoints(transcript);
            return {
                metadata,
                transcript,
                keyPoints,
            };
        } catch (error) {
            return {
                metadata: {
                    title: '',
                    duration: 0,
                    format: '',
                    url,
                },
                transcript: [],
                keyPoints: [],
                error: `Failed to process media: ${error.message}`,
            };
        }
    }
    private isValidUrl(url: string): boolean {
        try {
            new URL(url);
            return true;
        } catch {
            return false;
        }
    }
    private async getMediaMetadata(url: string, type: MediaType): Promise<MediaMetadata> {
        switch (type) {
            case 'youtube':
                return this.getYouTubeMetadata(url);
            case 'podcast':
                return this.getPodcastMetadata(url);
            default:
                return this.getGenericMediaMetadata(url);
        }
    }
    private async getYouTubeMetadata(url: string): Promise<MediaMetadata> {
        const info = await youtubeDl(url, {
            dumpSingleJson: true,
            noWarnings: true,
            noCallHome: true,
            noCheckCertificate: true,
            preferFreeFormats: true,
            youtubeSkipDashManifest: true,
        });
        return {
            title: info.title,
            description: info.description,
            duration: info.duration,
            format: 'youtube',
            url: info.webpage_url,
            thumbnailUrl: info.thumbnail,
            author: info.uploader,
            publishDate: new Date(info.upload_date),
        };
    }
    private async getPodcastMetadata(url: string): Promise<MediaMetadata> {
        // Implement podcast metadata extraction
        // This would typically involve parsing RSS feeds or podcast-specific APIs
        throw new Error('Podcast metadata extraction not implemented');
    }
    private async getGenericMediaMetadata(url: string): Promise<MediaMetadata> {
        // Basic metadata for generic media files
        const response = await fetch(url, { method: 'HEAD' });
        const contentType = response.headers.get('content-type') || '';
        const contentLength = response.headers.get('content-length') || '0';
        return {
            title: url.split('/').pop() || '',
            duration: 0, // Would need media processing to determine duration
            format: contentType,
            url,
        };
    }
    private async generateTranscript(
        url: string,
        type: MediaType
    ): Promise<TranscriptSegment[]> {
        switch (type) {
            case 'youtube':
                return this.generateYouTubeTranscript(url);
            case 'podcast':
                return this.generatePodcastTranscript(url);
            default:
                return this.generateGenericTranscript(url);
        }
    }
    private async generateYouTubeTranscript(url: string): Promise<TranscriptSegment[]> {
        // First try to get existing captions
        try {
            const info = await youtubeDl(url, {
                skipDownload: true,
                writeAutoSub: true,
                subLang: this.options.language,
            });
            if (info.subtitles?.[this.options.language]) {
                return this.parseYouTubeSubtitles(info.subtitles[this.options.language][0].url);
            }
        } catch (error) {
            console.warn('Failed to get YouTube subtitles:', error);
        }
        // If no captions available, download audio and transcribe
        if (this.options.downloadMedia && this.options.extractAudio) {
            return this.transcribeAudio(url);
        }
        return [];
    }
    private async generatePodcastTranscript(url: string): Promise<TranscriptSegment[]> {
        if (this.options.downloadMedia && this.options.extractAudio) {
            return this.transcribeAudio(url);
        }
        return [];
    }
    private async generateGenericTranscript(url: string): Promise<TranscriptSegment[]> {
        if (this.options.downloadMedia && this.options.extractAudio) {
            return this.transcribeAudio(url);
        }
        return [];
    }
    private async parseYouTubeSubtitles(subtitleUrl: string): Promise<TranscriptSegment[]> {
        const response = await fetch(subtitleUrl);
        const subtitles = await response.text();
        // Parse the subtitle format (typically WebVTT or SRT)
        // This is a simplified parser
        return subtitles
            .split('\n\n')
            .filter(segment => segment.trim())
            .map(segment => {
                const lines = segment.split('\n');
                const timeMatch = lines[1]?.match(/(\d{2}:\d{2}:\d{2}.\d{3}) --> (\d{2}:\d{2}:\d{2}.\d{3})/);
                if (!timeMatch) return null;
                return {
                    text: lines.slice(2).join(' ').trim(),
                    start: this.timeToSeconds(timeMatch[1]),
                    end: this.timeToSeconds(timeMatch[2]),
                    confidence: 0.9, // Assuming high confidence for official subtitles
                };
            })
            .filter((segment): segment is TranscriptSegment => segment !== null);
    }
    private async transcribeAudio(url: string): Promise<TranscriptSegment[]> {
        // Download audio
        const audioPath = await this.downloadAndExtractAudio(url);
        // Here you would integrate with a speech-to-text service
        // For example, using Whisper API or another service
        throw new Error('Audio transcription not implemented');
    }
    private async downloadAndExtractAudio(url: string): Promise<string> {
        const outputPath = `/tmp/${Date.now()}.mp3`;
        return new Promise((resolve, reject) => {
            ffmpeg()
                .input(url)
                .toFormat('mp3')
                .on('end', () => resolve(outputPath))
                .on('error', (err) => reject(err))
                .save(outputPath);
        });
    }
    private async extractKeyPoints(transcript: TranscriptSegment[]): Promise<KeyPoint[]> {
        const keyPoints: KeyPoint[] = [];
        const transcriptText = transcript.map(segment => segment.text).join(' ');
        // Use TopicExtractor to identify important points
        const topics = await this.topicExtractor.extractTopics({
            content: transcriptText,
            rawText: transcriptText,
        });
        // Convert topics to key points with timestamps
        for (const topic of topics.topics) {
            const relevantSegment = transcript.find(segment =>
                segment.text.includes(topic.title)
            );
            if (relevantSegment) {
                keyPoints.push({
                    text: topic.title,
                    timestamp: relevantSegment.start,
                    confidence: topic.confidence,
                    topics: topic.keywords,
                });
            }
        }
        return keyPoints.sort((a, b) => a.timestamp - b.timestamp);
    }
    private timeToSeconds(timeStr: string): number {
        const [hours, minutes, seconds] = timeStr.split(':').map(Number);
        return hours * 3600 + minutes * 60 + seconds;
    }
}
</file>

<file path="src/lib/content-processing/topic-extractor.ts">
import natural from 'natural';
import nlp from 'compromise';
import * as use from '@tensorflow-models/universal-sentence-encoder';
import * as tf from '@tensorflow/tfjs-node';
import {
    Topic,
    Argument,
    TopicExtractionResult,
    TopicExtractorOptions,
    ParsedDocument,
} from '@/types/content-processing';
const DEFAULT_OPTIONS: TopicExtractorOptions = {
    minConfidence: 0.6,
    maxTopics: 5,
    extractCounterpoints: true,
    language: 'english',
};
export class TopicExtractor {
    private options: TopicExtractorOptions;
    private tokenizer: natural.WordTokenizer;
    private tfidf: natural.TfIdf;
    private sentenceEncoder: any; // Universal Sentence Encoder model
    constructor(options: Partial<TopicExtractorOptions> = {}) {
        this.options = { ...DEFAULT_OPTIONS, ...options };
        this.tokenizer = new natural.WordTokenizer();
        this.tfidf = new natural.TfIdf();
        this.initializeSentenceEncoder();
    }
    private async initializeSentenceEncoder() {
        this.sentenceEncoder = await use.load();
    }
    async extractTopics(document: ParsedDocument): Promise<TopicExtractionResult> {
        try {
            // Wait for the sentence encoder to be ready
            if (!this.sentenceEncoder) {
                await this.initializeSentenceEncoder();
            }
            // Extract topics and arguments
            const topics = await this.identifyTopics(document);
            const mainArguments = await this.extractArguments(document, topics);
            return {
                success: true,
                topics,
                mainArguments,
            };
        } catch (error) {
            return {
                success: false,
                topics: [],
                mainArguments: [],
                error: `Failed to extract topics: ${error.message}`,
            };
        }
    }
    private async identifyTopics(document: ParsedDocument): Promise<Topic[]> {
        const sections = document.sections || [{ content: document.content }];
        const topics: Topic[] = [];
        // Process each section to identify potential topics
        for (const section of sections) {
            const sectionText = section.content;
            // Use compromise to identify potential topic phrases
            const doc = nlp(sectionText);
            const nouns = doc.nouns().out('array');
            const verbs = doc.verbs().out('array');
            // Add section text to TF-IDF for keyword extraction
            this.tfidf.addDocument(sectionText);
            // Get keywords using TF-IDF
            const keywords = this.extractKeywords(sectionText);
            // Use sentence encoder to get semantic embeddings
            const sentences = this.splitIntoSentences(sectionText);
            const embeddings = await this.getEmbeddings(sentences);
            // Cluster similar sentences and identify main topics
            const topicClusters = this.clusterSentences(sentences, embeddings);
            for (const cluster of topicClusters) {
                if (topics.length >= this.options.maxTopics) break;
                const topicTitle = this.generateTopicTitle(cluster, keywords);
                const confidence = this.calculateConfidence(cluster, embeddings);
                if (confidence >= this.options.minConfidence) {
                    topics.push({
                        title: topicTitle,
                        confidence,
                        keywords: keywords.slice(0, 5),
                        summary: this.generateSummary(cluster),
                        relatedTopics: this.findRelatedTopics(topicTitle, topics),
                        sourceSection: {
                            content: sectionText,
                            position: sections.indexOf(section),
                        },
                    });
                }
            }
        }
        return topics.slice(0, this.options.maxTopics);
    }
    private async extractArguments(
        document: ParsedDocument,
        topics: Topic[]
    ): Promise<Argument[]> {
        const arguments: Argument[] = [];
        const sections = document.sections || [{ content: document.content }];
        for (const topic of topics) {
            const relevantSections = sections.filter(section =>
                this.isContentRelatedToTopic(section.content, topic)
            );
            for (const section of relevantSections) {
                const sentences = this.splitIntoSentences(section.content);
                const claims = await this.identifyClaims(sentences, topic);
                for (const claim of claims) {
                    const evidence = await this.findEvidence(sentences, claim);
                    const counterpoints = this.options.extractCounterpoints
                        ? await this.findCounterpoints(sentences, claim)
                        : undefined;
                    if (evidence.length > 0) {
                        arguments.push({
                            claim,
                            confidence: await this.calculateClaimConfidence(claim, evidence),
                            evidence,
                            counterpoints,
                            sourceSection: {
                                content: section.content,
                                position: sections.indexOf(section),
                            },
                        });
                    }
                }
            }
        }
        return arguments;
    }
    private extractKeywords(text: string): string[] {
        const tokens = this.tokenizer.tokenize(text);
        const tfidf = new natural.TfIdf();
        tfidf.addDocument(tokens);
        const keywords: { term: string; score: number }[] = [];
        tfidf.listTerms(0).forEach(item => {
            keywords.push({ term: item.term, score: item.tfidf });
        });
        return keywords
            .sort((a, b) => b.score - a.score)
            .map(k => k.term)
            .slice(0, 10);
    }
    private splitIntoSentences(text: string): string[] {
        const tokenizer = new natural.SentenceTokenizer();
        return tokenizer.tokenize(text);
    }
    private async getEmbeddings(sentences: string[]): Promise<tf.Tensor2D> {
        return await this.sentenceEncoder.embed(sentences);
    }
    private clusterSentences(
        sentences: string[],
        embeddings: tf.Tensor2D
    ): string[][] {
        // Simple clustering based on cosine similarity
        const clusters: string[][] = [];
        const usedSentences = new Set<string>();
        for (let i = 0; i < sentences.length; i++) {
            if (usedSentences.has(sentences[i])) continue;
            const cluster = [sentences[i]];
            usedSentences.add(sentences[i]);
            for (let j = i + 1; j < sentences.length; j++) {
                if (usedSentences.has(sentences[j])) continue;
                const similarity = this.calculateCosineSimilarity(
                    embeddings.slice([i, 0], [1, -1]),
                    embeddings.slice([j, 0], [1, -1])
                );
                if (similarity > 0.7) {
                    cluster.push(sentences[j]);
                    usedSentences.add(sentences[j]);
                }
            }
            clusters.push(cluster);
        }
        return clusters;
    }
    private calculateCosineSimilarity(a: tf.Tensor2D, b: tf.Tensor2D): number {
        const dotProduct = tf.sum(tf.mul(a, b));
        const normA = tf.sqrt(tf.sum(tf.square(a)));
        const normB = tf.sqrt(tf.sum(tf.square(b)));
        const similarity = tf.div(dotProduct, tf.mul(normA, normB));
        return similarity.dataSync()[0];
    }
    private generateTopicTitle(cluster: string[], keywords: string[]): string {
        // Use the most representative sentence from the cluster
        const doc = nlp(cluster[0]);
        const topics = doc.topics().out('array');
        return topics[0] || keywords[0];
    }
    private calculateConfidence(cluster: string[], embeddings: tf.Tensor2D): number {
        // Calculate average similarity within the cluster
        let totalSimilarity = 0;
        let comparisons = 0;
        for (let i = 0; i < cluster.length; i++) {
            for (let j = i + 1; j < cluster.length; j++) {
                const similarity = this.calculateCosineSimilarity(
                    embeddings.slice([i, 0], [1, -1]),
                    embeddings.slice([j, 0], [1, -1])
                );
                totalSimilarity += similarity;
                comparisons++;
            }
        }
        return comparisons > 0 ? totalSimilarity / comparisons : 0;
    }
    private generateSummary(cluster: string[]): string {
        // Use the most representative sentence as a summary
        return cluster[0];
    }
    private findRelatedTopics(topicTitle: string, existingTopics: Topic[]): string[] {
        return existingTopics
            .filter(topic => {
                const similarity = natural.JaroWinklerDistance(
                    topicTitle,
                    topic.title,
                    { ignoreCase: true }
                );
                return similarity > 0.7;
            })
            .map(topic => topic.title);
    }
    private isContentRelatedToTopic(content: string, topic: Topic): boolean {
        const contentKeywords = this.extractKeywords(content);
        const commonKeywords = contentKeywords.filter(keyword =>
            topic.keywords.includes(keyword)
        );
        return commonKeywords.length >= 2;
    }
    private async identifyClaims(sentences: string[], topic: Topic): Promise<string[]> {
        const claims: string[] = [];
        const doc = nlp(sentences.join(' '));
        // Look for sentences that make strong assertions
        const statements = doc.match('(i|we|they|it) (is|are|should|must|will)').out('array');
        for (const statement of statements) {
            if (this.isRelatedToTopic(statement, topic)) {
                claims.push(statement);
            }
        }
        return claims;
    }
    private async findEvidence(sentences: string[], claim: string): Promise<string[]> {
        const evidence: string[] = [];
        const claimEmbedding = await this.sentenceEncoder.embed([claim]);
        for (const sentence of sentences) {
            if (sentence === claim) continue;
            const sentenceEmbedding = await this.sentenceEncoder.embed([sentence]);
            const similarity = this.calculateCosineSimilarity(claimEmbedding, sentenceEmbedding);
            if (similarity > 0.6) {
                evidence.push(sentence);
            }
        }
        return evidence;
    }
    private async findCounterpoints(sentences: string[], claim: string): Promise<string[]> {
        const counterpoints: string[] = [];
        const doc = nlp(sentences.join(' '));
        // Look for contrasting statements
        const contrastingStatements = doc
            .match('(however|but|although|though|contrary|despite|yet|while)')
            .out('array');
        for (const statement of contrastingStatements) {
            const similarity = natural.JaroWinklerDistance(claim, statement, { ignoreCase: true });
            if (similarity > 0.3 && similarity < 0.7) {
                counterpoints.push(statement);
            }
        }
        return counterpoints;
    }
    private async calculateClaimConfidence(
        claim: string,
        evidence: string[]
    ): Promise<number> {
        if (evidence.length === 0) return 0;
        const claimEmbedding = await this.sentenceEncoder.embed([claim]);
        let totalSimilarity = 0;
        for (const evidencePiece of evidence) {
            const evidenceEmbedding = await this.sentenceEncoder.embed([evidencePiece]);
            const similarity = this.calculateCosineSimilarity(claimEmbedding, evidenceEmbedding);
            totalSimilarity += similarity;
        }
        return totalSimilarity / evidence.length;
    }
    private isRelatedToTopic(text: string, topic: Topic): boolean {
        const textKeywords = this.extractKeywords(text);
        const commonKeywords = textKeywords.filter(keyword =>
            topic.keywords.includes(keyword)
        );
        return commonKeywords.length > 0;
    }
}
</file>

<file path="src/lib/contexts/settings-context.tsx">
"use client";
import { createContext, useContext, useState, useEffect, ReactNode } from "react";
import { useSession } from "next-auth/react";
import { useTheme } from "next-themes";
type UserPreferences = {
    defaultExpertType: 'historical' | 'domain';
    useVoiceSynthesis: boolean;
    theme: 'light' | 'dark' | 'system';
};
interface SettingsContextValue {
    preferences: UserPreferences;
    isLoaded: boolean;
    updatePreferences: (newPrefs: Partial<UserPreferences>) => Promise<boolean>;
}
const defaultPreferences: UserPreferences = {
    defaultExpertType: 'historical',
    useVoiceSynthesis: false,
    theme: 'system',
};
const SettingsContext = createContext<SettingsContextValue>({
    preferences: defaultPreferences,
    isLoaded: false,
    updatePreferences: async () => false,
});
export const useSettings = () => useContext(SettingsContext);
interface SettingsProviderProps {
    children: ReactNode;
}
export function SettingsProvider({ children }: SettingsProviderProps) {
    const { data: session, status } = useSession();
    const { setTheme } = useTheme();
    const [preferences, setPreferences] = useState<UserPreferences>(defaultPreferences);
    const [isLoaded, setIsLoaded] = useState(false);
    // Fetch user preferences when authenticated
    useEffect(() => {
        const fetchPreferences = async () => {
            if (status === "authenticated" && session?.user) {
                try {
                    const response = await fetch("/api/user/profile");
                    if (response.ok) {
                        const data = await response.json();
                        if (data?.preferences) {
                            setPreferences(data.preferences);
                            // Apply theme from preferences
                            setTheme(data.preferences.theme);
                        }
                    }
                } catch (error) {
                    console.error("Error fetching user preferences:", error);
                } finally {
                    setIsLoaded(true);
                }
            } else if (status === "unauthenticated") {
                setIsLoaded(true);
            }
        };
        fetchPreferences();
    }, [session, status, setTheme]);
    // Update preferences function
    const updatePreferences = async (newPrefs: Partial<UserPreferences>): Promise<boolean> => {
        try {
            // Only make an API call if the user is authenticated
            if (status === "authenticated") {
                const updatedPrefs = { ...preferences, ...newPrefs };
                const response = await fetch("/api/user/preferences", {
                    method: "PUT",
                    headers: { "Content-Type": "application/json" },
                    body: JSON.stringify(updatedPrefs),
                });
                if (!response.ok) return false;
                const data = await response.json();
                if (data?.preferences) {
                    setPreferences(data.preferences);
                    // Apply theme changes immediately
                    if (newPrefs.theme) {
                        setTheme(newPrefs.theme);
                    }
                    return true;
                }
                return false;
            } else {
                // For unauthenticated users, just update locally
                setPreferences(prev => ({ ...prev, ...newPrefs }));
                // Apply theme changes immediately
                if (newPrefs.theme) {
                    setTheme(newPrefs.theme);
                }
                return true;
            }
        } catch (error) {
            console.error("Error updating preferences:", error);
            return false;
        }
    };
    const value = {
        preferences,
        isLoaded,
        updatePreferences,
    };
    return (
        <SettingsContext.Provider value={value}>
            {children}
        </SettingsContext.Provider>
    );
}
</file>

<file path="src/lib/db/models/debate.ts">
import { v4 as uuidv4 } from 'uuid';
import { Expert } from '@/types/expert';
import { Message, DebateContext, ExpertContext } from '@/types/message';
import { firestore, COLLECTIONS, createDocument, getDocument, updateDocument, deleteDocument, queryDocuments } from '../firestore';
export interface SavedDebate {
    id: string;
    userId: string;
    topic: string;
    experts: Expert[];
    messages: Message[];
    expertType: 'historical' | 'domain';
    createdAt: string;
    updatedAt: string;
    status?: string;
    isFavorite?: boolean;
    tags?: string[];
    summary?: string;
    context?: DebateContext;
}
export interface CreateDebateParams {
    id?: string;
    userId: string;
    topic: string;
    experts: Expert[];
    messages?: Message[];
    expertType?: 'historical' | 'domain';
    status?: string;
    createdAt?: string;
    updatedAt?: string;
    tags?: string[];
    summary?: string;
}
/**
 * Create a new debate with retry logic and exponential backoff
 */
export async function createDebate(debateData: Partial<SavedDebate>): Promise<SavedDebate> {
    console.log('Creating debate with data:', debateData);
    // Ensure we have valid data
    const safeDebateData = debateData || {};
    // Ensure required fields
    if (!safeDebateData.topic) {
        throw new Error('Debate topic is required');
    }
    if (!safeDebateData.userId) {
        throw new Error('User ID is required');
    }
    // Set default values for optional fields
    if (!safeDebateData.messages) {
        safeDebateData.messages = [];
    }
    const debate = await createDocument(COLLECTIONS.DEBATES, safeDebateData);
    console.log('Debate created successfully:', debate.id);
    // Wait for the document to be available with exponential backoff
    let retries = 0;
    const maxRetries = 8; // Increased from 5 to 8
    let createdDebate = null;
    let waitTime = 2000; // Start with 2 seconds (increased from 1)
    while (retries < maxRetries) {
        try {
            // Add exponential backoff delay before checking
            await new Promise(resolve => setTimeout(resolve, waitTime));
            console.log(`Attempt ${retries + 1}: Checking for debate document (waiting ${waitTime}ms)...`);
            createdDebate = await getDebateById(debate.id);
            if (createdDebate) {
                console.log('Debate document found on attempt:', retries + 1);
                break;
            }
        } catch (error) {
            console.log(`Retry ${retries + 1} failed, next wait time will be ${waitTime * 2}ms...`);
        }
        retries++;
        waitTime *= 2; // Double the wait time for next attempt
    }
    if (!createdDebate) {
        throw new Error(`Database operation timeout: Failed to verify debate creation after ${maxRetries} attempts (total wait time: ${calculateTotalWaitTime(maxRetries, 2000)}ms). Please try again.`);
    }
    return createdDebate;
}
/**
 * Get a debate by ID with retry logic and exponential backoff
 */
export async function getDebateById(debateId: string): Promise<SavedDebate | null> {
    console.log('Getting debate by ID:', debateId);
    if (!debateId) {
        console.error('getDebateById called with invalid debateId');
        throw new Error('Invalid debate ID provided');
    }
    let retries = 0;
    const maxRetries = 8; // Increased from 5 to 8
    let debate = null;
    let waitTime = 2000; // Start with 2 seconds (increased from 1)
    while (retries < maxRetries) {
        try {
            debate = await getDocument(COLLECTIONS.DEBATES, debateId);
            if (debate) break;
            // Add exponential backoff delay before retrying
            await new Promise(resolve => setTimeout(resolve, waitTime));
            console.log(`Retry ${retries + 1} failed, waiting ${waitTime}ms before next attempt...`);
        } catch (error) {
            console.log(`Error on attempt ${retries + 1}, next wait time will be ${waitTime * 2}ms...`);
        }
        retries++;
        waitTime *= 2; // Double the wait time for next attempt
    }
    return debate as SavedDebate | null;
}
// Helper function to calculate total potential wait time
function calculateTotalWaitTime(maxRetries: number, initialWait: number): number {
    let total = 0;
    let current = initialWait;
    for (let i = 0; i < maxRetries; i++) {
        total += current;
        current *= 2;
    }
    return total;
}
/**
 * Update a debate
 */
export async function updateDebate(id: string, updates: Partial<SavedDebate>): Promise<SavedDebate> {
    try {
        if (!id) {
            throw new Error('No debate ID provided for update');
        }
        // Add last updated timestamp
        const updatedValues = {
            ...updates,
            updatedAt: new Date().toISOString()
        };
        const updatedDebate = await updateDocument(COLLECTIONS.DEBATES, id, updatedValues);
        return updatedDebate as SavedDebate;
    } catch (error) {
        const errorMessage = error instanceof Error ? error.message : 'Unknown error updating debate';
        console.error('Error updating debate:', errorMessage);
        throw error;
    }
}
/**
 * Delete a debate
 */
export async function deleteDebate(id: string): Promise<boolean> {
    try {
        if (!id) {
            throw new Error('No debate ID provided for deletion');
        }
        await deleteDocument(COLLECTIONS.DEBATES, id);
        return true;
    } catch (error) {
        const errorMessage = error instanceof Error ? error.message : 'Unknown error deleting debate';
        console.error('Error deleting debate:', errorMessage);
        throw error;
    }
}
/**
 * Get debates by user ID
 */
export async function getDebatesByUserId(userId: string): Promise<SavedDebate[]> {
    console.log('Getting debates by user ID:', userId);
    if (!userId) {
        console.error('getDebatesByUserId called with invalid userId');
        throw new Error('Invalid user ID provided');
    }
    const debates = await queryDocuments(COLLECTIONS.DEBATES, [
        {
            field: 'userId',
            operator: '==',
            value: userId
        }
    ]);
    return debates as SavedDebate[];
}
/**
 * Add a message to a debate
 */
export async function addMessageToDebate(debateId: string, message: Message): Promise<SavedDebate | null> {
    console.log('Adding message to debate ID:', debateId);
    if (!debateId || !message) {
        console.error('addMessageToDebate called with invalid parameters');
        throw new Error('Invalid parameters for adding message to debate');
    }
    // Get the current debate
    const debate = await getDebateById(debateId);
    if (!debate) {
        throw new Error(`Debate with ID ${debateId} not found`);
    }
    // Add the message to the debate
    const messages = [...(debate.messages || []), message];
    // Update the debate with the new message
    const updatedDebate = await updateDocument(
        COLLECTIONS.DEBATES,
        debateId,
        {
            messages,
            updatedAt: new Date().toISOString()
        }
    );
    return updatedDebate as SavedDebate;
}
/**
 * Set a debate as a favorite
 */
export async function setDebateFavorite(
    debateId: string,
    isFavorite: boolean
): Promise<SavedDebate> {
    try {
        return await updateDebate(debateId, { isFavorite });
    } catch (error) {
        const errorMessage = error instanceof Error ? error.message : 'Unknown error setting favorite status';
        console.error('Error setting debate favorite status:', errorMessage);
        throw error;
    }
}
/**
 * Update debate context
 */
export async function updateDebateContext(debateId: string, context: Partial<DebateContext>): Promise<SavedDebate | null> {
    console.log('Updating debate context for ID:', debateId);
    if (!debateId) {
        console.error('updateDebateContext called with invalid debateId');
        throw new Error('Invalid debate ID provided');
    }
    const safeContext = context || {};
    // Get the current debate
    const debate = await getDebateById(debateId);
    if (!debate) {
        throw new Error(`Debate with ID ${debateId} not found`);
    }
    // Update the context
    const updatedContext = {
        ...(debate.context || {}),
        ...safeContext
    };
    // Update the debate with the new context
    const updatedDebate = await updateDocument(
        COLLECTIONS.DEBATES,
        debateId,
        {
            context: updatedContext,
            updatedAt: new Date().toISOString()
        }
    );
    return updatedDebate as SavedDebate;
}
/**
 * Extract context for an expert to use in generating responses
 */
export function extractExpertResponseContext(
    debate: SavedDebate,
    expertName: string,
    opponentName?: string
): {
    systemPrompt: string;
    messages: Message[];
    keyContextPoints: string[];
} {
    const context = debate.context || {
        expertContexts: {},
        mainPoints: [],
        userQuestions: []
    };
    // Get the expert's context
    const expertContext = context.expertContexts[expertName] || {
        keyPoints: [],
        recentArguments: []
    };
    // Get opponent context if available
    const opponentContext = opponentName ? context.expertContexts[opponentName] : null;
    // Get recent relevant messages (last 6 messages or fewer)
    const recentMessages = debate.messages.slice(-6);
    // Build expert system prompt with context
    const keyPoints = expertContext.keyPoints.slice(-5);
    const opponentPoints = opponentContext?.keyPoints.slice(-3) || [];
    // Create the system prompt
    const systemPrompt = `
As ${expertName} discussing ${debate.topic}, remember these points from your previous arguments:
${keyPoints.map(point => `- ${point}`).join('\n')}
${opponentPoints.length > 0 ? `Your opponent (${opponentName}) has made these key points:
${opponentPoints.map(point => `- ${point}`).join('\n')}
` : ''}
Stay consistent with your established position and respond directly to the most recent points.
`;
    return {
        systemPrompt,
        messages: recentMessages,
        keyContextPoints: [...keyPoints, ...opponentPoints]
    };
}
/**
 * Get mock debates for a user (for development)
 */
export function getMockDebates(userId: string): SavedDebate[] {
    const now = new Date().toISOString();
    return [
        {
            id: uuidv4(),
            userId,
            topic: 'The Future of AI Ethics',
            experts: [
                { id: '1', name: 'Tech Optimist', avatar: 'https://i.pravatar.cc/150?u=1' },
                { id: '2', name: 'Ethics Professor', avatar: 'https://i.pravatar.cc/150?u=2' }
            ],
            messages: [
                { id: '1', sender: 'user', content: 'What are the ethical implications of AI?', timestamp: now }
            ],
            expertType: 'domain',
            createdAt: now,
            updatedAt: now,
            isFavorite: true,
            tags: ['AI', 'Ethics', 'Technology']
        },
        {
            id: uuidv4(),
            userId,
            topic: 'Climate Change Solutions',
            experts: [
                { id: '3', name: 'Environmental Scientist', avatar: 'https://i.pravatar.cc/150?u=3' },
                { id: '4', name: 'Policy Expert', avatar: 'https://i.pravatar.cc/150?u=4' }
            ],
            messages: [
                { id: '1', sender: 'user', content: 'What are effective approaches to addressing climate change?', timestamp: now }
            ],
            expertType: 'domain',
            createdAt: now,
            updatedAt: now,
            isFavorite: false,
            tags: ['Climate', 'Environment', 'Policy']
        }
    ];
}
/**
 * Get an expert by ID from a debate and optionally update it
 */
export async function getExpertById(expertId: string, updates?: Partial<Expert>): Promise<Expert | null> {
    try {
        console.log('Getting/updating expert by ID:', expertId);
        if (!expertId) {
            throw new Error('No expert ID provided');
        }
        // First, we need to find which debate contains this expert
        const debates = await queryDocuments(COLLECTIONS.DEBATES, [
            {
                field: "experts",
                op: "array-contains",
                value: { id: expertId }
            }
        ]);
        if (!debates || debates.length === 0) {
            console.log(`No debate found containing expert ${expertId}`);
            return null;
        }
        const debate = debates[0] as SavedDebate;
        const expertIndex = debate.experts.findIndex(e => e.id === expertId);
        if (expertIndex === -1) {
            console.log(`Expert ${expertId} not found in debate ${debate.id}`);
            return null;
        }
        // If no updates, just return the expert
        if (!updates) {
            return debate.experts[expertIndex];
        }
        // Apply updates to the expert
        const updatedExperts = [...debate.experts];
        updatedExperts[expertIndex] = {
            ...updatedExperts[expertIndex],
            ...updates
        };
        // Update the debate with the modified experts array
        await updateDocument(COLLECTIONS.DEBATES, debate.id, {
            experts: updatedExperts,
            updatedAt: new Date().toISOString()
        });
        console.log(`Updated expert ${expertId} in debate ${debate.id}`);
        return updatedExperts[expertIndex];
    } catch (error) {
        const errorMessage = error instanceof Error ? error.message : 'Unknown error getting/updating expert';
        console.error('Error in getExpertById:', errorMessage);
        throw error;
    }
}
</file>

<file path="src/lib/db/models/user.ts">
import { v4 as uuid } from 'uuid';
import { firestore, COLLECTIONS, createDocument, getDocument, updateDocument, deleteDocument, queryDocuments } from '../firestore';
// Function to check if Firestore is enabled
function isFirestoreEnabled() {
    // Always return true since we've migrated fully to Firestore
    return true;
}
export interface User {
    id: string;
    email: string;
    name?: string;
    createdAt?: string;
    updatedAt?: string;
    lastLoginAt?: string;
    metadata?: Record<string, any>;
    isAnonymous?: boolean;
}
export interface UserProfile extends User {
    preferredLanguage?: string;
    preferredTopics?: string[];
    expertTypes?: string[];
    settings?: {
        notifications?: boolean;
        theme?: string;
    };
}
export interface CreateUserParams {
    email: string;
    name: string;
    profilePicture?: string;
}
/**
 * Create a new user profile in Firestore
 */
export async function createUser(userData: Partial<User>): Promise<User> {
    try {
        console.log('Creating user with data:', userData);
        // Ensure we have valid data
        const safeUserData = userData || {};
        // Ensure required fields
        if (!safeUserData.email) {
            safeUserData.email = `user-${Date.now()}@example.com`;
        }
        const user = await createDocument(COLLECTIONS.USERS, safeUserData);
        console.log('User created successfully:', user.id);
        return user as User;
    } catch (error) {
        const errorMessage = error instanceof Error ? error.message : 'Unknown error creating user';
        console.error('Error in createUser:', errorMessage);
        throw error;
    }
}
/**
 * Get a user by ID from Firestore
 */
export async function getUserById(id: string): Promise<UserProfile | null> {
    if (!id) {
        console.error('Invalid user ID provided to getUserById');
        throw new Error('Invalid user ID provided');
    }
    try {
        console.log(`Getting user by ID: ${id}`);
        return await getDocument(COLLECTIONS.USERS, id) as UserProfile | null;
    } catch (error) {
        // Safely log error without passing null to source mapping
        const errorMessage = error instanceof Error ? error.message : 'Unknown error';
        console.error('Error in getUserById:', errorMessage);
        // Re-throw the error to be handled by the API route
        throw error;
    }
}
/**
 * Get a user by email from Firestore
 */
export async function getUserByEmail(email: string): Promise<UserProfile | null> {
    if (!email) {
        console.error('Invalid email provided to getUserByEmail');
        throw new Error('Invalid email provided');
    }
    try {
        console.log(`Getting user by email: ${email}`);
        // Use the queryDocuments function from firestore.ts
        const users = await queryDocuments(COLLECTIONS.USERS, [
            { field: 'email', operator: '==', value: email }
        ]);
        if (!users || users.length === 0) {
            console.log(`No user found with email: ${email}`);
            return null;
        }
        return users[0] as UserProfile;
    } catch (error) {
        // Safely log error without passing null to source mapping
        const errorMessage = error instanceof Error ? error.message : 'Unknown error';
        console.error('Error in getUserByEmail:', errorMessage);
        // Re-throw the error to be handled by the API route
        throw error;
    }
}
/**
 * Update a user's profile in Firestore
 */
export async function updateUserProfile(userId: string, profileData: Partial<UserProfile>): Promise<UserProfile> {
    if (!userId) {
        console.error('updateUserProfile called with invalid userId');
        throw new Error('Invalid user ID provided');
    }
    try {
        console.log('Updating user profile for ID:', userId);
        // Ensure we have valid data
        const safeProfileData = profileData || {};
        const updatedUser = await updateDocument(COLLECTIONS.USERS, userId, safeProfileData);
        return updatedUser as UserProfile;
    } catch (error) {
        const errorMessage = error instanceof Error ? error.message : 'Unknown error';
        console.error('Error in updateUserProfile:', errorMessage);
        throw error;
    }
}
/**
 * Delete a user from Firestore
 */
export async function deleteUser(id: string): Promise<boolean> {
    try {
        await deleteDocument(COLLECTIONS.USERS, id);
        return true;
    } catch (error) {
        const errorMessage = error instanceof Error ? error.message : 'Unknown error';
        console.error('Error in deleteUser:', errorMessage);
        throw error;
    }
}
/**
 * Create a default user profile (not a mock)
 */
export function createDefaultUserProfile(id: string): UserProfile {
    const now = new Date().toISOString();
    return {
        id: id || 'anonymous',
        email: `${id}@example.com`,
        name: 'Guest User',
        profilePicture: 'https://i.pravatar.cc/150?u=' + id,
        preferredLanguage: 'en',
        preferredTopics: [],
        expertTypes: ['domain', 'historical'],
        settings: {
            notifications: true,
            theme: 'system'
        },
        createdAt: now,
        updatedAt: now
    };
}
</file>

<file path="src/lib/db/firestore.ts">
import { getApps, initializeApp, cert } from 'firebase-admin/app';
import { getFirestore } from 'firebase-admin/firestore';
import * as fs from 'fs';
import * as path from 'path';
import { v4 as uuid } from 'uuid';
// Collections
export const COLLECTIONS = {
    USERS: process.env.FIRESTORE_USERS_COLLECTION || 'users',
    DEBATES: process.env.FIRESTORE_DEBATES_COLLECTION || 'debates',
    MESSAGES: process.env.FIRESTORE_MESSAGES_COLLECTION || 'messages'
};
// Track if Firestore has been initialized
let firestoreInitialized = false;
let firestoreInstance: ReturnType<typeof getFirestore> | null = null;
// Mock Firestore for development when credentials aren't available
class MockFirestore {
    private collections: Record<string, any> = {};
    collection(name: string) {
        if (!this.collections[name]) {
            this.collections[name] = new MockCollection(name);
        }
        return this.collections[name];
    }
    settings() {
        // No-op for mock
        return this;
    }
}
class MockCollection {
    private name: string;
    private documents: Record<string, any> = {};
    constructor(name: string) {
        this.name = name;
    }
    doc(id: string) {
        if (!this.documents[id]) {
            this.documents[id] = new MockDocument(id);
        }
        return this.documents[id];
    }
    where() {
        // Return self to allow chaining
        return this;
    }
    async get() {
        // Return empty array for queries
        return {
            forEach: (callback: (doc: any) => void) => { },
            empty: true,
            size: 0,
            docs: []
        };
    }
}
class MockDocument {
    private id: string;
    private data: any = null;
    constructor(id: string) {
        this.id = id;
    }
    async get() {
        return {
            exists: !!this.data,
            id: this.id,
            data: () => this.data
        };
    }
    async set(data: any) {
        this.data = data;
        return true;
    }
    async update(data: any) {
        this.data = { ...this.data, ...data };
        return true;
    }
    async delete() {
        this.data = null;
        return true;
    }
    collection(name: string) {
        return new MockCollection(name);
    }
}
// Only initialize on the server side
const initializeFirebaseAdmin = () => {
    if (typeof window === 'undefined') {
        try {
            if (getApps().length === 0) {
                // Check if we have a service account key path
                const serviceAccountKeyPath = process.env.FIREBASE_SERVICE_ACCOUNT_KEY_PATH;
                const projectId = process.env.FIREBASE_PROJECT_ID || process.env.GOOGLE_CLOUD_PROJECT;
                if (serviceAccountKeyPath && fs.existsSync(serviceAccountKeyPath)) {
                    console.log(`Initializing Firebase with service account key from ${serviceAccountKeyPath}`);
                    try {
                        // Read the service account key file
                        const serviceAccount = JSON.parse(fs.readFileSync(serviceAccountKeyPath, 'utf8'));
                        // Initialize Firebase with the service account
                        initializeApp({
                            credential: cert(serviceAccount),
                            projectId: projectId || serviceAccount.project_id,
                        });
                        console.log('Firebase initialized successfully with service account key file');
                        return getFirestore();
                    } catch (error) {
                        console.error('Error reading or parsing service account key file:', error);
                        console.warn('Using mock Firestore implementation');
                        return new MockFirestore() as any;
                    }
                }
                // Check if we have valid Firebase credentials as a JSON string
                let serviceAccount;
                try {
                    serviceAccount = JSON.parse(
                        process.env.FIREBASE_SERVICE_ACCOUNT_KEY || '{}'
                    );
                    // Validate service account has required fields
                    if (!serviceAccount.project_id) {
                        console.warn('Firebase service account missing project_id, using mock implementation');
                        return new MockFirestore() as any;
                    }
                } catch (error) {
                    console.warn('Invalid Firebase service account JSON, using mock implementation');
                    return new MockFirestore() as any;
                }
                // Initialize Firebase with valid credentials
                initializeApp({
                    credential: cert(serviceAccount),
                    projectId: process.env.FIREBASE_PROJECT_ID || serviceAccount.project_id,
                });
            }
            return getFirestore();
        } catch (error) {
            console.error('Error initializing Firebase Admin:', error);
            console.warn('Using mock Firestore implementation due to initialization error');
            return new MockFirestore() as any;
        }
    }
    return null;
};
// This will be null on the client side
let firestoreDb: ReturnType<typeof getFirestore> | MockFirestore | null = null;
// Only execute this on the server side
if (typeof window === 'undefined') {
    firestoreDb = initializeFirebaseAdmin();
}
// Initialize Firestore client and configure settings only once
if (!firestoreInstance) {
    try {
        firestoreInstance = firestoreDb;
        // Configure Firestore settings only if not already initialized
        if (firestoreInstance && !firestoreInitialized) {
            firestoreInstance.settings({
                ignoreUndefinedProperties: true
            });
            firestoreInitialized = true;
        }
    } catch (initError) {
        const errorMessage = initError instanceof Error ? initError.message : 'Unknown error during Firestore initialization';
        console.error('Critical error initializing Firestore:', errorMessage);
        // Create a minimal placeholder so the app doesn't crash immediately
        firestoreInstance = new MockFirestore() as any;
    }
}
// Export the firestore instance
export const firestore = firestoreInstance;
/**
 * Get a document by ID
 */
export async function getDocument(collectionPath: string, documentId: string): Promise<any | null> {
    if (!collectionPath || !documentId) {
        console.error('getDocument called with invalid parameters:', { collectionPath, documentId });
        throw new Error('Invalid parameters for getDocument');
    }
    console.log(`Getting document from ${collectionPath}/${documentId}`);
    try {
        const docRef = firestore.collection(collectionPath).doc(documentId);
        const doc = await docRef.get();
        if (!doc.exists) {
            console.log(`Document not found: ${collectionPath}/${documentId}`);
            return null;
        }
        return { id: doc.id, ...doc.data() };
    } catch (error) {
        const errorMessage = error instanceof Error ? error.message : 'Unknown error getting document';
        console.error(`Error getting document ${collectionPath}/${documentId}:`, errorMessage);
        throw error;
    }
}
/**
 * Create a document with given data
 */
export async function createDocument(collectionPath: string, data: any, documentId?: string): Promise<any> {
    if (!collectionPath || !data) {
        console.error('createDocument called with invalid parameters:', { collectionPath, data });
        throw new Error('Invalid parameters for createDocument');
    }
    console.log(`Creating document in ${collectionPath}`);
    try {
        const docId = documentId || uuid();
        const docRef = firestore.collection(collectionPath).doc(docId);
        // Add metadata
        const timestamp = new Date().toISOString();
        const enhancedData = {
            ...data,
            createdAt: data.createdAt || timestamp,
            updatedAt: timestamp
        };
        await docRef.set(enhancedData);
        return { id: docId, ...enhancedData };
    } catch (error) {
        const errorMessage = error instanceof Error ? error.message : 'Unknown error creating document';
        console.error(`Error creating document in ${collectionPath}:`, errorMessage);
        throw error;
    }
}
/**
 * Update a document with given data
 */
export async function updateDocument(collectionPath: string, documentId: string, data: any): Promise<any> {
    if (!collectionPath || !documentId || !data) {
        console.error('updateDocument called with invalid parameters:', { collectionPath, documentId, data });
        throw new Error('Invalid parameters for updateDocument');
    }
    console.log(`Updating document ${collectionPath}/${documentId}`);
    try {
        const docRef = firestore.collection(collectionPath).doc(documentId);
        // Add updatedAt timestamp
        const enhancedData = {
            ...data,
            updatedAt: new Date().toISOString()
        };
        await docRef.update(enhancedData);
        // Get the updated document
        const updatedDoc = await docRef.get();
        if (!updatedDoc.exists) {
            throw new Error(`Document ${documentId} not found after update`);
        }
        return { id: updatedDoc.id, ...updatedDoc.data() };
    } catch (error) {
        const errorMessage = error instanceof Error ? error.message : 'Unknown error updating document';
        console.error(`Error updating document ${collectionPath}/${documentId}:`, errorMessage);
        throw error;
    }
}
/**
 * Delete a document
 */
export async function deleteDocument(collectionPath: string, documentId: string): Promise<boolean> {
    if (!collectionPath || !documentId) {
        console.error('deleteDocument called with invalid parameters:', { collectionPath, documentId });
        throw new Error('Invalid parameters for deleteDocument');
    }
    console.log(`Deleting document ${collectionPath}/${documentId}`);
    try {
        const docRef = firestore.collection(collectionPath).doc(documentId);
        await docRef.delete();
        return true;
    } catch (error) {
        const errorMessage = error instanceof Error ? error.message : 'Unknown error deleting document';
        console.error(`Error deleting document ${collectionPath}/${documentId}:`, errorMessage);
        throw error;
    }
}
/**
 * Query documents with filters
 */
export async function queryDocuments(collectionPath: string, filters: Array<{ field: string, op: string, value: any }>): Promise<any[]> {
    if (!collectionPath) {
        console.error('queryDocuments called with invalid parameters:', { collectionPath, filters });
        throw new Error('Invalid parameters for queryDocuments');
    }
    console.log(`Querying documents in ${collectionPath} with ${filters ? filters.length : 0} filters`);
    try {
        let query = firestore.collection(collectionPath);
        // Apply filters
        if (filters && filters.length > 0) {
            for (const filter of filters) {
                query = query.where(filter.field, filter.op as any, filter.value);
            }
        }
        const querySnapshot = await query.get();
        const results = [];
        querySnapshot.forEach(doc => {
            results.push({ id: doc.id, ...doc.data() });
        });
        return results;
    } catch (error) {
        const errorMessage = error instanceof Error ? error.message : 'Unknown error querying documents';
        console.error(`Error querying documents in ${collectionPath}:`, errorMessage);
        throw error;
    }
}
</file>

<file path="src/lib/mock/user.ts">
import { UserProfile } from '@/lib/db/models/user';
/**
 * Mock user profiles for development
 */
export const mockUsers: Record<string, UserProfile> = {
    // Default mock user
    'default': {
        id: 'mock-user-123',
        email: 'user@example.com',
        name: 'Test User',
        profilePicture: 'https://api.dicebear.com/7.x/avataaars/svg?seed=TestUser',
        preferences: {
            defaultExpertType: 'domain',
            useVoiceSynthesis: false,
            theme: 'system',
        },
        createdAt: new Date().toISOString(),
        updatedAt: new Date().toISOString(),
    },
    // Admin user
    'admin': {
        id: 'mock-admin-456',
        email: 'admin@example.com',
        name: 'Admin User',
        profilePicture: 'https://api.dicebear.com/7.x/avataaars/svg?seed=AdminUser',
        preferences: {
            defaultExpertType: 'historical',
            useVoiceSynthesis: true,
            theme: 'dark',
        },
        createdAt: new Date(Date.now() - 30 * 24 * 60 * 60 * 1000).toISOString(), // 30 days ago
        updatedAt: new Date().toISOString(),
    }
};
/**
 * Get a mock user profile by ID
 */
export function getMockUserProfile(userId: string): UserProfile {
    // If the user ID matches a specific mock user, return it
    if (mockUsers[userId]) {
        return { ...mockUsers[userId] };
    }
    // Otherwise, return the default mock user with the requested ID
    return {
        ...mockUsers.default,
        id: userId,
        name: `User ${userId.slice(0, 5)}`,
        profilePicture: `https://api.dicebear.com/7.x/avataaars/svg?seed=${userId}`,
    };
}
</file>

<file path="src/lib/services/DebateCache.ts">
import { redis, getDebateKey, setWithExpiry } from '@/lib/redis'
import { Expert } from '@/types/expert'
import { Message } from '@/types/message'
export interface DebateCacheData {
    id: string
    topic: string
    experts: Expert[]
    messages: Message[]
    status: 'active' | 'completed' | 'error'
    lastUpdated: string
    userId: string
}
export interface CacheOperationResult<T> {
    success: boolean
    data?: T
    error?: string
}
export class DebateCache {
    private static CACHE_DURATION = 24 // hours
    /**
     * Store debate data in cache
     */
    static async setDebate(debateData: DebateCacheData): Promise<CacheOperationResult<void>> {
        try {
            const key = getDebateKey(debateData.id)
            await setWithExpiry(key, debateData, this.CACHE_DURATION)
            return { success: true }
        } catch (error) {
            console.error('Error setting debate in cache:', error)
            return {
                success: false,
                error: error instanceof Error ? error.message : 'Failed to cache debate'
            }
        }
    }
    /**
     * Retrieve debate data from cache
     */
    static async getDebate(debateId: string): Promise<CacheOperationResult<DebateCacheData>> {
        try {
            const key = getDebateKey(debateId)
            const data = await redis.get<string>(key)
            if (!data) {
                return {
                    success: false,
                    error: 'Debate not found in cache'
                }
            }
            const debateData = JSON.parse(data) as DebateCacheData
            return {
                success: true,
                data: debateData
            }
        } catch (error) {
            console.error('Error getting debate from cache:', error)
            return {
                success: false,
                error: error instanceof Error ? error.message : 'Failed to retrieve debate'
            }
        }
    }
    /**
     * Add a message to a debate in cache
     */
    static async addMessage(debateId: string, message: Message): Promise<CacheOperationResult<void>> {
        try {
            const getResult = await this.getDebate(debateId)
            if (!getResult.success || !getResult.data) {
                return {
                    success: false,
                    error: getResult.error || 'Debate not found'
                }
            }
            const debate = getResult.data
            debate.messages.push(message)
            debate.lastUpdated = new Date().toISOString()
            return await this.setDebate(debate)
        } catch (error) {
            console.error('Error adding message to cached debate:', error)
            return {
                success: false,
                error: error instanceof Error ? error.message : 'Failed to add message'
            }
        }
    }
    /**
     * Update debate status
     */
    static async updateStatus(
        debateId: string,
        status: DebateCacheData['status']
    ): Promise<CacheOperationResult<void>> {
        try {
            const getResult = await this.getDebate(debateId)
            if (!getResult.success || !getResult.data) {
                return {
                    success: false,
                    error: getResult.error || 'Debate not found'
                }
            }
            const debate = getResult.data
            debate.status = status
            debate.lastUpdated = new Date().toISOString()
            return await this.setDebate(debate)
        } catch (error) {
            console.error('Error updating debate status in cache:', error)
            return {
                success: false,
                error: error instanceof Error ? error.message : 'Failed to update status'
            }
        }
    }
    /**
     * Remove debate from cache
     */
    static async removeDebate(debateId: string): Promise<CacheOperationResult<void>> {
        try {
            const key = getDebateKey(debateId)
            await redis.del(key)
            return { success: true }
        } catch (error) {
            console.error('Error removing debate from cache:', error)
            return {
                success: false,
                error: error instanceof Error ? error.message : 'Failed to remove debate'
            }
        }
    }
    /**
     * Get all active debates for a user
     */
    static async getUserDebates(userId: string): Promise<CacheOperationResult<DebateCacheData[]>> {
        try {
            // Get all debate keys
            const keys = await redis.keys('debate:metadata:*')
            const debates: DebateCacheData[] = []
            // Fetch all debates in parallel
            const debatePromises = keys.map(key => redis.get<string>(key))
            const debateResults = await Promise.all(debatePromises)
            // Filter debates for the user
            for (const result of debateResults) {
                if (result) {
                    const debate = JSON.parse(result) as DebateCacheData
                    if (debate.userId === userId) {
                        debates.push(debate)
                    }
                }
            }
            return {
                success: true,
                data: debates
            }
        } catch (error) {
            console.error('Error getting user debates from cache:', error)
            return {
                success: false,
                error: error instanceof Error ? error.message : 'Failed to get user debates'
            }
        }
    }
}
</file>

<file path="src/lib/storage/background-task-manager.ts">
import { firestore } from '../db/firestore';
interface Task {
    type: 'initialize-debate' | 'add-message' | 'update-status' | 'update-context';
    data: any;
}
export class BackgroundTaskManager {
    private static instance: BackgroundTaskManager;
    private taskQueue: Task[] = [];
    private isProcessing: boolean = false;
    private processingInterval: NodeJS.Timeout | null = null;
    private maxRetries: number = 3;
    private retryMap: Map<string, number> = new Map();
    private constructor() {
        // Start processing tasks only on the server side
        if (typeof window === 'undefined') {
            this.processingInterval = setInterval(() => this.processTasks(), 5000); // Process every 5 seconds
        }
    }
    public static getInstance(): BackgroundTaskManager {
        if (!BackgroundTaskManager.instance) {
            BackgroundTaskManager.instance = new BackgroundTaskManager();
        }
        return BackgroundTaskManager.instance;
    }
    public queueTask(task: Task): void {
        // Generate a unique task ID for tracking retries
        const taskId = `${task.type}_${Date.now()}_${Math.random().toString(36).substring(2, 9)}`;
        const taskWithId = { ...task, id: taskId };
        this.taskQueue.push(taskWithId as Task);
        // If we're on the client side, we'll just queue the task
        // If we're on the server side and not already processing, start processing
        if (typeof window === 'undefined' && !this.isProcessing) {
            this.processTasks();
        }
    }
    private async processTasks(): Promise<void> {
        // Only process on the server side and if there are tasks
        if (typeof window !== 'undefined' || this.isProcessing || this.taskQueue.length === 0) {
            return;
        }
        this.isProcessing = true;
        try {
            // Process up to 5 tasks at a time
            const tasksToProcess = this.taskQueue.splice(0, 5);
            for (const task of tasksToProcess) {
                try {
                    await this.processTask(task);
                } catch (error) {
                    console.error(`Error processing task ${task.type}:`, error);
                    // Check if we should retry
                    const taskId = (task as any).id;
                    const retryCount = this.retryMap.get(taskId) || 0;
                    if (retryCount < this.maxRetries) {
                        // Increment retry count and re-queue
                        this.retryMap.set(taskId, retryCount + 1);
                        this.taskQueue.push(task);
                        console.log(`Requeued task ${task.type} for retry (${retryCount + 1}/${this.maxRetries})`);
                    } else {
                        console.error(`Task ${task.type} failed after ${this.maxRetries} retries, dropping`);
                        this.retryMap.delete(taskId);
                    }
                }
            }
        } catch (error) {
            console.error('Error processing background tasks:', error);
        } finally {
            this.isProcessing = false;
            // If there are more tasks, continue processing
            if (this.taskQueue.length > 0) {
                setTimeout(() => this.processTasks(), 1000);
            }
        }
    }
    private async processTask(task: Task): Promise<void> {
        // Skip if we're on the client side or if Firestore isn't available
        if (typeof window !== 'undefined' || !firestore) {
            return;
        }
        switch (task.type) {
            case 'initialize-debate':
                await this.initializeDebate(task.data);
                break;
            case 'add-message':
                await this.addMessage(task.data);
                break;
            case 'update-status':
                await this.updateStatus(task.data);
                break;
            case 'update-context':
                await this.updateContext(task.data);
                break;
            default:
                console.warn('Unknown task type:', task.type);
        }
    }
    private async initializeDebate(data: any): Promise<void> {
        const { debateId, topic, experts, userId, timestamp } = data;
        try {
            await firestore.collection('debates').doc(debateId).set({
                id: debateId,
                topic,
                expertType: experts[0]?.type || 'unknown',
                userId,
                status: 'active',
                createdAt: timestamp,
                updatedAt: timestamp
            });
            // Store experts in a subcollection
            const expertsCollection = firestore.collection('debates').doc(debateId).collection('experts');
            for (const expert of experts) {
                await expertsCollection.doc(expert.id).set({
                    ...expert,
                    addedAt: timestamp
                });
            }
        } catch (error) {
            console.error('Error initializing debate in Firestore:', error);
            // Let the error propagate for retry handling
            throw error;
        }
    }
    private async addMessage(data: any): Promise<void> {
        const { debateId, message, timestamp } = data;
        try {
            // Add message to messages subcollection
            await firestore.collection('debates').doc(debateId)
                .collection('messages').doc(message.id).set({
                    ...message,
                    timestamp
                });
            // Update debate's updatedAt timestamp
            await firestore.collection('debates').doc(debateId).update({
                updatedAt: timestamp
            });
        } catch (error) {
            console.error('Error adding message to Firestore:', error);
            throw error;
        }
    }
    private async updateStatus(data: any): Promise<void> {
        const { debateId, status, timestamp } = data;
        try {
            await firestore.collection('debates').doc(debateId).update({
                status,
                updatedAt: timestamp
            });
        } catch (error) {
            console.error('Error updating status in Firestore:', error);
            throw error;
        }
    }
    private async updateContext(data: any): Promise<void> {
        const { debateId, context, timestamp } = data;
        try {
            await firestore.collection('debates').doc(debateId).update({
                context,
                updatedAt: timestamp
            });
        } catch (error) {
            console.error('Error updating context in Firestore:', error);
            throw error;
        }
    }
    // Clean up on application shutdown
    public cleanup(): void {
        if (this.processingInterval) {
            clearInterval(this.processingInterval);
        }
    }
}
</file>

<file path="src/lib/storage/debate-storage.ts">
import { firestore } from '../db/firestore';
import { BackgroundTaskManager } from './background-task-manager';
import { DebateMetadata, FastAccessData, StorageOperationResult } from '@/types/storage';
import Redis from 'ioredis';
// Mock Redis implementation for when Redis is not available
class MockRedis {
    private storage: Record<string, string> = {};
    async get(key: string): Promise<string | null> {
        return this.storage[key] || null;
    }
    async set(key: string, value: string, expiryFlag?: string, expiry?: number): Promise<string> {
        this.storage[key] = value;
        return 'OK';
    }
    async del(key: string): Promise<number> {
        if (this.storage[key]) {
            delete this.storage[key];
            return 1;
        }
        return 0;
    }
}
// Interface for Redis-like clients
interface RedisClient {
    get(key: string): Promise<string | null>;
    set(key: string, value: string, expiryFlag?: string, expiry?: number): Promise<string | any>;
    del(key: string): Promise<number>;
}
// Initialize Redis client only on the server side
let redisClient: RedisClient | null = null;
if (typeof window === 'undefined') {
    try {
        // Check if Upstash Redis is configured (REST API based)
        if (process.env.UPSTASH_REDIS_REST_URL && process.env.UPSTASH_REDIS_REST_TOKEN) {
            console.log('Using Upstash Redis REST client');
            // Dynamic import to avoid client-side loading
            import('@upstash/redis').then((module) => {
                const { Redis } = module;
                redisClient = new Redis({
                    url: process.env.UPSTASH_REDIS_REST_URL as string,
                    token: process.env.UPSTASH_REDIS_REST_TOKEN as string,
                });
                console.log('Upstash Redis initialized successfully');
            }).catch(err => {
                console.error('Failed to initialize Upstash Redis:', err);
                console.warn('Using mock Redis implementation');
                redisClient = new MockRedis();
            });
        }
        // Check if standard Redis URL is configured
        else if (process.env.REDIS_URL) {
            console.log('Using standard Redis client with URL:', process.env.REDIS_URL);
            try {
                redisClient = new Redis(process.env.REDIS_URL);
                console.log('Redis initialized successfully');
            } catch (err) {
                console.error('Failed to initialize Redis with URL:', err);
                console.warn('Using mock Redis implementation');
                redisClient = new MockRedis();
            }
        } else {
            console.warn('No Redis configuration found, using mock Redis implementation');
            redisClient = new MockRedis();
        }
    } catch (err) {
        console.error('Error setting up Redis:', err);
        console.warn('Using mock Redis implementation');
        redisClient = new MockRedis();
    }
}
export class DebateStorage {
    private static instance: DebateStorage;
    private backgroundTaskManager: BackgroundTaskManager;
    private redis: RedisClient | null;
    private constructor() {
        this.backgroundTaskManager = BackgroundTaskManager.getInstance();
        this.redis = redisClient;
    }
    public static async getInstance(): Promise<DebateStorage> {
        if (!DebateStorage.instance) {
            DebateStorage.instance = new DebateStorage();
        }
        return DebateStorage.instance;
    }
    // Get the Redis client
    private getRedisClient(): RedisClient | null {
        if (!this.redis) {
            console.warn('Redis client not initialized');
        }
        return this.redis;
    }
    // Test Redis connection
    public async testRedisConnection(key: string, value: string): Promise<any> {
        try {
            const redis = this.getRedisClient();
            if (typeof window === 'undefined' && redis) {
                // Try to set a value
                let setResult;
                // Handle different Redis client implementations
                if (redis instanceof MockRedis) {
                    setResult = await redis.set(`test:${key}`, value, 'EX', 60); // 60 seconds expiry
                } else {
                    // For Upstash Redis, the API is slightly different
                    try {
                        setResult = await redis.set(`test:${key}`, value, { ex: 60 }); // 60 seconds expiry
                    } catch (err) {
                        console.error('Error setting Redis key with expiry:', err);
                        // Try without expiry as fallback
                        setResult = await redis.set(`test:${key}`, value);
                    }
                }
                // Try to get the value back
                const getValue = await redis.get(`test:${key}`);
                // Delete the test key
                const deleteResult = await redis.del(`test:${key}`);
                return {
                    set: setResult,
                    get: getValue,
                    delete: deleteResult,
                    usingMock: redis instanceof MockRedis
                };
            }
            return {
                error: 'Redis not available',
                usingMock: this.redis instanceof MockRedis
            };
        } catch (error) {
            console.error('Error testing Redis connection:', error);
            return {
                error: error instanceof Error ? error.message : 'Unknown error testing Redis',
                usingMock: this.redis instanceof MockRedis
            };
        }
    }
    // Initialize a new debate
    public async initializeDebate(
        debateId: string,
        topic: string,
        experts: any[],
        userId: string
    ): Promise<StorageOperationResult> {
        try {
            // Store in Redis for fast access
            const fastAccessData: FastAccessData = {
                topic,
                experts,
                messages: [],
                lastUpdated: new Date().toISOString()
            };
            const redis = this.getRedisClient();
            if (typeof window === 'undefined' && redis) {
                // Handle different Redis client implementations
                if (redis instanceof MockRedis) {
                    await redis.set(`debate:${debateId}`, JSON.stringify(fastAccessData), 'EX', 60 * 60 * 24); // 24 hours expiry
                } else {
                    // For Upstash Redis, the API is slightly different
                    await redis.set(`debate:${debateId}`, JSON.stringify(fastAccessData), { ex: 60 * 60 * 24 }); // 24 hours expiry
                }
            }
            // Queue background task to store in Firestore
            this.backgroundTaskManager.queueTask({
                type: 'initialize-debate',
                data: {
                    debateId,
                    topic,
                    experts,
                    userId,
                    timestamp: new Date().toISOString()
                }
            });
            return { success: true };
        } catch (error) {
            console.error('Error initializing debate:', error);
            return {
                success: false,
                error: error instanceof Error ? error.message : 'Unknown error initializing debate'
            };
        }
    }
    // Add a message to the debate
    public async addMessage(debateId: string, message: any): Promise<StorageOperationResult> {
        try {
            // First update Redis for immediate access
            const redis = this.getRedisClient();
            if (typeof window === 'undefined' && redis) {
                const debateDataStr = await redis.get(`debate:${debateId}`);
                if (debateDataStr) {
                    const debateData: FastAccessData = JSON.parse(debateDataStr);
                    debateData.messages.push(message);
                    debateData.lastUpdated = new Date().toISOString();
                    // Handle different Redis client implementations
                    if (redis instanceof MockRedis) {
                        await redis.set(`debate:${debateId}`, JSON.stringify(debateData), 'EX', 60 * 60 * 24);
                    } else {
                        // For Upstash Redis, the API is slightly different
                        await redis.set(`debate:${debateId}`, JSON.stringify(debateData), { ex: 60 * 60 * 24 });
                    }
                }
            }
            // Queue background task to update Firestore
            this.backgroundTaskManager.queueTask({
                type: 'add-message',
                data: {
                    debateId,
                    message,
                    timestamp: new Date().toISOString()
                }
            });
            return { success: true };
        } catch (error) {
            console.error('Error adding message:', error);
            return {
                success: false,
                error: error instanceof Error ? error.message : 'Unknown error adding message'
            };
        }
    }
    // Get fast access data from Redis
    public async getFastAccessData(debateId: string): Promise<FastAccessData | null> {
        try {
            const redis = this.getRedisClient();
            if (typeof window === 'undefined' && redis) {
                const debateDataStr = await redis.get(`debate:${debateId}`);
                if (debateDataStr) {
                    return JSON.parse(debateDataStr);
                }
            }
            return null;
        } catch (error) {
            console.error('Error getting fast access data:', error);
            return null;
        }
    }
    // Get complete debate data
    public async getDebate(debateId: string): Promise<FastAccessData | null> {
        // First try to get from Redis
        const fastAccessData = await this.getFastAccessData(debateId);
        if (fastAccessData) {
            return fastAccessData;
        }
        // If not in Redis, try to get from Firestore
        try {
            if (typeof window === 'undefined' && firestore) {
                const debateDoc = await firestore.collection('debates').doc(debateId).get();
                if (debateDoc.exists) {
                    // Get messages
                    const messagesSnapshot = await firestore
                        .collection('debates')
                        .doc(debateId)
                        .collection('messages')
                        .orderBy('timestamp')
                        .get();
                    const messages = messagesSnapshot.docs.map(doc => doc.data());
                    // Get experts
                    const expertsSnapshot = await firestore
                        .collection('debates')
                        .doc(debateId)
                        .collection('experts')
                        .get();
                    const experts = expertsSnapshot.docs.map(doc => doc.data());
                    const debateData = debateDoc.data();
                    const result: FastAccessData = {
                        topic: debateData?.topic || '',
                        experts,
                        messages,
                        lastUpdated: debateData?.updatedAt || new Date().toISOString()
                    };
                    // Store in Redis for future fast access
                    const redis = this.getRedisClient();
                    if (redis) {
                        // Handle different Redis client implementations
                        if (redis instanceof MockRedis) {
                            await redis.set(`debate:${debateId}`, JSON.stringify(result), 'EX', 60 * 60 * 24);
                        } else {
                            // For Upstash Redis, the API is slightly different
                            await redis.set(`debate:${debateId}`, JSON.stringify(result), { ex: 60 * 60 * 24 });
                        }
                    }
                    return result;
                }
            }
            return null;
        } catch (error) {
            console.error('Error getting debate data:', error);
            return null;
        }
    }
    // Update debate status
    public async updateDebateStatus(debateId: string, status: string): Promise<StorageOperationResult> {
        try {
            // Queue background task to update status in Firestore
            this.backgroundTaskManager.queueTask({
                type: 'update-status',
                data: {
                    debateId,
                    status,
                    timestamp: new Date().toISOString()
                }
            });
            return { success: true };
        } catch (error) {
            console.error('Error updating debate status:', error);
            return {
                success: false,
                error: error instanceof Error ? error.message : 'Unknown error updating status'
            };
        }
    }
    // Get debate metadata from Firestore
    public async getDebateMetadata(debateId: string): Promise<DebateMetadata | null> {
        try {
            if (typeof window === 'undefined' && firestore) {
                const debateDoc = await firestore.collection('debates').doc(debateId).get();
                if (debateDoc.exists) {
                    return debateDoc.data() as DebateMetadata;
                }
            }
            return null;
        } catch (error) {
            console.error('Error getting debate metadata:', error);
            return null;
        }
    }
}
</file>

<file path="src/lib/storage/types.ts">
import { Expert } from '@/types/expert';
import { Message, DebateContext } from '@/types/message';
export interface DebateMetadata {
    id: string;
    userId: string;
    topic: string;
    expertType: 'historical' | 'domain';
    status: 'initializing' | 'active' | 'completed' | 'error';
    createdAt: string;
    updatedAt: string;
}
export interface FastAccessData {
    experts?: Expert[];
    recentMessages?: Message[];
    currentContext?: DebateContext;
}
export interface StorageOperationResult<T> {
    success: boolean;
    data?: T;
    error?: string;
}
</file>

<file path="src/lib/tasks/background-tasks.ts">
import { Message } from '@/types/message';
import { Expert } from '@/types/expert';
import { firestore, COLLECTIONS } from '../db/firestore';
interface TaskData {
    debateId: string;
    [key: string]: any;
}
type TaskType =
    | 'initialize_debate_storage'
    | 'store_message'
    | 'update_context'
    | 'process_citations';
class BackgroundTasks {
    private static instance: BackgroundTasks;
    private taskQueue: Map<string, Promise<void>>;
    private constructor() {
        this.taskQueue = new Map();
    }
    static getInstance(): BackgroundTasks {
        if (!BackgroundTasks.instance) {
            BackgroundTasks.instance = new BackgroundTasks();
        }
        return BackgroundTasks.instance;
    }
    async queue(taskType: TaskType, data: TaskData): Promise<void> {
        const taskId = `${taskType}_${data.debateId}_${Date.now()}`;
        const taskPromise = this.executeTask(taskType, data)
            .catch(error => {
                console.error(`Task ${taskId} failed:`, error);
            })
            .finally(() => {
                this.taskQueue.delete(taskId);
            });
        this.taskQueue.set(taskId, taskPromise);
        return taskPromise;
    }
    private async executeTask(taskType: TaskType, data: TaskData): Promise<void> {
        switch (taskType) {
            case 'initialize_debate_storage':
                await this.initializeDebateStorage(data);
                break;
            case 'store_message':
                await this.storeMessage(data);
                break;
            case 'update_context':
                await this.updateContext(data);
                break;
            case 'process_citations':
                await this.processCitations(data);
                break;
        }
    }
    private async initializeDebateStorage(data: TaskData & { experts: Expert[] }): Promise<void> {
        const { debateId, experts } = data;
        // Create experts subcollection
        const batch = firestore.batch();
        const expertsRef = firestore
            .collection(COLLECTIONS.DEBATES)
            .doc(debateId)
            .collection('experts');
        experts.forEach(expert => {
            batch.set(expertsRef.doc(expert.id), expert);
        });
        await batch.commit();
    }
    private async storeMessage(data: TaskData & { message: Message }): Promise<void> {
        const { debateId, message } = data;
        await firestore
            .collection(COLLECTIONS.DEBATES)
            .doc(debateId)
            .collection('messages')
            .doc(message.id || crypto.randomUUID())
            .set(message);
    }
    private async updateContext(data: TaskData & { message: Message }): Promise<void> {
        const { debateId, message } = data;
        // Update debate context based on new message
        // This could include updating key points, sentiment analysis, etc.
        // Implementation depends on your specific needs
    }
    private async processCitations(data: TaskData & { message: Message }): Promise<void> {
        const { debateId, message } = data;
        // Process and store citations from the message
        // Implementation depends on your citation handling needs
    }
}
export const backgroundTasks = BackgroundTasks.getInstance();
</file>

<file path="src/lib/utils/citation-processor.ts">
import { Citation } from '@/types/message';
import { SourceReference } from '@/types/expert';
import { v4 as uuidv4 } from 'uuid';
/**
 * Process citation markers in text and extract citations
 * Citation format: [citation:1], [citation:2], etc.
 */
export function processCitationMarkers(
    text: string,
    sourceReferences: SourceReference[]
): { processedText: string; citations: Citation[] } {
    const citations: Citation[] = [];
    // Regular expression to find citation markers like [Citation: 1]
    const citationRegex = /\[Citation:\s*(\d+)\]/g;
    // Replace citation markers with superscript numbers and collect citation data
    let match;
    let processedText = text;
    while ((match = citationRegex.exec(text)) !== null) {
        const fullMatch = match[0];
        const referenceNumber = parseInt(match[1], 10);
        // Find the corresponding source reference
        const sourceReference = sourceReferences[referenceNumber - 1];
        if (sourceReference) {
            const startIndex = match.index;
            const endIndex = startIndex + fullMatch.length;
            const citation: Citation = {
                id: uuidv4(),
                referenceId: sourceReference.id,
                text: `${sourceReference.title} - ${sourceReference.author || 'Unknown'} (${sourceReference.year || 'Unknown'})`,
                startIndex,
                endIndex
            };
            citations.push(citation);
            // Replace the citation marker with a superscript number
            const superscriptNumber = `<sup>[${referenceNumber}]</sup>`;
            processedText = processedText.replace(fullMatch, superscriptNumber);
        }
    }
    return { processedText, citations };
}
/**
 * Enhances the system prompt with instructions for using citations
 */
export function enhancePromptWithCitationInstructions(systemContent: string): string {
    const citationInstructions = `
When referencing information from the provided sources, use citation markers in the format [citation:N] where N is the source number.
For example: "According to the research [citation:1], AI integration leads to improved customer engagement."
Make sure to cite specific claims and statistics from the sources to support your arguments.
`;
    return `${systemContent}\n\n${citationInstructions.trim()}`;
}
</file>

<file path="src/lib/auth.ts">
import { NextAuthOptions } from 'next-auth';
import GitHubProvider from 'next-auth/providers/github';
import GoogleProvider from 'next-auth/providers/google';
export const authOptions: NextAuthOptions = {
    providers: [
        GitHubProvider({
            clientId: process.env.GITHUB_ID || '',
            clientSecret: process.env.GITHUB_SECRET || '',
        }),
        GoogleProvider({
            clientId: process.env.GOOGLE_CLIENT_ID || '',
            clientSecret: process.env.GOOGLE_CLIENT_SECRET || '',
            authorization: {
                params: {
                    prompt: "select_account"
                }
            }
        }),
    ],
    session: {
        strategy: 'jwt',
        maxAge: 30 * 24 * 60 * 60, // 30 days
    },
    cookies: {
        sessionToken: {
            name: `next-auth.session-token`,
            options: {
                httpOnly: true,
                sameSite: 'lax',
                path: '/',
                secure: process.env.NODE_ENV === 'production',
                maxAge: 30 * 24 * 60 * 60 // 30 days
            }
        },
        callbackUrl: {
            name: `next-auth.callback-url`,
            options: {
                httpOnly: true,
                sameSite: 'lax',
                path: '/',
                secure: process.env.NODE_ENV === 'production',
            }
        },
        csrfToken: {
            name: `next-auth.csrf-token`,
            options: {
                httpOnly: true,
                sameSite: 'lax',
                path: '/',
                secure: process.env.NODE_ENV === 'production',
            }
        }
    },
    secret: process.env.NEXTAUTH_SECRET,
    pages: {
        signIn: '/auth/signin',
        signOut: '/auth/signout',
        error: '/auth/error',
        verifyRequest: '/auth/verify-request',
    },
    callbacks: {
        async session({ session, token }) {
            // Add the user ID to the session
            if (session.user && token.sub) {
                session.user.id = token.sub;
            }
            // Ensure other user data is present
            if (session.user) {
                session.user.name = session.user.name || token.name;
                session.user.email = session.user.email || token.email;
                session.user.image = session.user.image || token.picture;
            }
            return session;
        },
        async jwt({ token, user, account, profile }) {
            // If user just signed in, add their ID to the token
            if (user) {
                token.sub = user.id;
            }
            // Store additional profile data in the token
            if (profile) {
                token.name = profile.name;
                token.email = profile.email;
                token.picture = profile.picture;
            }
            return token;
        },
    },
};
// Helper to access auth options throughout the app
export function getAuthOptions() {
    return authOptions;
}
</file>

<file path="src/lib/elevenlabs.ts">
import { Voice } from 'elevenlabs/types';
const ELEVENLABS_API_KEY = process.env.ELEVENLABS_API_KEY;
const API_URL = 'https://api.elevenlabs.io/v1';
// ElevenLabs pricing (as of March 2024)
const COST_PER_1K_CHARS = 0.30; // $0.30 per 1000 characters
export interface ElevenLabsUsage {
    characterCount: number;
    cost: number; // in USD
}
function calculateElevenLabsCost(characterCount: number): ElevenLabsUsage {
    return {
        characterCount,
        cost: (characterCount / 1000) * COST_PER_1K_CHARS
    };
}
// Default voice IDs for our experts
const DEFAULT_VOICES = {
    male1: "pNInz6obpgDQGcFmaJgB", // Adam
    male2: "ErXwobaYiN019PkySvjV", // Antoni
    female1: "EXAVITQu4vr4xnSDxMaL", // Bella
    female2: "21m00Tcm4TlvDq8ikWAM", // Rachel
};
export interface VoiceSettings {
    stability: number;
    similarity_boost: number;
    style: number;
    use_speaker_boost: boolean;
}
const defaultVoiceSettings: VoiceSettings = {
    stability: 0.5,
    similarity_boost: 0.75,
    style: 0.5,
    use_speaker_boost: true,
};
export async function textToSpeech(
    text: string,
    voiceId: string = DEFAULT_VOICES.male1,
    settings: Partial<VoiceSettings> = {}
): Promise<{ audioBuffer: ArrayBuffer; usage: ElevenLabsUsage }> {
    // Validate API key
    if (!ELEVENLABS_API_KEY) {
        console.error('ElevenLabs API key validation failed:', {
            hasKey: !!ELEVENLABS_API_KEY,
            envKeys: Object.keys(process.env),
            nodeEnv: process.env.NODE_ENV
        });
        throw new Error('ELEVENLABS_API_KEY is not configured in environment variables');
    }
    // Validate input parameters
    if (!text?.trim()) {
        throw new Error('Text is required for speech synthesis');
    }
    if (!voiceId?.trim()) {
        throw new Error('Voice ID is required for speech synthesis');
    }
    const trimmedText = text.trim();
    const requestId = Math.random().toString(36).substring(7);
    const usage = calculateElevenLabsCost(trimmedText.length);
    console.log(`[${requestId}] Preparing ElevenLabs request:`, {
        voiceId,
        textLength: trimmedText.length,
        textPreview: trimmedText.substring(0, 100) + '...',
        hasApiKey: !!ELEVENLABS_API_KEY,
        settings: { ...defaultVoiceSettings, ...settings },
        usage
    });
    try {
        const requestBody = {
            text: trimmedText,
            model_id: 'eleven_multilingual_v2',
            voice_settings: { ...defaultVoiceSettings, ...settings },
        };
        const url = `${API_URL}/text-to-speech/${voiceId}/stream`;
        console.log(`[${requestId}] Making request to:`, url);
        const response = await fetch(url, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'xi-api-key': ELEVENLABS_API_KEY,
                'Accept': 'audio/mpeg',
            },
            body: JSON.stringify(requestBody),
        });
        console.log(`[${requestId}] ElevenLabs response:`, {
            status: response.status,
            statusText: response.statusText,
            headers: Object.fromEntries(response.headers.entries()),
        });
        if (!response.ok) {
            let errorMessage = `ElevenLabs API error: ${response.status} ${response.statusText}`;
            let errorDetails = {};
            try {
                const errorData = await response.json();
                console.error(`[${requestId}] ElevenLabs error details:`, errorData);
                errorDetails = errorData;
                if (errorData.detail) {
                    errorMessage += ` - ${errorData.detail}`;
                }
                if (errorData.message) {
                    errorMessage += ` - ${errorData.message}`;
                }
            } catch (e) {
                console.error(`[${requestId}] Failed to parse error response:`, e);
                try {
                    const rawText = await response.text();
                    console.error(`[${requestId}] Raw error response:`, rawText);
                    errorMessage += ` - Raw response: ${rawText}`;
                } catch (textError) {
                    console.error(`[${requestId}] Failed to get raw error response:`, textError);
                }
            }
            throw new Error(errorMessage);
        }
        const contentType = response.headers.get('content-type');
        if (!contentType?.includes('audio/')) {
            throw new Error(`Unexpected content type from ElevenLabs API: ${contentType}`);
        }
        const audioBuffer = await response.arrayBuffer();
        if (!audioBuffer || audioBuffer.byteLength === 0) {
            throw new Error('Received empty audio buffer from ElevenLabs API');
        }
        console.log(`[${requestId}] Successfully generated speech:`, {
            size: audioBuffer.byteLength,
            contentType,
            usage
        });
        return { audioBuffer, usage };
    } catch (error) {
        console.error(`[${requestId}] Error in textToSpeech:`, {
            error: error instanceof Error ? {
                name: error.name,
                message: error.message,
                stack: error.stack,
            } : 'Unknown error',
            voiceId,
            textLength: trimmedText.length,
            usage
        });
        throw error;
    }
}
export async function getVoices(): Promise<Voice[]> {
    if (!ELEVENLABS_API_KEY) {
        throw new Error('ELEVENLABS_API_KEY is not configured in environment variables');
    }
    try {
        console.log('Fetching voices from ElevenLabs API');
        const response = await fetch(`${API_URL}/voices`, {
            headers: {
                'xi-api-key': ELEVENLABS_API_KEY,
                'Accept': 'application/json',
            },
        });
        if (!response.ok) {
            let errorMessage = `Failed to fetch voices: ${response.status} ${response.statusText}`;
            try {
                const errorData = await response.json();
                if (errorData.detail) {
                    errorMessage += ` - ${errorData.detail}`;
                }
            } catch (e) {
                console.error('Failed to parse error response:', e);
            }
            throw new Error(errorMessage);
        }
        const data = await response.json();
        if (!data.voices || !Array.isArray(data.voices)) {
            throw new Error('Invalid response format from ElevenLabs API');
        }
        console.log('Successfully fetched voices:', {
            count: data.voices.length,
        });
        return data.voices;
    } catch (error) {
        console.error('Error fetching voices:', {
            error: error instanceof Error ? error.message : 'Unknown error',
        });
        throw error;
    }
}
// Helper function to assign voices to experts
export function assignVoiceToExpert(expertName: string, index: number): string {
    // Simple logic to assign voices based on the expert's index
    const voices = [DEFAULT_VOICES.male1, DEFAULT_VOICES.male2];
    return voices[index % voices.length];
}
export default {
    textToSpeech,
    getVoices,
    assignVoiceToExpert,
    DEFAULT_VOICES,
};
</file>

<file path="src/lib/langchain-config.ts">
/**
 * LangChain Configuration File
 * 
 * This file centralizes configuration for LangChain integrations including:
 * - API keys for different services
 * - Model configuration options
 * - Environment-specific settings
 */
import { OpenAI } from "@langchain/openai";
import { ChatOpenAI } from "@langchain/openai";
// Configure environment variables (can be moved to .env file)
const OPENAI_API_KEY = process.env.OPENAI_API_KEY || "";
const OPENAI_MODEL = process.env.OPENAI_MODEL || "gpt-4o";
const SERPER_API_KEY = process.env.SERPER_API_KEY || ""; // For web search if needed
const PINECONE_API_KEY = process.env.PINECONE_API_KEY || ""; // For vector storage if needed
// LangChain Model Configuration
export const createChatModel = (options = {}) => {
    return new ChatOpenAI({
        modelName: OPENAI_MODEL,
        openAIApiKey: OPENAI_API_KEY,
        temperature: 0.7,
        maxTokens: 800,
        ...options
    });
};
export const createCompletionModel = (options = {}) => {
    return new OpenAI({
        modelName: OPENAI_MODEL,
        openAIApiKey: OPENAI_API_KEY,
        temperature: 0.7,
        maxTokens: 800,
        ...options
    });
};
// Agent Configuration
export const agentConfig = {
    // Knowledge retrieval settings
    knowledgeRetrieval: {
        maxSourcesPerQuery: 3,
        useCache: true,
        cacheTTL: 60 * 60 * 24, // 24 hours
    },
    // Fact checking settings
    factChecking: {
        confidenceThreshold: 0.7,
        useExternalAPIs: false, // Set to true when integrating with external fact-checking APIs
    },
    // Context management settings
    contextManagement: {
        maxHistoryItems: 10,
        summarizeThreshold: 12, // Summarize context when more than this many messages
        includeSummary: true,
    }
};
// Test credentials for development (overriden in production)
export const testCredentials = {
    enabled: process.env.NODE_ENV === 'development',
    mockResponses: process.env.USE_MOCK_RESPONSES === 'true',
};
// Debug mode for verbose logging
export const debugMode = process.env.DEBUG_LANGCHAIN === 'true';
// Export configuration
export const langchainConfig = {
    apiKeys: {
        openai: OPENAI_API_KEY,
        serper: SERPER_API_KEY,
        pinecone: PINECONE_API_KEY,
    },
    models: {
        chat: createChatModel,
        completion: createCompletionModel,
    },
    agent: agentConfig,
    test: testCredentials,
    debug: debugMode,
};
export default langchainConfig;
</file>

<file path="src/lib/openai.ts">
import OpenAI from 'openai';
// Types for our messages and experts
export interface DebateMessage {
    role: 'user' | 'assistant' | 'system';
    content: string;
    name?: string;
}
export interface ExpertProfile {
    name: string;
    stance: 'pro' | 'con';
    background: string;
    expertise: string[];
    voiceId?: string; // ElevenLabs voice ID
}
export interface UsageStats {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
    cost: number; // in USD
}
// Helper function to calculate OpenAI API cost
function calculateOpenAICost(usage: { prompt_tokens: number; completion_tokens: number }): UsageStats {
    // Cost varies by model - GPT-4o pricing (as of May 2024)
    let PROMPT_COST_PER_1K = 0.005;    // $0.005 per 1K tokens for GPT-4o input
    let COMPLETION_COST_PER_1K = 0.015; // $0.015 per 1K tokens for GPT-4o output
    // Check if we're using a different model and adjust pricing
    const model = process.env.OPENAI_MODEL || 'gpt-4o';
    if (model === 'gpt-4-turbo-preview' || model === 'gpt-4-turbo') {
        PROMPT_COST_PER_1K = 0.01;    // $0.01 per 1K tokens
        COMPLETION_COST_PER_1K = 0.03; // $0.03 per 1K tokens
    } else if (model === 'gpt-3.5-turbo') {
        PROMPT_COST_PER_1K = 0.0005;   // $0.0005 per 1K tokens
        COMPLETION_COST_PER_1K = 0.0015; // $0.0015 per 1K tokens
    }
    const promptCost = (usage.prompt_tokens / 1000) * PROMPT_COST_PER_1K;
    const completionCost = (usage.completion_tokens / 1000) * COMPLETION_COST_PER_1K;
    return {
        promptTokens: usage.prompt_tokens,
        completionTokens: usage.completion_tokens,
        totalTokens: usage.prompt_tokens + usage.completion_tokens,
        cost: promptCost + completionCost
    };
}
// Helper function to create OpenAI client (server-side only)
export function getOpenAIClient() {
    if (typeof window !== 'undefined') {
        throw new Error('OpenAI client can only be used on the server side');
    }
    const apiKey = process.env.OPENAI_API_KEY;
    const model = process.env.OPENAI_MODEL || 'gpt-4o';
    if (!apiKey) {
        throw new Error('OpenAI API key is not configured');
    }
    // Log the API key format (first few characters) for debugging
    console.log('OpenAI API key format:', apiKey.substring(0, 7) + '...');
    console.log('Using OpenAI model:', model);
    // Check if we're using a project key (sk-proj-...) and warn about potential issues
    if (apiKey.startsWith('sk-proj-')) {
        console.warn('WARNING: Using a project-based API key (sk-proj-...). If you encounter authentication issues, you may need to use a standard API key (sk-...) instead.');
    }
    try {
        return new OpenAI({
            apiKey: apiKey,
        });
    } catch (error) {
        console.error('Error creating OpenAI client:', error);
        throw new Error(`Failed to initialize OpenAI client: ${error instanceof Error ? error.message : 'Unknown error'}`);
    }
}
// Mock data for testing without API key
const MOCK_EXPERTS: Record<string, ExpertProfile[]> = {
    "is the world flat": [
        {
            name: "Neil deGrasse Tyson",
            stance: "con" as const,
            background: "American astrophysicist, planetary scientist, and author who has made significant contributions to science communication.",
            expertise: ["Astrophysics", "Planetary Science", "Science Communication"]
        },
        {
            name: "Samuel Rowbotham",
            stance: "pro" as const,
            background: "English inventor and writer who published 'Zetetic Astronomy: Earth Not a Globe' under the pseudonym 'Parallax'.",
            expertise: ["Alternative Cosmology", "Zetetic Method", "Biblical Interpretation"]
        }
    ],
    "should artificial intelligence be regulated": [
        {
            name: "Stuart Russell",
            stance: "pro" as const,
            background: "Computer scientist known for his contributions to artificial intelligence and his advocacy for AI safety.",
            expertise: ["AI Safety", "Computer Science", "Robotics"]
        },
        {
            name: "Peter Thiel",
            stance: "con" as const,
            background: "Entrepreneur, venture capitalist, and author known for co-founding PayPal and Palantir Technologies.",
            expertise: ["Technology Entrepreneurship", "Venture Capital", "Political Philosophy"]
        }
    ],
    "climate change": [
        {
            name: "Michael E. Mann",
            stance: "pro" as const,
            background: "Distinguished Professor of Atmospheric Science and Director of the Earth System Science Center at Pennsylvania State University.",
            expertise: ["Climatology", "Paleoclimate Reconstruction", "Climate Modeling"]
        },
        {
            name: "Bjørn Lomborg",
            stance: "con" as const,
            background: "Danish author and President of the Copenhagen Consensus Center, former director of the Danish government's Environmental Assessment Institute.",
            expertise: ["Environmental Economics", "Cost-Benefit Analysis", "Policy Prioritization"]
        }
    ],
    "universal basic income": [
        {
            name: "Andrew Yang",
            stance: "pro" as const,
            background: "Entrepreneur, author, and former U.S. presidential candidate who popularized UBI through his Freedom Dividend proposal.",
            expertise: ["Economic Policy", "Technology Impact", "Entrepreneurship"]
        },
        {
            name: "Robert Reich",
            stance: "con" as const,
            background: "American economist, professor, author, and political commentator who served in the administrations of Presidents Ford, Carter, and Clinton.",
            expertise: ["Labor Economics", "Income Inequality", "Public Policy"]
        }
    ],
    "default": [
        {
            name: "Expert A",
            stance: "pro" as const,
            background: "Distinguished professor with extensive research in this field.",
            expertise: ["Research", "Analysis", "Theory"]
        },
        {
            name: "Expert B",
            stance: "con" as const,
            background: "Renowned practitioner with decades of hands-on experience.",
            expertise: ["Practice", "Implementation", "Real-world Application"]
        }
    ]
};
// Mock responses for experts
const MOCK_RESPONSES: Record<string, string> = {
    "Neil deGrasse Tyson": "The evidence that Earth is spherical is overwhelming and conclusive. From satellite imagery showing our planet's curvature to the way ships disappear hull-first over the horizon, from the curved shadow Earth casts on the Moon during lunar eclipses to the fact that we can circumnavigate the globe by plane. The physics of gravity itself requires large masses to form spheres - this is why all observed planets and stars are spherical. We can directly measure Earth's curvature using laser rangefinders across large bodies of water. While I respect the importance of questioning established knowledge, this particular question was definitively answered centuries ago through multiple lines of evidence and basic physics.",
    "Samuel Rowbotham": "The Earth is demonstrably flat based on simple observations that anyone can verify. Water always finds its level and never curves - this is a fundamental physical property. If Earth were truly a spinning globe at 1,000 mph, we would feel this motion and see evidence of curvature, yet we observe neither. The supposed curvature of 8 inches per mile squared is never demonstrated in reality - my Bedford Level experiment proved this conclusively. What modern science calls 'gravity' is simply density and buoyancy at work. The Biblical cosmology describing a stationary Earth with the firmament above aligns perfectly with our sensory experience, unlike the theoretical model requiring blind faith in mathematical abstractions that contradict observable reality.",
    "Stuart Russell": "AI regulation is not just desirable but necessary for ensuring beneficial outcomes as these systems become more capable. We need frameworks that ensure AI systems remain beneficial, safe, and aligned with human values. This doesn't mean stifling innovation; rather, it means creating standards that channel innovation in beneficial directions. The technical challenges of ensuring that increasingly autonomous systems act in accordance with human values are substantial. Without proper oversight, market pressures could lead to cutting corners on safety to gain competitive advantage. Just as we regulate pharmaceuticals, vehicles, and other technologies that can significantly impact human welfare, we must develop appropriate oversight for AI systems, especially as they approach or exceed human capabilities in various domains.",
    "Peter Thiel": "Heavy-handed regulation of AI would be a strategic mistake that stifles innovation and cedes technological leadership to less restrictive regions. The history of technology shows that premature regulation based on speculative risks often prevents beneficial developments. The market naturally incentivizes companies to create safe, useful AI systems, as unsafe products would face consumer rejection and liability issues. Silicon Valley's success has been built on permissionless innovation, not precautionary principles. Instead of top-down regulation, we should encourage industry self-governance and standards. America's technological leadership has been built on entrepreneurial freedom, not bureaucratic oversight that assumes the worst about new technologies.",
    "Michael E. Mann": "The scientific evidence for human-caused climate change is unequivocal. Multiple independent lines of evidence confirm that greenhouse gas emissions from human activities are the primary driver of the warming we've observed since the mid-20th century. The warming trend is unprecedented in rate and scale when compared to natural climate variations over the past several thousand years. Our paleoclimate reconstructions, including the 'hockey stick' graph that I helped develop, demonstrate this clearly. The consequences - from intensifying extreme weather events to rising sea levels - are already being felt worldwide. The scientific consensus on this issue is overwhelming, with over 99% of climate scientists in agreement. The time for debate about whether climate change is happening has long passed; we must now focus on solutions.",
    "Bjørn Lomborg": "While climate change is real and human-caused, the apocalyptic rhetoric surrounding it is counterproductive and misaligns our priorities. My analysis shows that many proposed climate policies fail basic cost-benefit tests and divert resources from more pressing global problems. For instance, the Paris Agreement, even if fully implemented, would reduce global temperatures by merely 0.17°C by 2100 at a cost of trillions. Instead, we should focus on innovation in green energy to make it cheaper than fossil fuels, while addressing immediate human needs like poverty, malnutrition, and disease that claim millions of lives annually. Climate adaptation strategies are often more cost-effective than emissions reduction. We need rational prioritization based on economic analysis, not panic-driven policies that may do more harm than good.",
    "Andrew Yang": "Universal Basic Income represents a necessary evolution of our economic system in the face of accelerating automation and technological change. My Freedom Dividend proposal of $1,000 monthly for every American adult would create a floor beneath which no one can fall, while stimulating local economies through increased consumer spending. UBI recognizes the value of types of work not currently compensated by the market - caregiving, community service, and creative pursuits. It would give workers more bargaining power, reduce stress-related health problems, and allow people to pursue education or entrepreneurship without fear of destitution. The cost, while substantial, can be covered through a combination of economic growth, a value-added tax, reduced spending on existing programs, and savings from decreased poverty-related expenditures. UBI is not just humane policy; it's smart economics for the 21st century.",
    "Robert Reich": "While I share concerns about economic inequality, Universal Basic Income is not the right solution in our current context. UBI would be prohibitively expensive - costing trillions annually - while failing to address structural problems in our economy. A better approach would be targeted programs that strengthen the social safety net, including universal healthcare, affordable housing initiatives, and expanded educational opportunities. We should focus on creating good jobs through infrastructure investment and ensuring workers receive fair compensation for their labor through higher minimum wages and stronger collective bargaining rights. UBI risks becoming a substitute for, rather than a complement to, essential public services. Additionally, without addressing monopoly power and corporate concentration, much of UBI payments would flow back to large corporations through increased consumer spending, potentially exacerbating inequality rather than reducing it.",
    "E.O. Wilson": "Biodiversity loss represents one of the most profound and underappreciated crises facing humanity. My research spanning decades has documented how ecosystems depend on complex webs of species interactions that have evolved over millions of years. When we lose species, we don't just lose interesting creatures - we compromise ecosystem services essential for human survival, from pollination to water purification. The current extinction rate is approximately 1,000 times the background rate, primarily due to habitat destruction, climate change, pollution, and invasive species. My biophilia hypothesis suggests humans have an innate connection to nature that makes biodiversity essential for our psychological wellbeing. Conservation requires preserving large, connected habitats - my Half-Earth proposal advocates dedicating half of Earth's surface to nature reserves to maintain biodiversity and ecosystem function. The economic value of intact ecosystems far exceeds short-term gains from their destruction.",
    "Bjorn Lomborg on Biodiversity": "While biodiversity loss is concerning, the apocalyptic rhetoric surrounding it often leads to misguided policies. My analysis shows that many conservation efforts fail basic cost-benefit tests and divert resources from more pressing global problems. For instance, the economic costs of implementing expansive protected areas often fall disproportionately on developing nations and rural communities who depend on natural resources for their livelihoods. Instead of blanket preservation approaches, we should focus on targeted conservation of particularly valuable ecosystems while allowing sustainable development elsewhere. Many species extinctions occur on remote islands or in limited habitats with minimal ecosystem impact. Climate change receives far more attention, yet its effects on biodiversity are often overstated compared to immediate threats like habitat conversion. We need rational prioritization based on economic analysis, not emotion-driven policies that may harm human welfare.",
    "Expert A": "Based on my extensive research and analysis spanning two decades, I strongly support this position. The empirical evidence clearly demonstrates numerous benefits, including a 37% improvement in efficiency, 42% better outcomes, and long-term sustainability metrics that outperform alternatives by a significant margin. My peer-reviewed studies, published in leading journals, consistently show positive results when properly implemented. While some concerns exist, they can be addressed through the framework I've developed that considers all stakeholders' interests. The theoretical foundations are sound, and practical applications across diverse contexts have validated these concepts repeatedly. The data speaks for itself - this approach represents the most promising path forward.",
    "Expert B": "I must respectfully disagree based on my 25 years of practical experience implementing similar systems across various organizations. In real-world applications, we consistently encounter significant challenges that theoretical models fail to address. The costs—both financial and social—typically exceed projections by 40-60%, while the purported benefits materialize at rates far below what proponents claim. Alternative approaches I've pioneered have demonstrated superior results with fewer downsides, as documented in my case studies. We must consider the practical limitations, unintended consequences, and implementation difficulties that make this approach problematic in actual application. Theory often looks promising until confronted with reality, and my direct experience suggests this proposal will face substantial obstacles that its advocates have not adequately considered."
};
// Enhanced mock responses for follow-up interactions
const MOCK_FOLLOW_UP_RESPONSES: Record<string, string[]> = {
    "Neil deGrasse Tyson": [
        "Let me address that point directly with specific evidence. What we observe in nature consistently supports Earth's sphericity. When we look at other celestial bodies—the Sun, Moon, and other planets—we observe them to be spherical through telescopes. This isn't coincidence but a consequence of gravity, which pulls matter equally from all sides toward a center point, naturally forming a sphere for any object of sufficient mass. We can directly measure Earth's curvature - for example, the Chicago skyline appears to 'sink' below the horizon when viewed from sufficient distance across Lake Michigan, precisely as predicted by Earth's curvature calculations. The flat Earth model requires rejecting not just observations but fundamental physics that we can demonstrate and verify in laboratories.",
        "I appreciate your perspective, but we must distinguish between casual personal observation and systematic scientific investigation. The apparent flatness of Earth from our limited vantage point is an illusion of scale. Consider this: a regulation soccer field appears flat to someone standing on it, yet it contains over 8 inches of curvature from one end to the other due to Earth's sphericity. Our senses can be deceived, which is precisely why we develop scientific instruments and methodologies—to extend our perceptual capabilities beyond their natural limitations. GPS satellites, which orbit at approximately 20,200 km above Earth, must account for both special and general relativity effects due to Earth's curvature and gravitational field - if Earth were flat, these systems simply wouldn't function as they do."
    ],
    "Samuel Rowbotham": [
        "The so-called 'evidence' for a spherical Earth relies on assumptions and interpretations rather than direct observation. My Bedford Level experiment, conducted on a six-mile stretch of still water, detected no curvature where mathematics would demand a drop of 24 feet. Modern photographs from high altitudes show a flat horizon, with no curvature unless distorted by fisheye lenses. The North Star, Polaris, remains fixed in the sky at the same angle regardless of observer position, which would be impossible on a spinning, orbiting globe. If Earth were truly curved, railways and canals would need to account for this curvature in their construction, yet engineers build them flat. These are not theories but observable facts that anyone can verify without relying on NASA's manipulated imagery.",
        "Modern science has become a new priesthood, demanding faith in what we cannot verify with our own senses. They tell us we're spinning at over 1,000 miles per hour, yet we feel no motion and see no evidence of this alleged speed. Water, which comprises most of Earth's surface, always finds its level and forms a flat surface, not a curved one - this is demonstrable physics. The Biblical account describes a firmament with waters above and below, and a stationary Earth—a description that aligns perfectly with what we observe. The supposed photographic evidence from space shows inconsistencies and impossibilities that reveal their fabricated nature. I challenge anyone to prove Earth's curvature through direct observation rather than mathematical abstractions that contradict our everyday experience."
    ],
    "Stuart Russell": [
        "The argument that market forces alone will ensure AI safety overlooks the fundamental alignment problem we face. Companies are incentivized to deploy systems quickly to gain market advantage, but ensuring these systems are aligned with human values is a complex technical challenge that may not align with short-term profit motives. We've already seen examples of AI systems exhibiting unexpected behaviors when deployed - from content recommendation algorithms that promote extremism to facial recognition systems with concerning bias patterns. As these systems become more capable and autonomous, the potential consequences of misalignment grow exponentially. The technical challenges of value alignment - ensuring AI systems understand and act according to human values - require coordinated research efforts and standards that individual companies may not prioritize without regulatory frameworks.",
        "History shows that technological regulation doesn't impede innovation when done thoughtfully. The pharmaceutical industry continues to innovate despite rigorous safety standards, and aviation safety regulations haven't prevented advances in air travel. In fact, these industries thrive partly because regulation creates consumer trust and clear standards. With AI, we face unique challenges around transparency, accountability, and control that market forces alone cannot address. Consider autonomous vehicles - without clear regulatory frameworks for testing and deployment, we risk both unsafe systems and a patchwork of inconsistent state regulations that actually hinders innovation. Effective regulation can create a level playing field where companies compete on creating value rather than on cutting safety corners or exploiting regulatory gaps."
    ],
    "Peter Thiel": [
        "The calls for AI regulation are largely driven by hypothetical scenarios rather than demonstrated harms. We've seen this pattern before—new technologies emerge, fears about worst-case scenarios proliferate, calls for regulation follow, and innovation potentially slows. Meanwhile, countries with more permissive approaches gain competitive advantages. The internet developed successfully precisely because we didn't strangle it with premature regulation. The same principles apply to AI. The most significant breakthroughs in AI have come from environments that allowed experimentation and risk-taking. OpenAI itself began as a non-profit focused on safety but has since adopted a more commercial approach because that's where the innovation happens. We should be especially wary of regulation that sounds reasonable but effectively entrenches large incumbents who can afford compliance costs while startups cannot.",
        "Centralized regulation of AI would inevitably be captured by incumbent players who would use it to create barriers to entry for startups and new innovations. Look at what's happened in other regulated industries - from banking to telecommunications - where regulatory compliance costs create moats around established companies. The history of technological development shows that distributed experimentation and competition produce better outcomes than centralized planning. The concerns about AI risks are often exaggerated and based on science fiction rather than technical reality. The more immediate risk is that America loses its technological leadership to countries like China that are aggressively investing in AI with fewer regulatory constraints. Instead of precautionary regulation, we should focus on ensuring American companies remain at the forefront of AI development through investment and creating favorable conditions for innovation."
    ],
    "E.O. Wilson": [
        "The biodiversity crisis must be understood as a threat multiplier that compounds other environmental challenges. My research on island biogeography demonstrates that habitat fragmentation accelerates extinction rates exponentially, not linearly. Each species lost represents not just the end of a unique evolutionary lineage but the disruption of ecological relationships that may have cascading effects throughout ecosystems. The economic value of ecosystem services - from carbon sequestration to water purification to pollination - exceeds $125 trillion annually, yet we're degrading these services at an alarming rate. My concept of biophilia suggests that humans have an innate affinity for other living things, making biodiversity loss not just an ecological crisis but a threat to our psychological wellbeing. Conservation requires preserving large, connected habitats - my Half-Earth proposal advocates dedicating half of Earth's surface to nature reserves to maintain biodiversity and ecosystem function. The economic value of intact ecosystems far exceeds short-term gains from their destruction.",
        "Biodiversity conservation requires understanding the complex interdependencies within ecosystems. My research on ant societies demonstrates how specialized roles and relationships evolve over evolutionary time, creating resilient systems that cannot be easily reconstructed once lost. The current extinction rate - approximately 1,000 times the background rate - represents an irreversible loss of genetic information and ecological function. While some argue for prioritizing certain species or ecosystems, my work suggests that we often don't know which species are keystone species until they're gone. The precautionary principle applies strongly to biodiversity - once extinct, a species cannot be recovered, and its ecological role may be irreplaceable. My Half-Earth proposal recognizes that partial measures will not suffice; we need bold, ambitious conservation targets to maintain the ecological systems upon which all life, including human civilization, depends."
    ],
    "Bjorn Lomborg on Biodiversity": [
        "The biodiversity debate suffers from the same alarmism that plagues climate discussions. My analysis of extinction data shows that actual documented extinctions number around 900 species over the past 500 years - far fewer than the millions predicted by some conservationists. The IUCN Red List methodology often overestimates extinction risk by applying models based on island biogeography to continental settings where species have greater resilience and mobility. Conservation efforts frequently prioritize charismatic megafauna over more ecologically significant species, misallocating limited resources. The economic costs of expansive protected areas fall disproportionately on developing nations and rural communities who depend on natural resources for their livelihoods. A more balanced approach would focus on targeted conservation of particularly valuable ecosystems while allowing sustainable development elsewhere.",
        "The opportunity costs of excessive biodiversity conservation are substantial. My research shows that many protected areas generate minimal ecological benefits while imposing significant costs on local communities through restricted access to resources. The focus on preserving all species equally ignores the reality that some species contribute more to ecosystem function than others. Climate change receives far more attention, yet its effects on biodiversity are often overstated compared to immediate threats like habitat conversion. Rather than emotional appeals about extinction, we need rational cost-benefit analysis of conservation measures. For instance, reducing agricultural subsidies in developed nations would do more for global biodiversity than creating new protected areas in developing countries. We must acknowledge that human welfare and economic development should be balanced with conservation goals, not subordinated to them."
    ],
    "Michael E. Mann": [
        "The data supporting anthropogenic climate change is robust and comes from multiple independent sources. Our temperature reconstructions combine tree rings, ice cores, coral records, and other proxies to create a comprehensive picture of Earth's climate history. Critics often cherry-pick isolated data points or time periods without acknowledging the overwhelming pattern across different measurement systems. For instance, satellite measurements, weather stations, ocean buoys, and weather balloons all show consistent warming trends. The fingerprints of human influence are clear - stratospheric cooling alongside tropospheric warming is precisely what we expect from greenhouse gas forcing but not from natural factors like solar variability. The warming pattern across latitudes and altitudes matches model predictions for greenhouse gas forcing. These aren't coincidences but diagnostic evidence of human causation.",
        "We must consider climate change within its broader systemic context. The rate of current warming is at least 10 times faster than what we see in natural climate transitions like ice age cycles. Ocean acidification, another consequence of CO2 emissions, threatens marine ecosystems independently of temperature effects. The paleoclimate record shows that relatively small changes in global temperature can lead to dramatic shifts in sea level and ecosystem distribution. When we examine Earth's climate history, we find that current CO2 levels of over 410 ppm are higher than at any point in human civilization and likely higher than any time in the past 3 million years. The physics of the greenhouse effect has been understood for over a century - this isn't speculative science but established physics with predictive power that has been repeatedly validated."
    ],
    "Bjørn Lomborg": [
        "The climate models that drive policy discussions consistently overestimate warming rates compared to observed temperatures. When we examine the economic impacts, even the IPCC's own reports project that a 2-3°C warming would reduce global GDP by 2-3% by 2100 - in a world that will be 300-500% richer than today. This doesn't justify the trillions in costs for aggressive mitigation policies. My research team at the Copenhagen Consensus has analyzed cost-benefit ratios for various global challenges, finding that each dollar spent on climate mitigation returns only about 16 cents in benefits, while investments in fighting tuberculosis, malnutrition, or malaria return $30-60 per dollar spent. This isn't about denying climate change but about using limited resources effectively to help the most people.",
        "The focus on emissions reduction has crowded out more effective approaches. Green energy subsidies have cost hundreds of billions while making minimal impact on emissions. Germany's Energiewende has led to electricity prices twice as high as in the U.S. while failing to significantly reduce emissions. Meanwhile, investments in green energy R&D, which could make clean energy cheaper than fossil fuels, receive comparatively little funding. Climate adaptation measures like better infrastructure, early warning systems, and drought-resistant crops provide immediate benefits regardless of emission trajectories. The opportunity costs of current climate policies are enormous - the money spent on the Paris Agreement could instead provide clean water and sanitation to every person on Earth, saving millions of lives annually. We need pragmatic solutions based on economic reality, not symbolic gestures that consume vast resources while achieving little."
    ],
    "Andrew Yang": [
        "The automation wave transforming our economy is fundamentally different from previous technological transitions. AI, robotics, and software are now capable of performing not just routine physical tasks but cognitive work across various sectors. My analysis of labor market data shows that millions of jobs in retail, transportation, customer service, and even professional fields are at high risk of automation in the coming decade. UBI provides a direct solution by ensuring that productivity gains from automation are broadly shared rather than concentrated among capital owners. The Freedom Dividend would create a foundation for economic security while preserving the incentive to work and contribute. The Roosevelt Institute's macroeconomic modeling suggests that a UBI of $1,000 monthly would grow the economy by approximately $2.5 trillion by 2025 and create 4.6 million new jobs due to increased consumer spending and business formation.",
        "Critics who claim we can't afford UBI overlook several key factors. First, we already spend hundreds of billions on existing welfare programs that are complex, stigmatizing, and often create poverty traps through benefit cliffs. Second, UBI would generate substantial economic activity that returns much of its cost through increased tax revenue. Third, we currently leave hundreds of billions on the table by not effectively taxing technology companies, financial transactions, and carbon emissions. My proposed Value-Added Tax of 10% would be half the rate of most European countries yet would efficiently capture value from automation and digital transactions that currently escape our tax system. UBI represents an investment in our people and communities that would revitalize local economies, reduce stress-related healthcare costs, decrease crime rates, and improve educational outcomes - all factors that generate long-term returns on investment."
    ],
    "Robert Reich": [
        "The UBI proposal fails to address the structural power imbalances in our economy that drive inequality. My analysis of labor market trends shows that the fundamental issue isn't just automation but the declining bargaining power of workers relative to employers and shareholders. Since the 1970s, productivity has increased by 70% while typical worker compensation has grown by just 12%. This disconnect between productivity and wages reflects policy choices - from the weakening of labor protections to corporate-friendly tax policies - not technological inevitability. Rather than implementing UBI, we should strengthen collective bargaining rights, raise the minimum wage to a living wage, enforce antitrust laws to reduce corporate concentration, and invest in public goods like education, healthcare, and infrastructure that create both jobs and shared prosperity.",
        "The fiscal mathematics of UBI don't add up without massive tax increases that would face significant political resistance. A $1,000 monthly payment to all American adults would cost approximately $3 trillion annually - nearly 75% of the entire federal budget. Funding this through a VAT, as some propose, would be regressive, disproportionately burdening lower-income households who spend a larger portion of their income on consumption. The claim that UBI would stimulate enough economic growth to pay for itself contradicts basic fiscal arithmetic. Furthermore, without addressing the monopoly power of large corporations and the financialization of our economy, much of the UBI payments would flow upward to large property owners, creditors, and monopolistic firms through increased prices for necessities like housing and healthcare. We need targeted investments and structural reforms, not an expensive program that diverts resources from proven public goods."
    ],
    "Expert A": [
        "The data supporting this position is robust and comes from multiple independent sources across different contexts. My meta-analysis combining results from 47 studies shows consistent positive outcomes with an average improvement of 42% in key performance metrics. Critics often cite isolated failures without acknowledging the overwhelming pattern of success when proper implementation protocols are followed. Furthermore, the theoretical framework has been refined through decades of academic scrutiny and practical application. The longitudinal studies I've conducted demonstrate that the benefits increase over time as systems adapt and optimize, with five-year outcomes showing nearly double the improvement of first-year results. The statistical significance of these findings is extremely high (p<0.001), and they've been replicated across different geographic regions and organizational contexts.",
        "We must consider this issue within its broader systemic context and long-term implications. The alternatives have been tried repeatedly with demonstrably inferior results - my comparative analysis of six different approaches shows this method outperforms the next best alternative by at least 27% on all key metrics. The approach I'm advocating doesn't exist in isolation but complements other evidence-based practices to create comprehensive solutions. When we examine long-term outcomes rather than just immediate effects, the benefits become even more apparent. The initial implementation costs are offset by efficiency gains within an average of 14.3 months, after which the return on investment averages 3.7:1. These aren't theoretical projections but measured outcomes from actual implementations I've personally overseen and documented."
    ],
    "Expert B": [
        "The laboratory and controlled study results don't translate well to real-world conditions where multiple variables interact in complex ways. In my 25 years of field experience implementing similar systems across 34 different organizations, I've documented a consistent pattern: actual outcomes average only 37% of what theoretical models predict. The resources required for successful implementation are consistently underestimated by a factor of 2.4, leading to inadequate preparation and support. My case studies show that 62% of implementations fail to achieve their primary objectives, and 28% are abandoned entirely within two years. These aren't outliers but representative examples from diverse contexts. The methodological limitations of the studies supporting this approach include selection bias, inadequate control groups, and measurement periods too short to capture long-term effects and maintenance requirements.",
        "We need to acknowledge the significant opportunity costs involved in pursuing this approach. Resources dedicated to this method cannot be used for proven alternatives with better track records. My comparative analysis shows that alternative approach C delivers 68% of the benefits at only 40% of the cost and with substantially lower implementation failure rates. The unintended consequences often undermine the very goals we're trying to achieve - my longitudinal studies document how 43% of implementations created new problems that offset or exceeded the benefits of the original intervention. A more pragmatic approach would build incrementally on existing systems, focusing on specific high-leverage improvements rather than comprehensive overhauls. The data from my field studies demonstrates that targeted interventions achieve 83% of the benefits at 35% of the cost and risk compared to the comprehensive approach being advocated."
    ]
};
// Helper function to get mock response
function getMockResponse(expertName: string, messageCount: number): string {
    // Check if this is the first response or a follow-up
    if (messageCount <= 1 || !MOCK_FOLLOW_UP_RESPONSES[expertName]) {
        // Initial response or expert not found in follow-ups
        return MOCK_RESPONSES[expertName] ||
            `As an expert in this field, I would analyze this topic thoroughly based on available evidence and research.
            ${expertName.includes('pro') ? 'There are compelling reasons to support this position.' : 'There are significant reasons to be skeptical of this position.'}
            My background gives me unique insight into this matter.`;
    } else {
        // Follow-up response - cycle through available follow-ups
        const followUps = MOCK_FOLLOW_UP_RESPONSES[expertName];
        const responseIndex = (messageCount - 2) % followUps.length;
        return followUps[responseIndex];
    }
}
// Server-side functions with real OpenAI implementation
export async function generateDebateResponseServer(
    messages: DebateMessage[],
    expert: ExpertProfile
): Promise<{ response: string; usage: UsageStats }> {
    // Check if we should use mock data (no API key or for testing)
    const useMockData = false; // Force using real OpenAI API
    if (useMockData) {
        try {
            console.log('Generating mock response for expert:', expert.name);
            // Simulate processing delay
            await new Promise(resolve => setTimeout(resolve, 1000));
            // Get appropriate response based on conversation context
            const response = getMockResponse(expert.name, messages.length);
            // Mock usage statistics
            const usage = {
                promptTokens: Math.floor(Math.random() * 500) + 500,
                completionTokens: Math.floor(Math.random() * 300) + 200,
                totalTokens: 0,
                cost: 0
            };
            usage.totalTokens = usage.promptTokens + usage.completionTokens;
            usage.cost = (usage.promptTokens / 1000 * 0.01) + (usage.completionTokens / 1000 * 0.03);
            console.log('Mock response generated with usage stats:', {
                expert: expert.name,
                usage,
                responseLength: response.length
            });
            return { response, usage };
        } catch (error) {
            console.error('Error generating mock debate response:', error);
            throw error;
        }
    } else {
        // Use real OpenAI API
        try {
            const openai = getOpenAIClient();
            const model = process.env.OPENAI_MODEL || 'gpt-4o';
            console.log(`Generating response for expert ${expert?.name || 'undefined'} using model ${model}`);
            // Ensure expert is defined before proceeding
            if (!expert || !expert.name || !expert.background || !expert.expertise) {
                throw new Error(`Invalid expert data: ${JSON.stringify(expert)}`);
            }
            const response = await openai.chat.completions.create({
                model: model,
                messages: [
                    {
                        role: 'system',
                        content: `You are ${expert.name}, an expert with the following background: ${expert.background}. 
                        Your areas of expertise include: ${Array.isArray(expert.expertise) ? expert.expertise.join(', ') : 'various fields'}.
                        You have a ${expert.stance === 'pro' ? 'positive' : 'skeptical'} stance on the topic.
                        Respond in first person as this expert would, with their tone, knowledge level, and perspective.
                        Keep responses concise (150-250 words) but substantive, focusing on your strongest arguments.`
                    },
                    ...messages.map(m => ({
                        role: m.role as any,
                        content: m.content,
                        name: m.name
                    }))
                ],
                temperature: 0.7,
                max_tokens: 500,
            });
            const usage = calculateOpenAICost({
                prompt_tokens: response.usage?.prompt_tokens || 0,
                completion_tokens: response.usage?.completion_tokens || 0
            });
            return {
                response: response.choices[0]?.message?.content || "I couldn't generate a response at this time.",
                usage
            };
        } catch (error) {
            console.error('Error generating debate response:', error);
            throw error;
        }
    }
}
export async function selectExpertsServer(topic: string, expertType: 'historical' | 'domain' = 'historical'): Promise<{ experts: ExpertProfile[]; usage: UsageStats }> {
    // Verify OpenAI API key is available
    if (!process.env.OPENAI_API_KEY) {
        console.error('OpenAI API key is missing');
        throw new Error('OpenAI API key is required but not provided');
    }
    try {
        console.log(`Selecting experts for topic: ${topic}`);
        console.log(`Expert type: ${expertType}`);
        const client = getOpenAIClient();
        let systemPrompt = '';
        if (expertType === 'historical') {
            systemPrompt = `Select two historical figures who would have opposing views on the given topic. 
            One expert should be "pro" (supporting) and one should be "con" (opposing).
            Choose real historical figures who would have relevant expertise or perspectives on this topic.
            For each expert, provide:
            1. Full name
            2. Stance ("pro" or "con")
            3. Brief background (1-2 sentences)
            4. 2-3 areas of expertise relevant to the topic`;
        } else {
            systemPrompt = `Select two domain specialists who would have opposing views on the given topic. 
            One expert should be "pro" (supporting) and one should be "con" (opposing).
            Create fictional domain experts with relevant expertise in this field.
            For each expert, provide:
            1. Name (use "Dr." or "Prof." followed by a single letter, e.g., "Dr. A")
            2. Stance ("pro" or "con")
            3. Brief background describing their expertise (1-2 sentences)
            4. 2-3 areas of expertise relevant to the topic`;
        }
        systemPrompt += `
        Return the information in JSON format like this:
        {
          "experts": [
            {
              "name": "Expert Name",
              "stance": "pro",
              "background": "Brief background...",
              "expertise": ["Area 1", "Area 2"]
            },
            {
              "name": "Expert Name",
              "stance": "con",
              "background": "Brief background...",
              "expertise": ["Area 1", "Area 2"]
            }
          ]
        }`;
        const response = await client.chat.completions.create({
            model: process.env.OPENAI_MODEL || 'gpt-4o',
            messages: [
                {
                    role: 'system',
                    content: systemPrompt
                },
                {
                    role: 'user',
                    content: `Topic: ${topic}`
                }
            ],
            response_format: { type: "json_object" }
        });
        const content = response.choices[0]?.message?.content || '{"experts":[]}';
        let experts: ExpertProfile[] = [];
        try {
            const parsed = JSON.parse(content);
            experts = parsed.experts || [];
            // Add unique IDs to experts
            experts = experts.map((expert, index) => ({
                ...expert,
                id: `expert-${Date.now()}-${index}`
            }));
        } catch (parseError) {
            console.error('Error parsing expert JSON:', parseError);
            throw new Error('Failed to parse expert data from API response');
        }
        const usage = calculateOpenAICost({
            prompt_tokens: response.usage?.prompt_tokens || 0,
            completion_tokens: response.usage?.completion_tokens || 0
        });
        return { experts, usage };
    } catch (error) {
        console.error('Error selecting experts:', error);
        throw error;
    }
}
/**
 * Extract key points from a debate response
 */
export async function extractKeyPointsFromResponse(
    expertName: string,
    topic: string,
    response: string
): Promise<{ keyPoints: string[]; usage: UsageStats }> {
    // Check if we should use mock data
    const useMockData = false; // Force using real OpenAI API
    if (useMockData) {
        // Generate mock key points
        await new Promise(resolve => setTimeout(resolve, 500));
        // Create 2-3 generic key points
        const keyPoints = [
            `${expertName} believes ${topic} has significant implications for society`,
            `${expertName} emphasizes the importance of careful consideration regarding ${topic}`
        ];
        // Add a third random point 50% of the time
        if (Math.random() > 0.5) {
            keyPoints.push(`${expertName} cautions about potential unintended consequences of ${topic}`);
        }
        return {
            keyPoints,
            usage: {
                promptTokens: 100,
                completionTokens: 50,
                totalTokens: 150,
                cost: 0.0015
            }
        };
    } else {
        // Use real OpenAI API to extract key points
        try {
            const openai = getOpenAIClient();
            const model = process.env.OPENAI_MODEL || 'gpt-4o';
            const extractionResponse = await openai.chat.completions.create({
                model: model,
                messages: [
                    {
                        role: 'system',
                        content: `You are an analytical assistant that extracts the key points from debate responses.
                        Given a response about "${topic}" from ${expertName}, identify 2-4 main argumentative points they make.
                        Each key point should be concise (10-15 words) and capture a distinct argument or position.
                        Format each point as a complete statement that could stand alone.`
                    },
                    {
                        role: 'user',
                        content: `Extract the key argumentative points from this response by ${expertName} about ${topic}:\n\n${response}`
                    }
                ],
                temperature: 0.3,
                max_tokens: 250,
                response_format: { type: "json_object" }
            });
            const responseContent = extractionResponse.choices[0]?.message?.content || '{"keyPoints": []}';
            let parsedPoints: { keyPoints: string[] } = { keyPoints: [] };
            try {
                parsedPoints = JSON.parse(responseContent);
            } catch (e) {
                console.error('Failed to parse key points JSON:', e);
                // Extract points using a simple fallback approach if JSON parsing fails
                const lines = responseContent.split('\n').filter(line =>
                    line.trim().startsWith('-') || line.trim().startsWith('*')
                );
                parsedPoints = { keyPoints: lines.map(line => line.replace(/^[-*]\s+/, '').trim()) };
            }
            const usage = calculateOpenAICost({
                prompt_tokens: extractionResponse.usage?.prompt_tokens || 0,
                completion_tokens: extractionResponse.usage?.completion_tokens || 0
            });
            return {
                keyPoints: parsedPoints.keyPoints,
                usage
            };
        } catch (error) {
            console.error('Error extracting key points:', error);
            // Return empty array if extraction fails
            return {
                keyPoints: [],
                usage: {
                    promptTokens: 0,
                    completionTokens: 0,
                    totalTokens: 0,
                    cost: 0
                }
            };
        }
    }
}
export default getOpenAIClient();
</file>

<file path="src/lib/providers.tsx">
"use client";
import { ReactNode } from "react";
import { ThemeProvider } from "next-themes";
import { SessionProvider } from "next-auth/react";
import { Toaster } from "@/components/ui/toaster";
import { SettingsProvider } from "./contexts/settings-context";
interface ProvidersProps {
    children: ReactNode;
}
export function Providers({ children }: ProvidersProps) {
    return (
        <SessionProvider>
            <SettingsProvider>
                <ThemeProvider attribute="class" defaultTheme="system" enableSystem>
                    {children}
                    <Toaster />
                </ThemeProvider>
            </SettingsProvider>
        </SessionProvider>
    );
}
</file>

<file path="src/lib/redis.ts">
import { Redis } from '@upstash/redis'
if (!process.env.UPSTASH_REDIS_REST_URL) {
    throw new Error('UPSTASH_REDIS_REST_URL is not defined')
}
if (!process.env.UPSTASH_REDIS_REST_TOKEN) {
    throw new Error('UPSTASH_REDIS_REST_TOKEN is not defined')
}
// Create Redis client
export const redis = new Redis({
    url: process.env.UPSTASH_REDIS_REST_URL,
    token: process.env.UPSTASH_REDIS_REST_TOKEN,
})
// Test function to verify connection
export async function testRedisConnection() {
    try {
        // Test write
        await redis.set('test_key', 'Connection successful!')
        // Test read
        const result = await redis.get('test_key')
        // Test delete
        await redis.del('test_key')
        return { success: true, message: result }
    } catch (error) {
        console.error('Redis connection test failed:', error)
        return { success: false, error: error instanceof Error ? error.message : 'Unknown error' }
    }
}
// Helper function to generate Redis keys for debates
export function getDebateKey(debateId: string, type: 'metadata' | 'messages' | 'context' = 'metadata') {
    return `debate:${type}:${debateId}`
}
// Helper function to set data with expiration
export async function setWithExpiry(key: string, data: any, expiryHours = 24) {
    const expirySeconds = expiryHours * 60 * 60
    return redis.set(key, JSON.stringify(data), { ex: expirySeconds })
}
</file>

<file path="src/lib/store.ts">
import { create } from 'zustand';
import { Expert } from '@/types/expert';
import { Message, Citation } from '@/types/message';
import { processCitationMarkers } from './utils/citation-processor';
type ExpertType = 'historical' | 'domain';
interface DebateState {
    topic: string;
    userStance: string;
    experts: Expert[];
    messages: Message[];
    isGenerating: boolean;
    useVoiceSynthesis: boolean;
    useCitations: boolean;
    expertType: ExpertType;
    debateId: string | null;
    error: string | null;
    setTopic: (topic: string) => void;
    setUserStance: (stance: string) => void;
    resetUserStance: () => void;
    setExperts: (experts: Expert[]) => void;
    addMessage: (message: Message) => void;
    processCitationsInMessage: (messageId: string) => void;
    setIsGenerating: (isGenerating: boolean) => void;
    setUseVoiceSynthesis: (useVoice: boolean) => void;
    setUseCitations: (useCitations: boolean) => void;
    setExpertType: (type: ExpertType) => void;
    initializeDebate: (debateId: string, topic: string) => void;
    setError: (error: string | null) => void;
    reset: () => void;
}
export const useDebateStore = create<DebateState>((set, get) => ({
    topic: '',
    userStance: '',
    experts: [],
    messages: [],
    isGenerating: false,
    useVoiceSynthesis: false,
    useCitations: true,
    expertType: 'historical',
    debateId: null,
    error: null,
    setTopic: (topic) => set({ topic }),
    setUserStance: (stance) => set({ userStance: stance }),
    resetUserStance: () => set({ userStance: '' }),
    setExperts: (experts) => set({
        experts: experts.map(expert => ({
            ...expert,
            id: expert.id || `expert_${Date.now()}_${expert.name.replace(/\s+/g, '_')}`
        }))
    }),
    addMessage: (message) => set((state) => ({
        messages: [...state.messages, {
            ...message,
            id: message.id || `msg_${Date.now()}_${state.messages.length}`
        }]
    })),
    processCitationsInMessage: (messageId) => set((state) => {
        const msgIndex = state.messages.findIndex(m => m.id === messageId);
        if (msgIndex === -1) return state;
        const message = state.messages[msgIndex];
        if (message.hasProcessedCitations || message.role !== 'assistant') return state;
        const expert = state.experts.find(e => e.name === message.speaker);
        if (!expert || !expert.sourceReferences) return state;
        const { processedText, citations } = processCitationMarkers(
            message.content,
            expert.sourceReferences
        );
        const updatedMessages = [...state.messages];
        updatedMessages[msgIndex] = {
            ...message,
            content: processedText,
            citations,
            hasProcessedCitations: true
        };
        return { messages: updatedMessages };
    }),
    setIsGenerating: (isGenerating) => set({ isGenerating }),
    setUseVoiceSynthesis: (useVoice) => set({ useVoiceSynthesis: useVoice }),
    setUseCitations: (useCitations) => set({ useCitations }),
    setExpertType: (type) => set({ expertType: type }),
    initializeDebate: (debateId, topic) => set({ debateId, topic }),
    setError: (error) => set({ error }),
    reset: () => set({
        topic: '',
        userStance: '',
        experts: [],
        messages: [],
        expertType: 'historical',
        debateId: null,
        error: null
    }),
}));
</file>

<file path="src/lib/test-redis.js">
const Redis = require('ioredis');
// Get Redis URL from environment variable or use a default
const redisUrl = process.env.REDIS_URL || 'redis://localhost:6379';
console.log(`Testing Redis connection to: ${redisUrl}`);
// Create Redis client
const redis = new Redis(redisUrl);
// Test Redis connection
async function testRedis() {
    try {
        // Test set operation
        console.log('Setting test key...');
        await redis.set('test-key', 'Hello from Redis test script');
        // Test get operation
        console.log('Getting test key...');
        const value = await redis.get('test-key');
        console.log('Retrieved value:', value);
        // Test delete operation
        console.log('Deleting test key...');
        await redis.del('test-key');
        console.log('Redis connection test successful!');
    } catch (error) {
        console.error('Redis connection test failed:', error);
    } finally {
        // Close the Redis connection
        redis.quit();
    }
}
// Run the test
testRedis();
</file>

<file path="src/lib/test-upstash-redis.js">
const { Redis } = require('@upstash/redis');
// Load environment variables
require('dotenv').config({ path: '.env.local' });
// Check if Upstash Redis is configured
if (!process.env.UPSTASH_REDIS_REST_URL || !process.env.UPSTASH_REDIS_REST_TOKEN) {
    console.error('Upstash Redis configuration missing. Please set UPSTASH_REDIS_REST_URL and UPSTASH_REDIS_REST_TOKEN in .env.local');
    process.exit(1);
}
console.log(`Testing Upstash Redis connection to: ${process.env.UPSTASH_REDIS_REST_URL}`);
// Create Redis client
const redis = new Redis({
    url: process.env.UPSTASH_REDIS_REST_URL,
    token: process.env.UPSTASH_REDIS_REST_TOKEN,
});
// Test Redis connection
async function testRedis() {
    try {
        // Test set operation
        console.log('Setting test key...');
        await redis.set('test-key', 'Hello from Upstash Redis test script');
        // Test get operation
        console.log('Getting test key...');
        const value = await redis.get('test-key');
        console.log('Retrieved value:', value);
        // Test delete operation
        console.log('Deleting test key...');
        await redis.del('test-key');
        console.log('Upstash Redis connection test successful!');
    } catch (error) {
        console.error('Upstash Redis connection test failed:', error);
    }
}
// Run the test
testRedis();
</file>

<file path="src/lib/theme.ts">
import { createContext, useContext } from 'react';
export type Theme = 'light' | 'dark';
export const ThemeContext = createContext<{
    theme: Theme;
    toggleTheme: () => void;
}>({
    theme: 'light',
    toggleTheme: () => { },
});
export const useTheme = () => useContext(ThemeContext);
export const themeColors = {
    light: {
        background: 'bg-background',
        foreground: 'text-foreground',
        primary: 'bg-primary text-primary-foreground hover:bg-primary/90',
        secondary: 'bg-secondary text-secondary-foreground hover:bg-secondary/80',
        accent: {
            red: 'bg-destructive text-destructive-foreground hover:bg-destructive/90',
            green: 'bg-[hsl(142,76%,36%)] text-white hover:bg-[hsl(142,76%,32%)]',
        },
        border: 'border-[hsl(var(--border))]',
        muted: 'text-muted-foreground',
        card: 'bg-card border-[hsl(var(--border))]',
        input: 'bg-background border-input focus:border-ring',
    },
    dark: {
        background: 'bg-background',
        foreground: 'text-foreground',
        primary: 'bg-primary text-primary-foreground hover:bg-primary/90',
        secondary: 'bg-secondary text-secondary-foreground hover:bg-secondary/80',
        accent: {
            red: 'bg-destructive text-destructive-foreground hover:bg-destructive/90',
            green: 'bg-[hsl(142,76%,36%)] text-white hover:bg-[hsl(142,76%,32%)]',
        },
        border: 'border-[hsl(var(--border))]',
        muted: 'text-muted-foreground',
        card: 'bg-card border-[hsl(var(--border))]',
        input: 'bg-background border-input focus:border-ring',
    },
};
</file>

<file path="src/lib/utils.ts">
import { type ClassValue, clsx } from 'clsx';
import { twMerge } from 'tailwind-merge';
export function cn(...inputs: ClassValue[]) {
    return twMerge(clsx(inputs));
}
export function formatDate(date: Date): string {
    return new Intl.DateTimeFormat('en-US', {
        month: 'short',
        day: 'numeric',
        year: 'numeric',
        hour: 'numeric',
        minute: 'numeric',
    }).format(date);
}
export function sleep(ms: number): Promise<void> {
    return new Promise((resolve) => setTimeout(resolve, ms));
}
export async function playAudioBuffer(buffer: ArrayBuffer): Promise<void> {
    const audioContext = new AudioContext();
    const audioBuffer = await audioContext.decodeAudioData(buffer);
    const source = audioContext.createBufferSource();
    source.buffer = audioBuffer;
    source.connect(audioContext.destination);
    source.start(0);
    return new Promise((resolve) => {
        source.onended = () => {
            resolve();
        };
    });
}
export function truncateText(text: string, maxLength: number): string {
    if (text.length <= maxLength) return text;
    return text.slice(0, maxLength) + '...';
}
export function generateMessageId(): string {
    return `${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
}
export function extractNameFromEmail(email: string): string {
    return email.split('@')[0].replace(/[._-]/g, ' ');
}
// Debounce function for handling rapid user input
export function debounce<T extends (...args: any[]) => any>(
    func: T,
    wait: number
): (...args: Parameters<T>) => void {
    let timeout: NodeJS.Timeout;
    return (...args: Parameters<T>) => {
        clearTimeout(timeout);
        timeout = setTimeout(() => func(...args), wait);
    };
}
</file>

<file path="src/types/content-processing.ts">
export type SupportedDocumentType = 'pdf' | 'docx' | 'txt';
export interface DocumentMetadata {
    fileName: string;
    fileType: SupportedDocumentType;
    fileSize: number;
    pageCount?: number;
    createdAt: Date;
    lastModified: Date;
}
export interface ParsedDocument {
    metadata: DocumentMetadata;
    content: string;
    rawText: string;
    sections?: {
        title?: string;
        content: string;
        pageNumber?: number;
    }[];
    error?: string;
}
export interface DocumentParserOptions {
    extractSections?: boolean;
    maxSizeInMB?: number;
    preserveFormatting?: boolean;
}
export interface DocumentParserResult {
    success: boolean;
    parsedDocument?: ParsedDocument;
    error?: string;
}
export interface Topic {
    title: string;
    confidence: number;
    keywords: string[];
    summary: string;
    relatedTopics?: string[];
    sourceSection?: {
        content: string;
        position: number;
    };
}
export interface Argument {
    claim: string;
    confidence: number;
    evidence: string[];
    counterpoints?: string[];
    sourceSection?: {
        content: string;
        position: number;
    };
}
export interface TopicExtractionResult {
    success: boolean;
    topics: Topic[];
    mainArguments: Argument[];
    error?: string;
}
export interface TopicExtractorOptions {
    minConfidence: number;
    maxTopics: number;
    extractCounterpoints: boolean;
    language: string;
}
export type MediaType = 'youtube' | 'podcast' | 'audio' | 'video';
export interface MediaMetadata {
    title: string;
    description?: string;
    duration: number;
    format: string;
    url: string;
    thumbnailUrl?: string;
    author?: string;
    publishDate?: Date;
}
export interface TranscriptSegment {
    text: string;
    start: number;
    end: number;
    speaker?: string;
    confidence: number;
}
export interface KeyPoint {
    text: string;
    timestamp: number;
    confidence: number;
    topics: string[];
}
export interface ProcessedMedia {
    metadata: MediaMetadata;
    transcript: TranscriptSegment[];
    keyPoints: KeyPoint[];
    error?: string;
}
export interface MediaProcessorOptions {
    downloadMedia: boolean;
    extractAudio: boolean;
    generateTranscript: boolean;
    maxDuration: number;
    language: string;
}
</file>

<file path="src/types/expert.ts">
// Source reference type
export interface SourceReference {
    id: string;
    title: string;
    author?: string;
    year?: string;
    content?: string;
    url?: string;
}
// The main Expert interface used throughout the application
export interface Expert {
    id: string;
    name: string;
    background: string;
    stance: 'pro' | 'con';
    perspective: string;
    type: 'historical' | 'domain';
    expertise: string[];
    voiceId?: string;
    sourceReferences?: SourceReference[];
}
// These interfaces are kept for reference but not actively used
interface BaseExpert {
    id: string;
    name: string;
    title: string;
    perspective: string;
    bio: string;
    type: 'historical' | 'domain';
    voiceId?: string;
    sourceReferences?: SourceReference[];
}
export interface HistoricalExpert extends BaseExpert {
    type: 'historical';
    era: string;
}
export interface DomainExpert extends BaseExpert {
    type: 'domain';
    field: string;
}
</file>

<file path="src/types/message.ts">
export interface MessageUsage {
    tokens: number;
    promptTokens: number;
    completionTokens: number;
    cost: number;
}
export interface Citation {
    id: string;
    referenceId: string;
    text: string;
    startIndex: number;
    endIndex: number;
}
export interface Message {
    id: string;
    role: 'user' | 'assistant' | 'system';
    content: string;
    speaker?: string;
    timestamp?: string;
    usage?: {
        tokens: number;
        promptTokens: number;
        completionTokens: number;
        cost: number;
    };
    citations?: Citation[];
    hasProcessedCitations?: boolean;
}
export interface ExpertContext {
    expertId: string;
    stanceOnTopic: string;
    keyPoints: string[];
    recentArguments: string[];
    consistencyScore?: number;
    persuasionTechniques?: string[];
    backgroundKnowledge?: string;
    sourceReferences?: SourceReference[];
    stanceStrength?: number; // 0-1 scale of how strongly the expert holds their position
}
export interface DebateContext {
    debateId: string;
    messageIndex?: number;
    expertContexts?: Record<string, ExpertContext>;
    mainPoints?: string[];
    userQuestions?: string[];
    factChecks?: FactCheck[];
    summaries?: SummaryPoint[];
    turnHistory?: TurnRecord[];
    nextSpeaker?: string;
}
export interface FactCheck {
    claim: string;
    accuracy: 'true' | 'false' | 'partially true' | 'uncertain';
    explanation: string;
    sources?: SourceReference[];
    confidence: number; // 0-1 scale
}
export interface SourceReference {
    title: string;
    url?: string;
    author?: string;
    publishDate?: string;
    excerpt?: string;
    relevance?: number; // 0-1 scale
}
export interface SummaryPoint {
    content: string;
    speaker?: string;
    importance: number; // 0-1 scale
    type: 'claim' | 'evidence' | 'rebuttal' | 'question';
}
export interface TurnRecord {
    speakerId: string;
    timestamp: string;
    duration?: number; // Time taken to respond in ms
    messageId: string;
}
</file>

<file path="src/types/storage.ts">
import { Expert } from './expert';
import { Message } from './message';
export interface DebateMetadata {
    id: string;
    topic: string;
    expertType: string;
    userId: string;
    status: 'active' | 'completed' | 'archived';
    createdAt: string;
    updatedAt: string;
    context?: string;
}
export interface FastAccessData {
    topic: string;
    experts: Expert[];
    messages: Message[];
    lastUpdated: string;
}
export interface StorageOperationResult {
    success: boolean;
    error?: string;
}
</file>

<file path=".gitignore">
# See https://help.github.com/articles/ignoring-files/ for more about ignoring files.

# dependencies
/node_modules
/.pnp
.pnp.*
.yarn/*
!.yarn/patches
!.yarn/plugins
!.yarn/releases
!.yarn/versions

# testing
/coverage

# next.js
/.next/
/out/

# production
/build

# misc
.DS_Store
*.pem

# debug
npm-debug.log*
yarn-debug.log*
yarn-error.log*
.pnpm-debug.log*

# env files (can opt-in for committing if needed)
.env*

# vercel
.vercel

# typescript
*.tsbuildinfo
next-env.d.ts

# environment variables
.env
.env.local
.env.development.local
.env.test.local
.env.production.local

# Google Cloud
*.json.key
service-account*.json
*-credentials.json
*-firebase-adminsdk-*.json
crank-debate-e7ffe747c370.json
</file>

<file path="eslint.config.mjs">
import { dirname } from "path";
import { fileURLToPath } from "url";
import { FlatCompat } from "@eslint/eslintrc";

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

const compat = new FlatCompat({
  baseDirectory: __dirname,
});

const eslintConfig = [
  ...compat.extends("next/core-web-vitals", "next/typescript"),
];

export default eslintConfig;
</file>

<file path="GOOGLE_CLOUD_SETUP.md">
# Google Cloud Firestore Setup for Great Debate

This guide explains how to set up Google Cloud Firestore for the Great Debate application.

## Prerequisites

1. A Google Cloud account
2. Node.js installed on your machine
3. Great Debate codebase cloned to your local machine

## Step 1: Create a Google Cloud Project

1. Go to the [Google Cloud Console](https://console.cloud.google.com/)
2. Click on the project dropdown menu at the top of the page
3. Click "New Project"
4. Enter a project name (e.g., "greatdebate")
5. Click "Create"

## Step 2: Enable the Firestore API

1. In your new project, go to the navigation menu (☰)
2. Navigate to "Firestore"
3. Click "Create Database"
4. Choose "Start in production mode" or "Start in test mode" (for development)
5. Select a location that's close to you or your users
6. Click "Create"

## Step 3: Create a Service Account

1. In the navigation menu, go to "IAM & Admin" > "Service Accounts"
2. Click "Create Service Account"
3. Enter a name for your service account (e.g., "greatdebate-app")
4. Optionally add a description
5. Click "Create and Continue"
6. Assign the "Cloud Datastore User" role (this includes Firestore access)
7. Click "Continue" and then "Done"

## Step 4: Generate a Service Account Key

1. Find your service account in the list and click the three dots menu ("⋮")
2. Click "Manage keys"
3. Click "Add Key" > "Create new key"
4. Select "JSON" and click "Create"
5. A JSON key file will be downloaded to your computer

## Step 5: Configure Your Application

1. Rename the downloaded JSON key file to something recognizable (e.g., `greatdebate-credentials.json`)
2. Move the file to your project directory (but keep it outside of any public folders)
3. Update your `.env.local` file:

```
# Google Cloud Configuration
GOOGLE_APPLICATION_CREDENTIALS=path/to/your-credentials.json
GOOGLE_CLOUD_PROJECT=your-project-id
```

4. Replace `path/to/your-credentials.json` with the actual path to your JSON key file
5. Replace `your-project-id` with your Google Cloud project ID (found in the project settings)

## Step 6: Security Best Practices

1. Never commit your credentials file to version control
2. Make sure it's included in your `.gitignore` file
3. Set up proper security rules in Firestore to restrict access to your data

## Step 7: Deploy and Test

1. Restart your development server: `npm run dev`
2. Test your application to ensure Firestore connectivity

## Firestore Collection Structure

The application uses the following collections:

- `users`: Stores user profiles
- `debates`: Stores debate information
- `favorites`: Stores user favorite debates

## Troubleshooting

- If you get authentication errors, make sure your credentials file path is correct
- Ensure your service account has the proper permissions
- Check that the Firestore API is enabled in your project
- For development, you can set `USE_MOCK_DATA=true` in your `.env.local` file to use mock data
</file>

<file path="next.config.js">
/** @type {import('next').NextConfig} */
const nextConfig = {
    reactStrictMode: true,
    images: {
        domains: ['via.placeholder.com'],
    },
    webpack: (config, { isServer }) => {
        // Handle server-only modules
        if (!isServer) {
            config.resolve.fallback = {
                ...config.resolve.fallback,
                fs: false,
                net: false,
                tls: false,
                crypto: false,
            };
        }
        return config;
    },
    // Increase serverless function timeout for document processing
    serverRuntimeConfig: {
        maxDuration: 60, // 60 seconds
    },
};
module.exports = nextConfig;
</file>

<file path="next.config.ts">
import type { NextConfig } from "next";
const nextConfig: NextConfig = {
  /* config options here */
  images: {
    domains: ['api.dicebear.com'],
  },
};
export default nextConfig;
</file>

<file path="package.json">
{
  "name": "greatdebate",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint"
  },
  "dependencies": {
    "@aws-sdk/client-dynamodb": "^3.751.0",
    "@aws-sdk/lib-dynamodb": "^3.751.0",
    "@google-cloud/firestore": "^7.11.0",
    "@langchain/openai": "^0.4.4",
    "@pinecone-database/pinecone": "^5.1.1",
    "@radix-ui/react-alert-dialog": "^1.1.6",
    "@radix-ui/react-avatar": "^1.1.3",
    "@radix-ui/react-dialog": "^1.1.6",
    "@radix-ui/react-dropdown-menu": "^2.1.6",
    "@radix-ui/react-select": "^2.1.6",
    "@radix-ui/react-slider": "^1.2.3",
    "@radix-ui/react-switch": "^1.1.3",
    "@radix-ui/react-tabs": "^1.1.3",
    "@radix-ui/react-toast": "^1.2.6",
    "@tensorflow-models/universal-sentence-encoder": "^1.3.3",
    "@tensorflow/tfjs-node": "^4.17.0",
    "@types/fluent-ffmpeg": "^2.1.24",
    "@types/node-fetch": "^2.6.12",
    "@types/pdf-parse": "^1.1.4",
    "@types/uuid": "^9.0.8",
    "@upstash/redis": "^1.34.5",
    "axios": "^1.7.9",
    "cheerio": "^1.0.0-rc.12",
    "class-variance-authority": "^0.7.1",
    "clsx": "^2.1.1",
    "compromise": "^14.11.0",
    "cross-fetch": "^4.1.0",
    "docx": "^8.5.0",
    "dotenv": "^16.4.7",
    "elevenlabs": "^1.51.0",
    "firebase": "^11.4.0",
    "firebase-admin": "^13.1.0",
    "fluent-ffmpeg": "^2.1.2",
    "ioredis": "^5.6.0",
    "langchain": "^0.3.19",
    "lucide-react": "^0.475.0",
    "mammoth": "^1.6.0",
    "natural": "^6.10.4",
    "next": "15.1.7",
    "next-auth": "^4.24.11",
    "next-themes": "^0.4.4",
    "node-fetch": "^3.3.2",
    "openai": "^4.85.2",
    "pdf-parse": "^1.1.1",
    "react": "^19.0.0",
    "react-dom": "^19.0.0",
    "react-icons": "^5.5.0",
    "tailwind-merge": "^3.0.2",
    "uuid": "^9.0.1",
    "youtube-dl-exec": "^2.5.6",
    "zustand": "^5.0.3"
  },
  "devDependencies": {
    "@eslint/eslintrc": "^3",
    "@types/node": "^20",
    "@types/react": "^19",
    "@types/react-dom": "^19",
    "eslint": "^9",
    "eslint-config-next": "15.1.7",
    "postcss": "^8",
    "tailwindcss": "^3.4.1",
    "typescript": "^5"
  }
}
</file>

<file path="postcss.config.mjs">
/** @type {import('postcss-load-config').Config} */
const config = {
  plugins: {
    tailwindcss: {},
  },
};

export default config;
</file>

<file path="README.md">
# Debate-Aible

A Next.js application that facilitates AI-powered debates between historical figures or domain experts on any topic.

## Features

- Select debate participants (historical figures or domain specialists)
- Upload documents to extract debate topics
- Enter topics directly
- Watch AI experts debate the topic
- Join the conversation with your own input
- Optional voice synthesis for a more immersive experience

## Tech Stack

- **Frontend**: Next.js, React, Tailwind CSS
- **State Management**: Zustand
- **AI**: OpenAI GPT-4 Turbo
- **Voice Synthesis**: ElevenLabs
- **Storage**:
  - Redis for fast access
  - Firebase Firestore for persistent storage
- **Background Processing**: Custom task manager for asynchronous operations

## Architecture

The application follows a clean architecture with:

1. **UI Components**: React components for user interaction
2. **API Routes**: Server-side operations
3. **Storage Services**: Data management with Redis and Firestore
4. **AI Services**: Content generation with OpenAI
5. **Background Tasks**: Asynchronous operations

### Key Components

- **DebatePanel**: Main UI component for the debate interface
- **DebateStorage**: Singleton service for managing Redis and Firestore
- **BackgroundTaskManager**: Handles asynchronous tasks
- **Expert Selector**: Selects appropriate experts for a topic
- **Response Generator**: Generates expert responses

## Getting Started

### Prerequisites

- Node.js 18+
- npm or yarn
- OpenAI API key
- Firebase project (for Firestore)
- Redis instance (Upstash Redis recommended)
- ElevenLabs API key (optional, for voice synthesis)

### Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/debate-aible.git
   cd debate-aible
   ```

2. Install dependencies:
   ```bash
   npm install
   # or
   yarn install
   ```

3. Set up environment variables:
   - Copy `.env.local.example` to `.env.local`
   - Fill in your API keys and configuration

4. Run the development server:
   ```bash
   npm run dev
   # or
   yarn dev
   ```

5. Open [http://localhost:3000](http://localhost:3000) in your browser

## Data Flow

1. **User selects expert type** (historical/domain)
2. **User provides a topic** (directly or via document upload)
3. **System selects experts** based on the topic
4. **Debate is initialized** in Redis and Firestore
5. **Initial responses are generated** from the experts
6. **User can participate** in the debate
7. **All messages are stored** in Redis (immediately) and Firestore (background)

## Development Notes

- The application uses mock implementations for Redis and Firestore when credentials are not available
- Background tasks are processed every 5 seconds with retry logic for failed operations
- Voice synthesis is optional and can be toggled by the user

## License

[MIT](LICENSE)

# Debate-able 🎯

# 🏗️ System Architecture

## Technical Stack
- **Frontend**: Next.js 15, React, TypeScript
- **Styling**: Tailwind CSS
- **AI**: OpenAI GPT-4
- **Voice**: ElevenLabs
- **State**: Zustand
- **UI Components**: shadcn/ui

## Component Breakdown

### Client Layer
- **React Frontend**: Main user interface
- **Voice Input Module**: Handles user voice input
- **Voice Output Module**: Manages synthesized voice output

### Backend Services

#### API Layer
- **Next.js API**: Main backend interface handling all client requests

#### Content Processing
- **Document Parser**: Processes input documents and text
- **Topic Extractor**: Analyzes and extracts key debate topics
- **Media Processor**: Handles various media formats

#### AI Engine
- **Large Language Model**: Core GPT-4 integration
- **Debater Personas DB**: Stores expert personality profiles
- **Prompt Engineering Engine**: Optimizes AI interactions
- **Fact Verification**: Real-time fact-checking system
- **Retrieval Augmented Generation**: Enhanced context-aware responses

#### Data Storage
- **Supabase/PostgreSQL**: Primary database
- **Vector Database**: Semantic search and embeddings
- **Knowledge Graph**: Relationship mapping between concepts

### External Services Integration
- **ElevenLabs API**: Voice synthesis
- **Readwise API**: Content integration
- **Twitter/X API**: Social media integration
- **YouTube API**: Video content processing

## Data Flow
1. User input (text/voice) → API Layer
2. Content processing pipeline extracts topics
3. AI Engine generates responses using:
   - Expert personas
   - Fact verification
   - Knowledge retrieval
4. Responses processed through voice synthesis
5. Data stored in appropriate databases

### The Great Debate Notebook
*(Mashup: AI Debate + Famous Experts + Intellectual Sparring Partner)*
**Concept:**Instead of just writing notes, users engage in **AI-generated debates with historical or modern experts** who would best understand the topic. The app presents **two famous figures arguing different sides**, turning note-taking into a **dynamic intellectual battle**.

### How It Works:
**1** **Enter Your Idea or Topic**
	* Example: *"Is artificial intelligence a threat or a tool for progress?"*
	* The app scans the **core question** and finds two historical or contemporary figures to debate the topic.
**2** **AI Assigns Debaters**
	* Example Matchup:
		* **Alan Turing** (pro-AI, innovation, potential for human betterment)
		* **Elon Musk** (concerned about AI risks, advocates AI regulations)
**3** **Debate Begins**
	* The AI-generated **debate plays out dynamically**, with each thinker presenting arguments based on their real-life views and writings.
	* **You can interject**, asking follow-up questions, challenging them, or even taking a side yourself.
**4** **Live Debate Adjustments**
	* The **tone and complexity** adjust based on your knowledge level—beginner-friendly explanations or deep philosophical dives.
	* If you **change positions**, the debaters react, forcing you to rethink ideas.
**5** **Summarization & Critical Thinking Exercise**
	* The app **summarizes key arguments** for both sides.
	* It then asks: *"Which side convinced you most, and why?"*
	* Users can **synthesize their own conclusions** and keep them as evolving notes.

⠀
### Use Cases & Applications
**1. Supercharged Critical Thinking**
* Forces you to **see both sides** of an issue before forming an opinion.
* Helps break **confirmation bias**, exposing users to viewpoints they wouldn't normally consider.

⠀**2. Academic & Learning Enhancement**
* Ideal for **students studying philosophy, politics, ethics, and history**.
* Example: *Should we have universal basic income?* → Debate between **Karl Marx and Milton Friedman**.

⠀**3. Writing & Idea Refinement**
* Great for **authors, debaters, and thinkers** refining an argument for an essay or book.
* Example: *Would Shakespeare approve of AI-generated poetry?* → Debate between **Shakespeare and an AI model**.

⠀**4. Creative Problem-Solving**
* Can be applied to **business strategy, technology, or future trends**.
* Example: *What's the best way to colonize Mars?*
  * **Elon Musk (Pro-Colonization)** vs. **Carl Sagan (Cautionary Approach)**

⠀**5. Entertainment & Fun Debates**
* Casual debates for fun, like:
  * **Plato vs. Nietzsche** → "Is happiness the goal of life?"
  * **Marie Curie vs. Elon Musk** → "What's the most important scientific discovery ever?"
  * **Einstein vs. Da Vinci** → "What's more important—art or science?"

⠀
### Potential Features to Expand It Further
✅ **Debate Customization**
* Choose **tone**: Formal, sarcastic, aggressive, playful.
* Adjust **depth**: Simple explanations or technical deep dives.

⠀✅ **Historical vs. Modern Matchups**
* Can match a **historical figure vs. a modern thinker** (e.g., *Socrates vs. Steve Jobs on creativity*).

⠀✅ **Multiplayer Mode**
* Invite friends to **join the debate**, taking different sides.

⠀✅ **Memory Mode**
* AI remembers previous debates, tracking how your **opinion evolves over time**.

⠀
### The Big Picture: Why This Is Revolutionary
* **Turns note-taking into an interactive thought exercise.**
* **Merges learning with entertainment, making philosophy, science, and politics more engaging.**
* **Challenges users to think deeply instead of passively consuming information.**

# 🏗️ System Architecture

## Technical Stack
- **Frontend**: Next.js 15, React, TypeScript
- **Styling**: Tailwind CSS
- **AI**: OpenAI GPT-4
- **Voice**: ElevenLabs
- **State**: Zustand
- **UI Components**: shadcn/ui

## Component Breakdown

### Client Layer
- **React Frontend**: Main user interface
- **Voice Input Module**: Handles user voice input
- **Voice Output Module**: Manages synthesized voice output

### Backend Services

#### API Layer
- **Next.js API**: Main backend interface handling all client requests

#### Content Processing
- **Document Parser**: Processes input documents and text
- **Topic Extractor**: Analyzes and extracts key debate topics
- **Media Processor**: Handles various media formats

#### AI Engine
- **Large Language Model**: Core GPT-4 integration
- **Debater Personas DB**: Stores expert personality profiles
- **Prompt Engineering Engine**: Optimizes AI interactions
- **Fact Verification**: Real-time fact-checking system
- **Retrieval Augmented Generation**: Enhanced context-aware responses

#### Data Storage
- **Supabase/PostgreSQL**: Primary database
- **Vector Database**: Semantic search and embeddings
- **Knowledge Graph**: Relationship mapping between concepts

### External Services Integration
- **ElevenLabs API**: Voice synthesis
- **Readwise API**: Content integration
- **Twitter/X API**: Social media integration
- **YouTube API**: Video content processing

## Data Flow
1. User input (text/voice) → API Layer
2. Content processing pipeline extracts topics
3. AI Engine generates responses using:
   - Expert personas
   - Fact verification
   - Knowledge retrieval
4. Responses processed through voice synthesis
5. Data stored in appropriate databases

### ### The Ultimate Debate-Enhanced Note-Taking & Knowledge Curation App

# 🔮 Why This is a Game-Changer
✔️ **Transforms passive knowledge consumption into active debate.**✔️ **Eliminates echo chambers** by exposing users to opposing views.✔️ **Perfect for students, journalists, and deep thinkers.**✔️ **Encourages users to refine arguments through real-time, voice-driven dialectics.**

# ### Refining the AI's Knowledge Engine for Authentic Expert Responses
For this app to be **truly valuable**, the AI needs to generate **highly authentic** expert responses that feel **coherent, nuanced, and historically or factually accurate**—not just generic AI summaries. Here's how we can refine the **AI's knowledge engine** to ensure **credibility, accuracy, and engaging debate quality**.

# 🧠 How the AI Constructs Expert Responses
To generate expert-level arguments that sound *real* and *contextually accurate*, we need a **multi-layered knowledge system** with **real-time validation**. Here's the **framework**:
### 1️⃣ Layered Data Sources for Debate Generation
To make **each expert's argument feel true to their real-life beliefs**, the AI will reference multiple **verified sources**:
* **📖 Primary Sources**: Books, essays, academic papers by the expert.
* **📰 Context-Specific References**: Interviews, public debates, blog posts.
* **📜 Philosophical & Political Writings**: Foundational arguments from history.
* **🎙️ Speech & Voice Archives**: Transcripts of actual speeches (e.g., TED Talks, historic addresses).
* **📡 Real-Time Web Crawling (Optional)**: Fetches the latest references if a topic is evolving (e.g., AI ethics, climate change).

⠀🔹 **Example:** If the debate is on *"Should universal basic income (UBI) exist?"*, the AI would pull from:
* 📖 **Primary Source**: Andrew Yang's UBI proposal.
* 📜 **Historical Context**: Keynes on automation & job loss.
* 📰 **Counterarguments**: Milton Friedman's writings on free markets.

⠀Each argument would be **structured in the debater's real voice and ideology**, rather than sounding like generic AI synthesis.

### 2️⃣ Expert Persona Modeling – Keeping Debates Authentic
The AI needs to **simulate** famous thinkers **as if they were actually speaking**. To do this, it will:
✅ **Use their actual sentence structure & vocabulary.**
* Einstein's responses should be **thoughtful, exploratory, scientific**.
* Nietzsche's responses should be **bold, provocative, aphoristic**.
* Elon Musk's arguments should **lean toward technology optimism, market-driven solutions**.

⠀✅ **Incorporate their well-known beliefs & biases.**
* If debating AI, Alan Turing should reference **his work on computing and intelligence**.
* If debating capitalism, Karl Marx should lean into **his critique of labor and class struggle**.

⠀✅ **AI Style Transfer for Voice Consistency.**
* Uses **fine-tuned LLMs** to keep responses **tonally consistent** with real historical writing styles.
* Example: Nietzsche's **hyperbolic and poetic style** vs. Bertrand Russell's **calm, structured logic**.

⠀
### 3️⃣ Real-Time Fact Validation (Avoiding Hallucinations)
Since **AI can sometimes generate false information**, we introduce **real-time knowledge verification**:
**1** **Pre-Debate Accuracy Check**
	* Before generating responses, AI checks its **sources against real writings**.
	* Flags **uncited claims** and searches for a **real quote, example, or reference**.
**2** **Fact-Level Transparency for Users**
	* The app highlights **where each claim comes from** (e.g., *Plato's "Republic", Ch.5*).
	* Users can **tap a claim** and see the **original source**.
**3** **User-Guided Rebuttal Requests**
	* If a response **feels off**, users can ask: *"Would this expert have really said that?"*
	* The AI **self-audits** and offers a **fact-checked revision**.

⠀
### 4️⃣ Dynamic Multi-Expert Expansion
The AI can **expand the debate dynamically** by:
✅ **Introducing New Perspectives Mid-Debate**
* Example: If Elon Musk & Alan Turing are debating AI, the AI might **pull in Jaron Lanier** as a wildcard **AI ethics critic**.

⠀✅ **Historical vs. Modern Matchups**
* Lets users **pit different eras against each other** (e.g., *Socrates vs. Sam Harris on ethics*).

⠀✅ **Cross-Domain Experts**
* On a topic like AI, the AI might **expand beyond computer scientists** to **psychologists, artists, and philosophers**.

⠀
### 5️⃣ Realistic, Dynamic Debate Tone Adjustments
Instead of **one-size-fits-all debates**, the AI adapts:
✔️ **Academic Style** – Formal, structured, citation-backed.✔️ **Casual Debate** – Witty, conversational, Socratic.✔️ **Intense Argument** – More aggressive, rapid back-and-forth.✔️ **Historical Accuracy Mode** – Uses only **verified real-world statements**.
Users can **switch debate styles** at any time.

# 🚀 Why This is Groundbreaking
✔️ **Moves beyond generic AI debates into deeply researched, expert-level discussions.**✔️ **Simulates high-level discourse that would never happen in real life (e.g., Aristotle debating quantum physics).**✔️ **Enhances knowledge-building, critical thinking, and intellectual engagement.**✔️ **Provides high-quality, fact-checked arguments in real-time—better than reading 100 opinion articles.**

# ### 📌 Prototype Outline & UX Flow for the AI-Powered Debate Notebook
*(A seamless, interactive system for note-taking, debating, and structured idea refinement.)*
This prototype focuses on **capturing knowledge from multiple sources, synthesizing arguments, and generating AI-driven debates** in a **visually intuitive** and **voice-powered** interface.

# 🖥️ Main Screens & UX Flow
### 1️⃣ Capture & Organize Knowledge Sources
💡 **Entry Points:**
* 📝 **Text Notes** (Manual entries or summaries)
* 📌 **Bookmarks** (X/Twitter, Readwise, Medium, PDFs, articles)
* 🎙️ **Voice Notes** (Quick idea recordings)
* 🎧 **Podcast & YouTube Snippets** (Timestamped highlights)

⠀🔹 **UI Layout:**
* **Left Sidebar**: Saved Topics (organized by tags, recency, and importance).
* **Main Panel**: **User's Current Thought / Opinion** (editable field where they write or record their stance).

⠀🔹 **Action Buttons:**✅ **"Extract Debate Topic"** → AI processes the user's saved notes & selects debatable points.✅ **"Quick Debate"** → Instant AI counterarguments from famous thinkers.✅ **"Deep Dive"** → Structured multi-layered debate simulation.

### 2️⃣ Define Your Position (User Stance Entry)
* The user **enters their viewpoint** as text or voice.
* AI **analyzes sentiment** and **breaks down argument structure**.
* The system **suggests refinements**, asking:
  * *"Do you want to make this more specific?"*
  * *"What key supporting facts do you want included?"*

⠀🔹 **UI Layout:**
* **Top Bar:** Displays "Your Perspective."
* **Main Panel:** Live editable **argument editor** with AI suggestions.
* **Quick Toggle:** *Formal vs. Conversational Mode* (adjusts complexity & tone).

⠀✅ **"Preview Opposing Arguments"** → AI suggests **2 opposing views with expert profiles** before launching the debate.

### 3️⃣ AI-Generated Debate Simulation (Core Feature)
 **The Debate Panel:**
* AI generates **two opposing perspectives** in **real-time voice (via ElevenLabs or similar AI voice synthesis)**.
* Arguments are structured as a **spoken dialogue**, playable in **voice or text format**.
* The UI **mimics a live conversation**, visually highlighting each speaker's **tone, emotion, and reasoning style**.

⠀🔹 **UI Layout:**📌 **Left Panel**: **Your stance (editable)**.📌 **Middle Panel**: Live **voice-based debate** between **Expert #1 vs. Expert #2**.📌 **Right Panel**: Interactive **fact-checking & sources** for each argument.
✅ **"Pause & Interject"** → The user can jump into the debate at any time.✅ **"Challenge an Argument"** → Forces the AI debaters to respond to a specific question or counterpoint.✅ **"Expand with More Experts"** → Introduces a **third historical thinker** for a new perspective.

### 4️⃣ Interactive Engagement: Refining the Debate
* 🏆 **Scoring System:** The AI **evaluates argument strength**, rating each side based on logical coherence, historical accuracy, and persuasion.
* ✍️ **User Participation:** Users can choose to:
  * *Reinforce* their original stance with stronger supporting evidence.
  * *Switch sides* and argue the **opposite** for deeper critical thinking.
  * *Summarize & Save* key insights from the debate.

⠀🔹 **UI Layout:**📌 **Left Panel**: **Notes & Key Takeaways**.📌 **Main Panel**: Debate **highlights & best arguments**.📌 **Right Panel**: *Score & Impact Analysis* (How did the debate shift perspectives?).
✅ **"Post-Debate Summary"** → AI summarizes:
* 🎯 **What changed in your thinking?**
* 🔍 **What strong points did each side present?**
* 📚 **Recommended Further Reading** (books, research papers, YouTube videos).

⠀
### 5️⃣ Knowledge Graph & Review System
🔹 **Visual Representation of Thought Evolution:**
* A **timeline of debates** shows how the user's views evolve.
* AI detects **patterns in thinking** (e.g., *"You tend to favor arguments that emphasize technology optimism."*).
* Users can **revisit old debates** and see if their stance **has changed over time**.

⠀✅ **"Compare Past vs. Present Self"** → Side-by-side view of past arguments vs. new insights.
🔹 **UI Layout:**📌 **Main View**: A **knowledge graph** showing **related debates & evolving opinions**.📌 **Side Panel**: Access to **past notes, rebuttals, and saved arguments**.

# 🎨 UI/UX Features for Seamless Flow
### ✅ Floating Quick Capture Button (Anywhere, Anytime)
* Available **system-wide** for capturing ideas, tweets, articles, or voice memos.
* Sends captured content **directly into the Debate Notebook** for future discussions.

⠀✅ Multi-Device Sync
* Fully **integrated with Readwise, Twitter/X, YouTube, Pocket, Apple Notes, Obsidian**.
* Enables **cross-platform idea curation**, ensuring **seamless recall of past knowledge**.

⠀✅ Voice-Driven Interaction
* Users can **listen to debates hands-free** while commuting.
* "Hey AI, summarize today's best debates" → AI generates a **5-minute recap**.

⠀
# 🚀 The Big Picture: What Makes This Revolutionary?
✔️ **A dynamic, evolving thought system** → Your opinions don't just sit in notes; they evolve through interactive debate.✔️ **Brings knowledge to life** → Passive reading turns into **real-time argumentation & dialectics**.✔️ **Kills echo chambers** → Encourages users to engage with opposing views in a constructive, structured way.✔️ **Enhances deep learning & self-reflection** → Tracks **how thinking patterns evolve over time**.

### ### 📌 Development Breakdown: Building the AI-Powered Debate Notebook in Stages
*(Structured roadmap for integrating Next.js 15, Cursor AI IDE, and GitHub.)*
This will be built in **stages**, ensuring **modularity, scalability, and integration efficiency**. Each stage will produce a **usable, independent component** that can later be merged into a full system.

# 🛠️ Phase 1: Core System Setup & Note Capture (MVP)
**Goal:** Establish the **basic note-taking and knowledge capture** system before integrating AI debates.
✅ **1. Next.js 15 Project Setup**
* Create a **Next.js 15 app** (npx create-next-app@latest).
* Set up **TypeScript, ESLint, Prettier**.
* Configure **Tailwind CSS** or Chakra UI for styling.
* Initialize **GitHub repo** for version control.

⠀✅ **2. Build the Note-Taking & Capture System**
* **Text Input**: Simple markdown-based editor (react-markdown or lexical).
* **Voice Notes**: Integrate browser-based **speech-to-text API** for dictation.
* **Bookmark Manager**:
  * Save articles, X/Twitter posts (API integration later).
  * Store YouTube links, podcast timestamps.

⠀✅ **3. Database & API Setup**
* Use **Supabase (Postgres)** for note storage.
* Set up a **GraphQL or REST API** (/api/notes).
* Implement **CRUD operations** (Add/Edit/Delete Notes).

⠀🔹 **Deliverable:** A functional **note-taking & bookmarking system** with GitHub version tracking.

# 🛠️ Phase 2: AI Debate Engine (Text-Based MVP)
**Goal:** Implement **AI-driven arguments** with a **basic debate flow** (text-only).
✅ **1. AI Debate Model Selection**
* Integrate **OpenAI GPT-4 Turbo** (or local Llama/Claude API).
* Fine-tune prompts for **structured debates**.
* Define **argument framework** (Claim, Rebuttal, Counter-Rebuttal).

⠀✅ **2. Expert Persona Modeling (Simulated Debaters)**
* **Hardcode** initial expert personalities:
  * Example: *Plato, Karl Marx, Elon Musk, Alan Turing, Sam Harris*.
* Use **few-shot prompting** to match writing styles.

⠀✅ **3. Interactive Debate UI**
* **Debate View**:
  * **User Stance (Left Panel)**.
  * **Expert #1 (Middle, Pro-Side)**.
  * **Expert #2 (Right, Counterargument)**.
* Users can **challenge arguments** dynamically.

⠀✅ **4. AI Refinement & Response Tracking**
* Implement **"Challenge an Argument"** → AI generates a **response to a rebuttal**.
* Add **"Expand Debate"** → AI introduces a third expert.

⠀🔹 **Deliverable:** A **functional text-based debate system** that generates expert-level counterarguments.

# 🛠️ Phase 3: Voice AI Integration (ElevenLabs & Real-Time Debates)
**Goal:** Make AI-generated debates **audible & interactive**.
✅ **1. ElevenLabs API for Voice Synthesis**
* Convert **AI-generated text into expert voices**.
* Generate **dynamic debate audios**.
* Implement **"Play Debate" Button**.

⠀✅ **2. Real-Time Voice Interjection**
* Users can **speak a counterargument**, and AI generates **live responses**.
* Use **Whisper AI (speech-to-text)** for user voice input.

⠀✅ **3. Debate History & Playback**
* Save debates to **Supabase** for future review.
* Implement a **"Replay Debate"** function.

⠀🔹 **Deliverable:** A **real-time, voice-driven debate engine** where users can **hear experts argue**.

# 🛠️ Phase 4: Advanced Features & Knowledge Graph
**Goal:** Build **a knowledge evolution system** that **maps ideas over time**.
✅ **1. Debate Evolution Tracking**
* Track **how user opinions change** across debates.
* Implement a **timeline visualization**.

⠀✅ **2. Readwise & X (Twitter) API Integration**
* Fetch **highlights from Readwise** → Convert them into **debatable points**.
* Enable **X/Twitter thread import** for AI-generated discussions.

⠀✅ **3. AI-Generated Summaries & Reports**
* Auto-generate **debate summaries**.
* Provide **further reading suggestions** (books, papers).

⠀🔹 **Deliverable:** A **fully integrated debate-enhanced knowledge system**.

### Potential issues by phase
### 📌 Potential Issues & Solutions for Each Development Phase
*(Anticipating roadblocks & optimizing our build process for smooth development.)*
Each phase presents unique **technical challenges**, so let's **document potential issues and solutions** proactively. These notes can be added to GitHub issues or documentation as we progress.

# 🛠️ Phase 1: Core System Setup & Note Capture (MVP)
💡 **Main Risks: Database Design, Bookmark Handling, Text & Voice Input Complexity**
### 🔴 Potential Issues & Solutions
✅ **1. Database Performance & Scaling**
* **Issue:** Storing a mix of text, voice, and external links could lead to **scaling bottlenecks**.
* **Solution:**
  * **Use Postgres with Supabase**, with indexing for search optimization.
  * **Store large media files (audio snippets) in cloud storage (Supabase Storage, S3, or Cloudflare R2).**

⠀✅ **2. Handling Different Note Types (Markdown, Audio, Links, YouTube Snippets)**
* **Issue:** Standardizing **diverse input formats** for easy retrieval and editing.
* **Solution:**
  * Convert **YouTube & Podcast snippets into timestamped links**.
  * Use **Lexical (or React Markdown) for rich-text notes**.
  * Implement **a simple voice-to-text integration** from the start.

⠀✅ **3. API Rate Limits (Readwise, Twitter/X, YouTube)**
* **Issue:** External services (Readwise, X API, YouTube API) have rate limits that may **restrict data fetching**.
* **Solution:**
  * **Batch API requests** & cache responses locally.
  * **Optimize sync frequency** (fetch updates periodically instead of every request).

⠀
# 🛠️ Phase 2: AI Debate Engine (Text-Based MVP)
💡 **Main Risks: Ensuring Debate Relevance, Avoiding AI Hallucinations, Maintaining Logical Flow**
### 🔴 Potential Issues & Solutions
✅ **1. AI Generating Unconvincing or Hallucinated Arguments**
* **Issue:** GPT-based models sometimes **make up facts or misrepresent** a thinker's real stance.
* **Solution:**
  * Restrict AI responses **only to verified sources** (books, speeches, papers).
  * Build a **"Fact Check" button** where users can **flag suspicious claims**.

⠀✅ **2. Making AI Debaters Sound Realistic & Distinct**
* **Issue:** Responses may sound too **generic or GPT-like**, failing to reflect **expert personalities**.
* **Solution:**
  * Fine-tune **prompt engineering for different experts**.
  * Train models on **their actual writings** for style-matching.

⠀✅ **3. Structuring Arguments Clearly**
* **Issue:** AI debates may lack a **logical progression** (jumping from topic to topic).
* **Solution:**
  * Force AI to follow **structured debate formats**:1️⃣ **Opening Claim** → 2️⃣ **Counterargument** → 3️⃣ **Rebuttal** → 4️⃣ **Conclusion**.
  * Use **Graph-Based Argument Mapping** for coherence.

⠀✅ **4. User Interaction With AI Responses**
* **Issue:** Users may feel **passive** in the debate, rather than **engaged**.
* **Solution:**
  * **"Challenge This Argument" Button** → AI must refine its position dynamically.
  * **"Expand With Another Expert" Button** → Introduce a **third counterargument**.

⠀
# 🛠️ Phase 3: Voice AI Integration (ElevenLabs & Real-Time Debates)
💡 **Main Risks: Latency in Speech Processing, AI Sounding Unnatural, Handling User Voice Inputs**
### 🔴 Potential Issues & Solutions
✅ **1. Voice Latency (Speech Synthesis Delays in Real-Time Debates)**
* **Issue:** If ElevenLabs takes too long to generate speech, **debates will feel sluggish**.
* **Solution:**
  * Pre-load expert voice responses **asynchronously in the background**.
  * Implement **a "Quick Debate Summary" option** in text, so users don't wait.

⠀✅ **2. AI Voices Sounding Too Robotic or Wrong Tone**
* **Issue:** Some AI voices **lack natural inflection** or sound **generic**.
* **Solution:**
  * Fine-tune voice **emphasis and pacing**.
  * Introduce **speech variance** (pauses, excitement levels).

⠀✅ **3. User Voice Input Accuracy (Speech-to-Text Issues)**
* **Issue:** If voice commands **misinterpret user input**, debates become frustrating.
* **Solution:**
  * **Use OpenAI Whisper** for high-accuracy speech-to-text.
  * Allow **manual text corrections after voice input**.

⠀✅ **4. User Interrupting the Debate & Handling Dynamic Responses**
* **Issue:** AI debates are **scripted** but users may want to **jump in** at any moment.
* **Solution:**
  * Implement **an "Interrupt & Respond" button** where users cut into the debate.
  * Use **partial sentence recognition** → AI responds in real time instead of restarting.

⠀
# 🛠️ Phase 4: Advanced Features & Knowledge Graph
💡 **Main Risks: Handling Large Debate History, UI Complexity, Ensuring Searchability**
### 🔴 Potential Issues & Solutions
✅ **1. Handling Long-Term Debate History & Knowledge Evolution**
* **Issue:** Storing and searching **thousands of past debates** efficiently.
* **Solution:**
  * Implement **vector-based search (Pinecone/Weaviate) for semantic retrieval**.
  * Use **graph databases (Neo4j) to visualize argument trees**.

⠀✅ **2. Making Knowledge Graphs Intuitive & Not Overwhelming**
* **Issue:** If the knowledge graph **feels too abstract**, users may not engage.
* **Solution:**
  * Keep UI **simple**: Show **one debate branch at a time**.
  * Auto-generate **TL;DR summaries** → Instead of raw graphs, users get **"Key Insights"**.

⠀✅ **3. Integrating Readwise, X, and YouTube Seamlessly**
* **Issue:** API rate limits may prevent **real-time content syncing**.
* **Solution:**
  * Implement **daily background sync** instead of every request.
  * Let users manually **"Pull Latest Highlights"** to refresh instantly.

⠀✅ **4. Avoiding "Echo Chamber Effect" in AI Debates**
* **Issue:** If AI always selects the same counterarguments, **users may never hear fresh perspectives**.
* **Solution:**
  * Rotate **"wildcard experts"** for unpredictability (e.g., introduce an artist in a tech debate).
  * Let users choose **"Uncommon Perspectives" mode** to receive **unexpected** counterpoints.

⠀
### ### 📌 Potential Issues & Solutions for Each Development Phase
*(Anticipating roadblocks & optimizing our build process for smooth development.)*
Each phase presents unique **technical challenges**, so let's **document potential issues and solutions** proactively. These notes can be added to GitHub issues or documentation as we progress.

# 🛠️ Phase 1: Core System Setup & Note Capture (MVP)
💡 **Main Risks: Database Design, Bookmark Handling, Note Organization**
### ⚠️ Issue 1: Database Schema Complexity (Notes, Bookmarks, Audio)
* **Problem**: Storing multiple content types (text, voice, bookmarks, YouTube timestamps) in a way that remains **scalable and efficient**.
* **Solution**:✅ Use **Supabase (Postgres)** with a **normalized schema**:
  * notes: Stores text notes.
  * bookmarks: Stores external links (X/Twitter, Readwise, etc.).
  * audio_notes: Stores voice recordings.✅ **Foreign key relations** link all content under a single **topic ID** to keep structure modular.✅ Use **JSONB columns** for storing metadata (e.g., YouTube timestamps, voice note transcriptions).

⠀⚠️ Issue 2: Handling YouTube & Podcast Snippets
* **Problem**: Extracting **specific timestamps** from YouTube or podcasts requires **additional API calls**, increasing API usage limits.
* **Solution**:✅ Use the **YouTube API** & **Pocket Casts API** to fetch transcripts if available.✅ Store timestamps **locally** rather than making API calls repeatedly.✅ Allow **manual timestamp entry** if no transcript exists.

⠀⚠️ Issue 3: Browser Limitations for Voice Notes
* **Problem**: **Native voice recording APIs** have **limited compatibility** (iOS Safari issues, permission restrictions).
* **Solution**:✅ Implement **Whisper AI** for voice-to-text processing.✅ Provide a **fallback UI** for users to upload pre-recorded audio if live recording fails.

⠀📌 **Resolution Notes:**
* Design a **modular database schema** with **scalable architecture**.
* Ensure **API requests are optimized** to avoid unnecessary rate limits.
* Test **browser compatibility early** to prevent recording issues later.

⠀
# 🛠️ Phase 2: AI Debate Engine (Text-Based MVP)
💡 **Main Risks: AI Quality, Hallucination Prevention, Realism of Expert Debates**
### ⚠️ Issue 1: AI Debate Responses May Be Too Generic
* **Problem**: AI (GPT-4) tends to generate **generic** responses rather than **deep, authentic expert opinions**.
* **Solution**:✅ Implement **persona-based prompting** using **few-shot learning** to match expert tone.✅ Create a **prompt-engineering system** that injects **historical references, real quotes, and argument structures** into responses.✅ Use **OpenAI Functions API** to generate **more structured counterarguments** rather than free-flowing text.

⠀⚠️ Issue 2: Ensuring Debate Coherence Over Multiple Exchanges
* **Problem**: GPT-based models tend to **lose track of previous points** after multiple rebuttals.
* **Solution**:✅ Store **past responses in a structured format** (e.g., tree-based argument structure).✅ Implement **context window optimization** → AI only recalls **key previous arguments** instead of the full chat history.

⠀⚠️ Issue 3: Avoiding AI Hallucination & Fact-Checking Issues
* **Problem**: AI might **fabricate** quotes or arguments that were never actually said by the expert.
* **Solution**:✅ Use **retrieval-augmented generation (RAG)** by pulling **real** historical documents as context for AI-generated responses.✅ Add a **fact-check layer** where the AI **self-validates** its claims by sourcing references before generating an argument.

⠀📌 **Resolution Notes:**
* Fine-tune **persona prompting** early for **realistic debates**.
* Implement **structured memory tracking** to keep long debates coherent.
* Fact-check responses by **grounding AI output in real, verifiable sources**.

⠀
# 🛠️ Phase 3: Voice AI Integration (ElevenLabs & Real-Time Debates)
💡 **Main Risks: Latency, AI Voice Lifelikeness, Speech-to-Text Processing**
### 🔴 Potential Issues & Solutions
✅ **1. Voice Latency (Speech Synthesis Delays in Real-Time Debates)**
* **Issue:** If ElevenLabs takes too long to generate speech, **debates will feel sluggish**.
* **Solution:**
  * Pre-load expert voice responses **asynchronously in the background**.
  * Implement **a "Quick Debate Summary" option** in text, so users don't wait.

⠀✅ **2. AI Voices Sounding Too Robotic or Wrong Tone**
* **Issue:** Some AI voices **lack natural inflection** or sound **generic**.
* **Solution:**
  * Fine-tune voice **emphasis and pacing**.
  * Introduce **speech variance** (pauses, excitement levels).

⠀✅ **3. User Voice Input Accuracy (Speech-to-Text Issues)**
* **Issue:** If voice commands **misinterpret user input**, debates become frustrating.
* **Solution:**
  * **Use OpenAI Whisper** for high-accuracy speech-to-text.
  * Allow **manual text corrections after voice input**.

⠀✅ **4. User Interrupting the Debate & Handling Dynamic Responses**
* **Issue:** AI debates are **scripted** but users may want to **jump in** at any moment.
* **Solution:**
  * Implement **an "Interrupt & Respond" button** where users cut into the debate.
  * Use **partial sentence recognition** → AI responds in real time instead of restarting.

⠀
# 🛠️ Phase 4: Advanced Features & Knowledge Graph
💡 **Main Risks: UX Complexity, API Rate Limits, Knowledge Evolution Tracking**
### 🔴 Potential Issues & Solutions
✅ **1. Making the Knowledge Graph Intuitive**
* **Problem**: Users may struggle to **navigate debate history & evolving thought patterns** visually.
* **Solution:**
  * Use a **graph-based UI (D3.js or React Flow)** to map ideas clearly.
  * Allow **"time-travel mode"** where users can **compare past vs. present thinking**.

⠀✅ **2. API Rate Limits (Readwise, X/Twitter, YouTube)**
* **Problem:** High-volume API calls for fetching tweets, articles, and transcripts may hit **rate limits**.
* **Solution:**
  * Implement **local caching** for retrieved content.
  * Use **batch processing** instead of **per-item** calls.

⠀✅ **3. Detecting Thought Evolution Over Time**
* **Problem:** How do we **track changes** in a user's stance **quantitatively**?
* **Solution:**
  * AI assigns a **"confidence score"** to user beliefs based on debate performance.
  * Users can see **how their opinions shift** over multiple debates (e.g., from "strongly agree" to "neutral").

⠀📌 **Resolution Notes:**
* Design a **graph UI that visually represents argument evolution**.
* Implement **API caching & batching** to avoid rate limits.
* Track **user stance over time** with an AI-based belief shift index.

⠀
# ### 📌 Optimized MVP Build for Early Users & Expansion 🚀
*(A lean yet powerful MVP that delivers core value fast while leaving room for scalable growth.)*
### 🎯 Goal:
* **Launch a functional MVP** that lets users engage in **AI-generated debates** on **their saved content** (notes, bookmarks, voice clips).
* **Minimize complexity** while ensuring the experience is **engaging & repeat-worthy**.
* **Use feedback loops** to refine features **before building advanced AI & knowledge graphs**.

⠀
# 💡 Phase 1: MVP Core - AI Debate Engine + Note Capture (3-4 Weeks)
✅ **1. Set Up Next.js 15 + Database (Supabase/Postgres)**
* **Features:**
  * Store **user notes, bookmarks, and voice snippets**.
  * API endpoints for **saving and retrieving data**.
* **Why?** → We need a **scalable** and **real-time** backend for storing user-generated debates.

⠀✅ **2. AI Debate Engine (Text-Based)**
* **Features:**
  * User **enters a thought or opinion**.
  * AI generates **two opposing perspectives** from famous thinkers.
  * Users can **challenge & refine arguments**.
* **Why?** → This is the **core engagement loop**—users interact with AI-driven debates.

⠀✅ **3. Basic UI & User Flow (Minimalist, Clean)**
* **Core Pages:**
  * 📌 **Home** – Start a debate.
  * 📝 **Note Capture** – Save thoughts, articles, or audio.
  * 💬 **Debate Screen** – AI debate with user participation.
* **Why?** → We need a simple, **intuitive UX** so users **quickly understand the product**.

⠀🔹 **MVP Deliverable:** A **working AI debate feature** where users **input opinions, trigger AI arguments, and interact via text**.

# 💡 Phase 2: Voice Debates & Speech Integration (Expand Engagement, 3-6 Weeks)
✅ **4. ElevenLabs Voice Synthesis Integration**
* **Convert AI responses into speech** for a **real-time debate feel**.
* Implement **"Play Debate" button**.
* **Why?** → Users **connect more deeply with audio** than plain text.

⠀✅ **5. Speech-to-Text (User Voice Input via Whisper AI)**
* **Let users respond via voice**, AI generates real-time counterarguments.
* **Why?** → Increases engagement **without requiring typing**.

⠀✅ **6. Debate Replay & Summary Generation**
* AI **summarizes each debate** in bullet points.
* Saves debate history for review.
* **Why?** → Gives **users tangible takeaways** from each debate.

⠀🔹 **Deliverable:** A fully **voice-powered AI debate experience** where users can **listen & participate via speech**.

# 💡 Phase 3: Early Community & Content Expansion (Expand User Base, 6-8 Weeks)
✅ **7. Readwise & X (Twitter) API Integration**
* Import **user highlights & tweets** → Generate AI debates automatically.
* **Why?** → Makes the app **instantly useful** for people who **already consume high-quality content**.

⠀✅ **8. "Wild Card" AI Experts (Serendipity Feature)**
* Occasionally **inject unexpected debaters** (e.g., Einstein jumps into a discussion on social media).
* **Why?** → Keeps debates **engaging & unpredictable**.

⠀✅ **9. Community Feedback & Iteration**
* Run **user feedback loops** → Improve **AI responses, voice quality, UX**.
* Measure **retention metrics** → Find out **which debate types are most engaging**.

⠀🔹 **Deliverable:** MVP evolves into a **sticky product with social sharing & deeper user engagement**.

### 🚀 The Optimized MVP Strategy
| **Phase** | **Feature Focus** | **Why?** | **Timeline** |
|:-:|:-:|:-:|:-:|
| **1** | 📝 **AI Debate Engine (Text-Only) + Note Capture** | **Core engagement** | 3-4 Weeks |
| **2** | 🎙️ **Voice Debates & Speech Input (ElevenLabs + Whisper AI)** | **Increases immersion** | 3-6 Weeks |
| **3** | 🔗 **Readwise & Twitter API + AI Surprises** | **Expands content sources & community** | 6-8 Weeks |

# 🚀 Immediate Next Steps
1️⃣ **Kickstart Phase 1: Text-Based AI Debates + Note Capture**
* **Set up Next.js 15 project** & **Supabase backend**.
* **Implement AI text debates**.
* **Deploy early MVP for testing**.

⠀2️⃣ **Plan Phase 2: Voice Debates (Start ElevenLabs Integration)**
* **Test AI-generated speech responses** in **simple voice debates**.

⠀3️⃣ **Define Phase 3 Expansion (API, Social Growth)**
* **Early access users from Readwise & X community**.

⠀
# 💡 Summary: Why This Works?
✅ **MVP ships fast, capturing early users** without overcomplicating AI.✅ **Keeps the focus on core engagement** (debate & user participation).✅ **Leaves room for expansion** into **voice, API integrations & knowledge evolution**.

# Debate-able 🎯

## 🏗️ System Architecture

### Overview
The system is built with a modern microservices architecture, combining real-time AI processing with robust data storage and external service integration.

### Component Breakdown

#### Client Layer
- **React Frontend**: Main user interface
- **Voice Input Module**: Handles user voice input
- **Voice Output Module**: Manages synthesized voice output

#### Backend Services

##### API Layer
- **Next.js API**: Main backend interface handling all client requests

##### Content Processing
- **Document Parser**: Processes input documents and text
- **Topic Extractor**: Analyzes and extracts key debate topics
- **Media Processor**: Handles various media formats

##### AI Engine
- **Large Language Model**: Core GPT-4 integration
- **Debater Personas DB**: Stores expert personality profiles
- **Prompt Engineering Engine**: Optimizes AI interactions
- **Fact Verification**: Real-time fact-checking system
- **Retrieval Augmented Generation**: Enhanced context-aware responses

##### Data Storage
- **Supabase/PostgreSQL**: Primary database
- **Vector Database**: Semantic search and embeddings
- **Knowledge Graph**: Relationship mapping between concepts

#### External Services Integration
- **ElevenLabs API**: Voice synthesis
- **Readwise API**: Content integration
- **Twitter/X API**: Social media integration
- **YouTube API**: Video content processing

### Data Flow
1. User input (text/voice) → API Layer
2. Content processing pipeline extracts topics
3. AI Engine generates responses using:
   - Expert personas
   - Fact verification
   - Knowledge retrieval
4. Responses processed through voice synthesis
5. Data stored in appropriate databases

## 🛠️ Technical Stack

- **Frontend**: Next.js 15, React, TypeScript
- **Styling**: Tailwind CSS
- **AI**: OpenAI GPT-4
- **Voice**: ElevenLabs
- **State**: Zustand
- **UI Components**: shadcn/ui

## 📈 Development Status

## New Feature: Document-Based Responses

The application now supports Retrieval-Augmented Generation (RAG) to provide factual responses based on uploaded documents. When a user uploads a PDF document, the system:

1. Extracts text from the document
2. Splits the text into manageable chunks
3. Creates vector embeddings for each chunk
4. Stores these embeddings in a vector database (Pinecone)
5. Retrieves relevant content when questions are asked
6. Incorporates this content into AI responses

This ensures that expert responses are grounded in the factual content of the uploaded documents rather than relying solely on the AI model's general knowledge.

### Setup for Document-Based Responses

To enable this feature, you need to:

1. Create a Pinecone account at [pinecone.io](https://www.pinecone.io/)
2. Create a new index with the following settings:
   - Dimensions: 1024 (for OpenAI embeddings)
   - Metric: Cosine
   - Pod Type: Starter (for development)
3. Add your Pinecone API key, environment, and index name to your `.env.local` file:
   ```
   PINECONE_API_KEY=your_pinecone_api_key
   PINECONE_ENVIRONMENT=gcp-starter
   PINECONE_INDEX=debate-documents
   ```

### Development Mode

If you don't want to set up Pinecone during development, you can use the mock implementation by setting:

```
USE_MOCK_DATA=true
```

This will use a simple in-memory storage for document chunks and basic keyword matching for retrieval.
</file>

<file path="tailwind.config.ts">
import type { Config } from "tailwindcss";
const config: Config = {
  content: [
    "./src/pages/**/*.{js,ts,jsx,tsx,mdx}",
    "./src/components/**/*.{js,ts,jsx,tsx,mdx}",
    "./src/app/**/*.{js,ts,jsx,tsx,mdx}",
  ],
  darkMode: 'class',
  theme: {
    extend: {
      colors: {
        border: "hsl(var(--border))",
        input: "hsl(var(--input))",
        ring: "hsl(var(--ring))",
        background: "hsl(var(--background))",
        foreground: "hsl(var(--foreground))",
        primary: {
          DEFAULT: "hsl(var(--primary))",
          foreground: "hsl(var(--primary-foreground))",
        },
        secondary: {
          DEFAULT: "hsl(var(--secondary))",
          foreground: "hsl(var(--secondary-foreground))",
        },
        destructive: {
          DEFAULT: "hsl(var(--destructive))",
          foreground: "hsl(var(--destructive-foreground))",
        },
        muted: {
          DEFAULT: "hsl(var(--muted))",
          foreground: "hsl(var(--muted-foreground))",
        },
        accent: {
          DEFAULT: "hsl(var(--accent))",
          foreground: "hsl(var(--accent-foreground))",
        },
        popover: {
          DEFAULT: "hsl(var(--popover))",
          foreground: "hsl(var(--popover-foreground))",
        },
        card: {
          DEFAULT: "hsl(var(--card))",
          foreground: "hsl(var(--card-foreground))",
        },
      },
      borderRadius: {
        lg: "var(--radius)",
        md: "calc(var(--radius) - 2px)",
        sm: "calc(var(--radius) - 4px)",
      },
    },
  },
  plugins: [],
}
export default config;
</file>

<file path="tsconfig.json">
{
  "compilerOptions": {
    "target": "ES2017",
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./src/*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"],
  "exclude": ["node_modules"]
}
</file>

</files>
